#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\begin_preamble
\usepackage[style=authoryear, natbib=true]{biblatex}
%\usepackage{natbib}
%\setcitestyle{square}
\addbibresource{progress_report.bib}
\end_preamble
\use_default_options true
\maintain_unincluded_children false
\begin_local_layout
Provides natbib 1
\end_local_layout
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command biber
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type authoryear
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Progress Report 
\end_layout

\begin_layout Section*
Review of my progress 
\end_layout

\begin_layout Standard
I made myself familiar with the literature: The main goal was to understand
 the biological and mathematical motivation for modeling neuronal networks
 in terms of density functions representing individual neuron populations.
 In order to understand the mathematical language, I deepened my knowledge
 about jump processes, stochastic differential equations, and partial differenti
al equations with boundary conditions.
 I studied in detail, under which conditions a Poisson processes can be
 well approximated by a diffusion process.
 The diffusion approximation is frequently applied in theoretical studies
 of neuronal networks to model the synaptic current invoked by stochastic
 spike arrivals.
 This work is summarized in the notebook ...
 which I uploaded with the other documents of the progress report.
 
\end_layout

\begin_layout Standard
In the context of population density techniques, the time evolution of the
 density function is described by a partial differential equation (PDE).
 One method of solution is spectral decomposition.
 This method expands the density function in terms of eigenfunctions of
 the operator which defines the PDE.
 I recovered the main results from the paper presented in 
\begin_inset CommandInset citation
LatexCommand citet
key "Mattia2002"

\end_inset

, in which the authors derived the spectra and eigenfunctions for the perfect
 integrate-and-fire (PIF) neuron.
 This includes a python implementation to numerical solve the characteristic
 equation which implicitly determines the eigenvalues.
 I gone through the derivation of the eigenfunctions and the characteristic
 equation for the leaky integrate-and-fire neuron.
 Both derivations are carried out in the diffusion approximation.
 This work is summarized in the notebook ...
 .
\end_layout

\begin_layout Standard
To apply the method of spectral decomposition to more complex neuron models
 than the LIF neuron, it is necessary to know the eigenvalues and eigenfunctions
 of the operator which defines the corresponding PDE.
 This is not an easy task, and so far not much progress has been made analytical
ly which goes beyond the LIF neuron.
 Our goal is to develop an algorithm which determines the spectra and eigenfunct
ions numerically for more complex neuron models.
 Our first naive approach is to use the simulator Miind, which solves the
 partial differential equation using the methods of characteristics.
 Having the full solution, we want to reverse engineer the spectra and eigenfunc
tions by making use of the fact that modes relax to equilibrium on different
 time scales determined by the imaginary part of the associated eigenvalue.
 If we identify epochs in which only a few or ideally a single mode is active,
 then we may be able to recover it from the full solution.
 On could start such a reconstruction from the first mode with the slowest
 decay constant and than successfully move to higher modes.
 As a proof concept, I implemented the PIF neuron model in Miind.
 Since, the eigenvalues and eigenfunctions are known for the PIF, we can
 compare the numerically results obtained from our proposed method to the
 ground truth provided by the theory.
 I first comparison showed a subtle discrepancy between the numerical solution
 obtained from Miind and the theory.
 The stationary firing rate and the time evolution of the density due to
 the first mode (slowest decay) of the spectral decomposition shows a small
 biased.
 Additional Monte Carlo simulations showed no biased with respect to the
 theory.
 I started to investigate what the cause of this bias is and if it can be
 fixed by changing the implementation of the PIF neuron in Miind.
 As a proof of principle, I recovered the first eigenfunction from the full
 solution despite the biased.
 
\end_layout

\begin_layout Standard
There are still some general questions if our naive approach can be fruitful.
 One complication arises if the input to a neuron is changing with time.
 If it does, then the operator defining the PDE is time dependent and so
 are the eigenvalues and eigenfunctions.
 In other words, we need to expand the density in a moving basis.
 In this case, it is necessary to not only determine the eigenfunctions
 but also there derivative with respect to time.
 One possible approach to this problem would be to define a input range
 of interest, discretize it and use the proposed method separately for a
 stationary input in the the given range.
 Using this set of eigenfunctions, it may be possible to estimate the derivative
 with respect to time using interpolation between the solutions for the
 different stationary inputs.
 
\end_layout

\begin_layout Standard
Another difficulty is due to the fact that the decay constants of successive
 modes become increasingly similar for higher modes.
 This means it many modes are simultaneously active when the network relaxes
 to equilibrium.
 
\end_layout

\begin_layout Section*
Provisional title of my thesis: 
\end_layout

\begin_layout Standard
Spectral analysis of the dynamics of neuronal networks using population-density
 techniques 
\end_layout

\begin_layout Section*
Statement of the research question:
\end_layout

\begin_layout Standard
Population density techniques have been applied to investigate the dynamics
 of large populations interacting neurons.
 Most of the studies focus on integrate-and-fire neuron models, i.e.
 single compartment models.
 The state of the neuron is described by a set of biophysical variables
 usually including the membrane potential.
 The other variables can e.g.
 account for gating mechanism of ion channels, synaptic dynamics or adaptive
 behavior of the neuron.
 
\end_layout

\begin_layout Standard
Population density techniques employ the redundancy present in subpopulations
 of cortical networks by introducing a probabilistic description of the
 entire population.
 This means that the state of each population is described by a single density
 function instead of modeling the coupled dynamics of each neuron individually.
 The density functions gives information about the proportion of neurons
 in the population which are at a given dynamical state at a given point
 in time.
 Like other mean-field approaches, the population density technique drastically
 reduces the dimensionality of the problem which makes it more suitable
 for analytical treatment and computational less demanding in large scale
 simulations.
 
\end_layout

\begin_layout Standard
However, even for simple neuronal models, the time evolution of the density
 is governed by a complicated nonlinear partial differential equation (PDE).
 Analytically studies have been only carried out for the most simple neuron
 models.
 For example, analytical expressions for the stationary distribution, and
 the firing rate of the leaky integrate-and-fire neurons have been derived
 in the diffusion limit.
 Stability of the stationary state and synaptic dynamics have been studied
 perturbatively.
 
\end_layout

\begin_layout Standard
Besides this analytical treatments, the PDE can also be solved numerically
 which allows for the study of more complicated models.
 However, using a numerical approach, it is more difficult and time consuming
 to get an insight into the relationship between system dynamics and the
 model parameter.
 This short come can be circumvented to some extend by using spectral decomposit
ion.
 It has been shown that the density can be decomposed in terms of eigenfunctions
 of the differential operator which defines the PDE.
 This decomposition reduces the PDE to an infinite system of ordinary differenti
al equations (ODEs).
 Depending on the question of interest, only a view modes of the expansion
 can be sufficient to capture the dynamics of the system.
 Describing the system in terms of eigenmodes offers a more intuitive descriptio
n of the non equilibrium dynamics.
 Furthermore, the spectrum can be used to distinguish different dynamical
 regimes of the network.
 
\end_layout

\begin_layout Standard
So far, the spectrum and eigenfunctions have only be derived for the perfect
 and leaky integrate-and-fire model in the diffusion limit.
 The goal of this project is to develop a general method to determine the
 spectra and eigenfunctions numerically for a given integrate-and-fire neuron
 model using the neuronal simulator Miind.
 As a next step, we would apply the method to different neuron models which
 e.g.
 include synaptic dynamics or adaptive behavior.
 Our hope is, that knowing the spectra and eigenfunctions of these models
 would enable us to obtain a better understanding of the dynamical properties
 of these models.
 This includes relaxation dynamics, dynamical regimes like asynchronous
 irregular firing, global oscillations or bursting behavior, resonance frequenci
es and gain modulation.
 Furthermore, comparing the spectra of different models may help answer
 the question if and why complex higher dimensional models can be reduced
 to some extend to lower dimensional ones.
\end_layout

\begin_layout Subsection*
Literature review 
\end_layout

\begin_layout Standard
In computational neuroscience, the most common method to simulate neural
 circuits is by means of direct simulation.
 This approach follows the dynamics of all neurons individually.
 Neurons are connected according to a connectivity blueprint which needs
 to specified depending on the brain region of interest.
 This method gives access to observables, like the membrane potential, firing
 rate or correlation measures, on the level of single neurons.
 However, due to the large number of neurons and synaptic connections in
 the mammalian cortex, modeling of a small area of cortex requires a fast
 amount of computational power.
 Hence, large scale brain simulations, even for extremely simplified neuron
 models, need to be run on super computers 
\begin_inset CommandInset citation
LatexCommand citep
key "Schuecker2017"

\end_inset

.
 The connectivity structure in such models is usually defined in terms of
 populations which represent neurons of the same type in a specific cortical
 area.
 The type of a neuron can be characterized by e.g.
 its morphology, its electrophysiological properties, or functional properties
 (e.g.
 receptivity to a specific stimulus feature).
 Neurons within a population are considered to be statistical identical,
 i.e.
 they form on average the same number of connections with neurons of other
 types.
 The strength of each individual connection is drawn randomly from a distributio
n which may differ depending on the type of the pre- and postsynaptic neuron.
 Parameters determining the neuron model are often assumed to be identical
 for all neurons which belong to the same population, but could be in principle
 drawn randomly from a given distribution.
 In this setting, one is usually not interested in the dynamical features
 of individual neurons, but instead on the dynamical features of the individual
 populations as a whole.
 These include e.g.
 the average population firing rate, interspike interval statistics (ISI),
 or the statistics of pairwise or higher order correlations of neuronal
 activity.
\end_layout

\begin_layout Standard
This motivated an alternative modeling approach which has been developed
 at the end of the last century simultaneously by different authors 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag,Knight2000a,Nykamp"

\end_inset

.
 It describes the dynamics on the level of populations instead of modeling
 individual neurons, and is therefore called population density method.
 It relies on the assumption that neurons in each population can be assumed
 to be homogeneous.
\end_layout

\begin_layout Standard
The method presented in 
\begin_inset CommandInset citation
LatexCommand citet
key "Omurtag"

\end_inset

 can be in principle be applied to any kind of point neuron model.
 Point neurons are single compartment models, i.e.
 the cell body of a neuron is collapsed to a single point.
 This means that they can not account for dynamical features which are related
 to the morphology of a neuron.
 
\end_layout

\begin_layout Standard
A neuron receives excitatory and inhibitory inputs which arrive from other
 neurons by their associated synapses.
 These inputs are modeled either as injected currents or as a change in
 conductance.
 Current based synapses are simpler compared to conductance based models
 because they produce a current which is independent of the state of the
 neuron.
 This means that multiple synaptic inputs can be summed linearly.
 Conductance synapse models are state dependent because the synaptic current
 produced by a conductance change depends on the difference between the
 membrane potential and the reversal potential of the corresponding synapse.
 As a consequence, the summation of synaptic inputs is nonlinear for conductance
 based models.
 
\end_layout

\begin_layout Standard
In absence of synaptic input, the membrane potential relaxes back to its
 reversal potential which marks equilibrium between cell interior and exterior.
 The time scale of the relaxation is controlled by a model parameter usually
 called the membrane time constant.
 If a neuron receives sufficiently strong excitatory input, the membrane
 potential exceeds a threshold value which will cause the neuron to emit
 an action potential, followed by a reset and refractory period.
 This threshold mechanism can be either intrinsically incorporated into
 the model, like it is for example in Hodgkin-Huxley (H-H) type models 
\begin_inset CommandInset citation
LatexCommand citep
key "Hodgkin1952"

\end_inset

 or it can be introduced artificially.
 Prominent examples of neuron models with artificial threshold mechanism
 are the perfect 
\begin_inset CommandInset citation
LatexCommand citep
key "Fusi1999"

\end_inset

 (PIF), leaky 
\begin_inset CommandInset citation
LatexCommand citep
key "Lapicque1907,Stein1967"

\end_inset

 (LIF), quadratic 
\begin_inset CommandInset citation
LatexCommand citep
key "Ermentrout1996"

\end_inset

 and exponential integrate-and-fire neurons 
\begin_inset CommandInset citation
LatexCommand citep
key "Fourcaud-Trocme2003"

\end_inset

.
 The quadratic and exponential integrate-and-fire neuron incorporate nonlinear
 dynamics to mimic the superthreshold transients of the membrane potential
 after spike initiation.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Fourcaud-Trocme2003"

\end_inset

 showed that these nonlinear dynamics are necessary to achieve a better
 agreement of the neuron response to time varying input if compared to simulatio
ns of more realistic H-H type models.
 
\end_layout

\begin_layout Standard
The integrate-and-fire models are simpler to study because they have less
 parameters and less dynamical variables and it has been shown that they
 are still able to adequately describe subthreshold dynamics of the membrane
 potential 
\begin_inset CommandInset citation
LatexCommand citep
key "Bernander1991"

\end_inset

.
 For an overview on the theory of different integrate-and-fire models see
 
\begin_inset CommandInset citation
LatexCommand citet
key "Burkitt2006,Burkitt2006a"

\end_inset

.
 
\end_layout

\begin_layout Standard
In general, for a given point neuron model, the state of a neuron can be
 determined by a set of dynamic variables 
\begin_inset Formula $\boldsymbol{v}=(v_{1},v_{2},\ldots,v_{n})$
\end_inset

 usually including the membrane potential which is set to be the first variable
 
\begin_inset Formula $v_{1}=V$
\end_inset

 by convention.
 The time evolution of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 is assumed to be determined by first order kinetics 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset


\begin_inset Formula 
\begin{equation}
\frac{d\boldsymbol{v}}{dt}=\boldsymbol{F}(\boldsymbol{v})+\boldsymbol{S}(\boldsymbol{v},g(t)).\label{eq: neuron dynamics}
\end{equation}

\end_inset

The vector field 
\begin_inset Formula $\boldsymbol{F}(\boldsymbol{v})$
\end_inset

 represents the time evolution of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 due to the intrinsic neuron dynamics and 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},s(t))$
\end_inset

 models the incoming synaptic current due to synaptic arrivals.
 Note that the term 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},g(t))$
\end_inset

 is a conductance based synapse, i.e.
 synaptic arrivals cause a conductance changes 
\begin_inset Formula $g(t)$
\end_inset

, which in turn produces a current which is state dependent.
 The current can be in general state 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 dependent.
 Note that Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

 only contains one type of synapse, i.e.
 it can only model a single excitatory or a single inhibitory input.
 However, in principle, a range of synapses can be included by replacing
 
\begin_inset Formula $g(t)$
\end_inset

 by a vector 
\begin_inset Formula $\boldsymbol{g}(t)$
\end_inset

.
 To given an specific example for Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 used a H-H type model defined by 
\begin_inset Formula 
\begin{align}
\frac{dV}{dt} & =\frac{1}{C}\left(g_{L}(V_{L}+V)+g_{n}m^{3}h(V_{N}-V)+g_{K}n^{4}(V_{K}-V)\right)+\frac{1}{C}g_{s}(t)(V_{s}-V),\nonumber \\
\frac{dm}{dt} & =\frac{1}{\tau_{m}(V)}(m_{\infty}(V)-m),\nonumber \\
\frac{dh}{dt} & =\frac{1}{\tau_{h}(V)}(h_{\infty}(V)-h),\nonumber \\
\frac{dn}{dt} & =\frac{1}{\tau_{n}(V)}(n_{\infty}(V)-n).\label{eq: H-H}
\end{align}

\end_inset

For this model, the state space 
\begin_inset Formula $\boldsymbol{v}=(V,m,h,n)$
\end_inset

 is four dimensional.
 Following our convention, the first entry in 
\begin_inset Formula $\boldsymbol{F}(\boldsymbol{v})$
\end_inset

 corresponds to the first equation describing the time evolution of 
\begin_inset Formula $V$
\end_inset

.
 
\end_layout

\begin_layout Standard
On the network level, populations are recurrently connected and receive
 additional inputs from the external surrounding.
 Assume that we know all times at which spikes arrive at synapses associated
 neuron 
\begin_inset Formula $i$
\end_inset

.
 This times can be represented as a sum of delta distributions 
\begin_inset Formula 
\begin{equation}
s_{i}(t)=\sum_{k}\sum_{n}\delta(t-t_{n}^{(k)}),\label{eq: s_i(t)}
\end{equation}

\end_inset

where the index 
\begin_inset Formula $k$
\end_inset

 corresponds to the different synapses.
 By inserting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: s_i(t)"

\end_inset

 into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

 and integrating the r.h.s., we obtain the deterministic time evolution of
 
\begin_inset Formula $\boldsymbol{v}_{i}$
\end_inset

 for the specific input 
\begin_inset Formula $s_{i}(t)$
\end_inset

.
 However, note that 
\begin_inset Formula $s_{i}(t)$
\end_inset

 is an unknown unless one would model the entire brain on a microscopic
 level for a given initial condition.
 For example, in stimulus response experiments, a high trial to variability
 in the response of individual neurons is observed.
 This apparently random variations are often accounted for by adding sources
 of noise to the model.
 This turns deterministic problem governed by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

 into a stochastic one.
 
\end_layout

\begin_layout Standard
In general, the membrane potential of a neuron is subject to two sources
 of noise: one intrinsic to the neuron, associated with the stochastic nature
 of the mechanism controlling neurotransmitter release, opening of ion channels
 and so forth.
 The other is external, arising from the apparently random arrival of individual
 spikes 
\begin_inset CommandInset citation
LatexCommand citet
key "Burkitt2006"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Mainen1995"

\end_inset

 showed in vitro experiment that neurons in rat cortex are able to reliably
 respond if stimulated with a noisy input current injected directly into
 cell body.
 Spike times over several trials could be reproduced with deviations in
 the order of 
\begin_inset Formula $ms$
\end_inset

.
 This suggests that intrinsic noise is insignificant compared to external
 noise associated with the stochastic synaptic input.
 
\end_layout

\begin_layout Standard
Consequently, the dominant source of randomness is assumed to be the stochastic
 time arrivals of the synaptic input.
 These are modeled in most cases as a Poisson process.
 Note that spikes which arrive at single synapse may differ from a Poisson
 input.
 However, as long as they can be approximated by a renewal process, i.e.
 ISI are identical and independently distributed, the pooling property 
\begin_inset CommandInset citation
LatexCommand citep
key "Gallager2011"

\end_inset

 of independent renewal process ensures that the Poisson process provides
 an adequate description for the overall input summed over a large number
 of synapses.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
In other words, the ISIs at synapse will tend to be large relative to ISIs
 of summed input.
 Thus, arrivals that are close together in time will typically come from
 different synapses.
\end_layout

\end_inset

 
\end_layout

\begin_layout Standard
Note that the above reasoning implies that spike trains arriving at different
 synapses are uncorrelated, which is in general no true 
\begin_inset CommandInset citation
LatexCommand citep
key "Poulet2008"

\end_inset

.
 Indeed, input correlations are in inevitable consequence of two neurons
 being part of the same network, and therefore sharing some common synaptic
 input 
\begin_inset CommandInset citation
LatexCommand citep
key "Ostojic"

\end_inset

.
 However, if the network is sparsely connected, i.e.
 the number of indegrees is small compared to the network size, then the
 number of common inputs can assumed to be small.
 Furthermore, it has been shown that in recurrently connected networks inhibitio
n decorrelates neural activity 
\begin_inset CommandInset citation
LatexCommand citep
key "Tetzlaff2012,Renart2010"

\end_inset

.
 Excitation and inhibition tends to balance each other leading to a stationary
 state where the membrane potential of individual neurons saturates beneath
 threshold.
 Threshold crossings in this state are caused by the random fluctuations
 in the input (noise driven regime) which lead to asynchronous irregular
 firing (AI), also refereed to as spontaneous activity 
\begin_inset CommandInset citation
LatexCommand citet
key "Amit1997"

\end_inset

.
 In such a setting, assuming the input at different synapses to be independent
 can be regarded as a zeroth order approximation.
 
\end_layout

\begin_layout Standard
If input correlations are assumed to be small , pairwise correlations can
 be studied perturbatively 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindner2001"

\end_inset

.
 For a recent nonpertubative study of the LIF neuron covering weak and strong
 correlated input dynamics see 
\begin_inset CommandInset citation
LatexCommand citep
key "Deniz2017"

\end_inset

.
 
\end_layout

\begin_layout Standard
For the reminder, we work in the zeroth order approximation, i.e.
 that neurons receive independent Poisson input.
 If 
\begin_inset Formula $s_{i}(t)$
\end_inset

 in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

 is assumed to be a inhomogeneous Poisson process, i.e.
 it is characterized by instantaneous input rate 
\begin_inset Formula $\sigma(t)$
\end_inset

.
 The product 
\begin_inset Formula $\sigma(t)\delta t$
\end_inset

 yields the average number of spike arrivals in the time interval 
\begin_inset Formula $[t,t+\delta t]$
\end_inset

 in the limes 
\begin_inset Formula $\delta t\rightarrow0$
\end_inset

.
 Hence, 
\begin_inset Formula $s_{i}(t)$
\end_inset

 is a stochastic quantity in the approach and Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: neuron dynamics"

\end_inset

 becomes a stochastic differential equation.
 
\end_layout

\begin_layout Standard
Instead of solving Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: neuron dynamics"

\end_inset

 for specific realization of 
\begin_inset Formula $s_{i}(t)$
\end_inset

, we are interested predicting the average response of the populations embedded
 in a network.
 Hence, starting from the microscopic Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

, the objective is to describe each population by a density function 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

.
 The product 
\begin_inset Formula $\rho(\boldsymbol{v},t)d\boldsymbol{v}$
\end_inset

 gives the proportion of neurons in the population which are in the state
 space volume 
\begin_inset Formula $[\boldsymbol{v},\boldsymbol{v}+d\boldsymbol{v}]$
\end_inset

 at a given time 
\begin_inset Formula $t$
\end_inset

.
 To arrive at a dynamic equation for the time evolution of 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

, the authors in 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 make several simplifying assumptions.
 
\end_layout

\begin_layout Standard
First, they assume that a neuron feels on average the instantaneous firing
 rate 
\begin_inset Formula 
\begin{equation}
\sigma(t)=\sigma_{0}(t)+Gr(t),\label{eq: input rate}
\end{equation}

\end_inset

where 
\begin_inset Formula $\sigma_{0}(t)$
\end_inset

 is the average firing rate of the external input, 
\begin_inset Formula $G$
\end_inset

 is average number of afferent recurrent connections and 
\begin_inset Formula $r(t)$
\end_inset

 is the average firing rate of the population.
 Secondly, they assume that synaptic time scales are short compared to the
 membrane time constant.
 Hence, they approximate the conductance changes caused by arriving spikes
 to be instantaneous 
\begin_inset Formula 
\begin{equation}
g_{i}(t)=\hat{g}\sum_{n}\delta(t-t_{n}).\label{eq: g_i(t)}
\end{equation}

\end_inset

which are called delta-synapses.
 The the magnitude of conductance change 
\begin_inset Formula $\hat{g}$
\end_inset

 is assumed to be constant for all connections.
 This is why the sum over the different synapses in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: s_i(t)"

\end_inset

 is not required.
 If conductance changes are instantaneous, the membrane potential makes
 a jump of 
\begin_inset Formula $h=\hat{g}V_{s}/C$
\end_inset

 whenever a spike arrives.
 The constant 
\begin_inset Formula $h$
\end_inset

 is called synaptic efficacy.
 This follows from integrating the membrane equation in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

 across the instant of a spike arrival.
 All other dynamic variables in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

 are unaffected.
 
\end_layout

\begin_layout Standard
Note that the total number of afferent connections will differ for different
 neurons.
 Note further that assuming a fixed 
\begin_inset Formula $\hat{g}$
\end_inset

 for all connections is not biological plausible, due to synaptic plasticity.
 Furthermore, the strength of a individual synapse may be subject to noise
 including the possibility to fail with a certain probability.
 To model this, one would need to introduce a synaptic strength 
\begin_inset Formula $\hat{g}_{k}$
\end_inset

 for each synapse and make 
\begin_inset Formula $\hat{g}_{k}$
\end_inset

 a stochastic quantity drawn randomly at each transmission.
 However, if one is only interested in predicting the average behavior of
 the entire population, then in the limes of large networks, the above mentioned
 inhomogeneities can be assumed to average out.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997a"

\end_inset

 included such inhomogeneities in direct simulations and showed that the
 theory still reliably predicts the steady state firing rate of the populations
 within the network.
 
\end_layout

\begin_layout Standard
Using this simplifications, 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 derived a partial differential equation for the population density
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=-\frac{\partial}{\partial\boldsymbol{v}}\left(F(\boldsymbol{v})\rho\right)-\sigma(t)\times\left\{ \rho(\boldsymbol{v},t)-\rho(\boldsymbol{v}''(\boldsymbol{v}),t)\frac{\partial\boldsymbol{v}''}{\partial\boldsymbol{v}}\right\} ,\label{eq: pde rho}
\end{equation}

\end_inset

where 
\begin_inset Formula $\boldsymbol{v}''(\boldsymbol{v})$
\end_inset

 is the region of state space which would jump to 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 after a spike arrival.
 For model H-H model described by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

 and delta-synapses, spikes only cause changes in membrane potential.
 Hence, the first entry 
\begin_inset Formula $\boldsymbol{v}''(\boldsymbol{v})$
\end_inset

 is given by 
\begin_inset Formula $V''=V-h$
\end_inset

 and all other entries 
\begin_inset Formula $v_{i}=v_{i}$
\end_inset

.
 The above equation can be written as a continuity equation 
\begin_inset Formula 
\begin{equation}
\rho(\boldsymbol{v},t)=-\frac{\partial}{\partial\boldsymbol{v}}\boldsymbol{J}(\boldsymbol{v},t),\label{eq: continuity equation}
\end{equation}

\end_inset

where 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 is the probability flux which determines the flow of probability at point
 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

.
 It has two two contributions 
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}=\boldsymbol{J}_{\text{str}}+\boldsymbol{J}_{\text{imp}},\label{eq: J}
\end{equation}

\end_inset

one accounting for intrinsic neuron dynamics
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}_{\text{str}}=\boldsymbol{F}(\boldsymbol{v})\rho(\boldsymbol{v},t),\label{eq: J_str}
\end{equation}

\end_inset

 and the other accounting for the Poisson input 
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}_{\text{imp}}=-\sigma(t)\int_{V}^{V''(V)}\boldsymbol{e}_{V}\rho(W,v_{2},\ldots)dW,\label{eq: J_imp}
\end{equation}

\end_inset

which depends on the input rate determined by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

.
 Note that 
\begin_inset Formula $\boldsymbol{J}(v,t)$
\end_inset

 is function of 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 as well as the input rate 
\begin_inset Formula $\sigma(t)$
\end_inset

.
 The firing rate of the population 
\begin_inset Formula $r(t)$
\end_inset

 can be determined defining a threshold value 
\begin_inset Formula $V=V_{\theta}$
\end_inset

 of the the membrane potential, constructing a Poincare surface at this
 value and determining the flux which goes through this surface.
 Hence, the the firing 
\begin_inset Formula $r(t)$
\end_inset

 rate can be expressed as a linear functional of 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 
\begin_inset Formula 
\begin{equation}
r(t)=R[\boldsymbol{J}(\boldsymbol{v},t)]\label{eq: r}
\end{equation}

\end_inset

To ensure conversation of probability, the probability which passed through
 the threshold needs to be reinserted at the reset potential 
\begin_inset Formula $V_{r}$
\end_inset

.
 This can be modeled by introducing a absorbing boundary at threshold with
 reset mechanism.
 The crucial point is that 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 depends on 
\begin_inset Formula $\sigma(t)$
\end_inset

, and therefor on 
\begin_inset Formula $r(t)$
\end_inset

 due to Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

.
 Replacing 
\begin_inset Formula $r(t)$
\end_inset

 by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: r"

\end_inset

 and expressing 
\begin_inset Formula $\boldsymbol{J}$
\end_inset

 in terms of 
\begin_inset Formula $\rho(\boldsymbol{v},t$
\end_inset

) makes Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 a nonlinear integro partial differential equation.
 
\end_layout

\begin_layout Standard
It can either be solved numerically, e.g.
 by using the method of characteristics 
\begin_inset CommandInset citation
LatexCommand citep
key "DeKamps2003,DeKamps2013"

\end_inset

, or analyzed analytically in case of very simple neuron models.
 As a proof of principle, 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 compared numerical results from the theory against direct simulations of
 a population of uncoupled (no recurrent connections) LIF neurons demonstrating
 excellent agreement for large number of neurons 
\begin_inset Formula $\mathcal{O}(>10^{4})$
\end_inset

.
 The importance of the work by 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 comes from the fact that their method applies in general to any type of
 point neuron model.
 The macroscopic Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 describing the dynamics on the population level can be derived from the
 microscopic details of the neuron model without introducing any additional
 parameter.
 
\end_layout

\begin_layout Standard
To gain additional insight it is desirable to also study Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: continuity equation"

\end_inset

 analytically.
 One extensively used method to simplify Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: continuity equation"

\end_inset

 is the diffusion approximation.
 It replaces the synaptic current in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: neuron dynamics"

\end_inset

 by an average current plus an additional Gaussian white noise.
 The diffusion approximation can be understood as an approximation of the
 Poisson input in the limes of large input rates and small synaptic efficacies.
 The latter means that the post synaptic potential PSP induced by spike
 arrivals is small compared to the distance from the reset to the threshold
 potential.
 In other words, jumps of the membrane potential invoked by incoming spikes
 must be small.
 The strength of the noise and the average input current depend of the rate
 of the Poisson input and on the intrinsic parameters of the neuron model.
 In the diffusion approximation, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 reduces to a Fokker-Planck equation.
 This can be shown by describing the time evolution of the density by the
 Chapman-Kolmogorov equation which can be expanded in a Kramer-Moyals expansion
 
\begin_inset CommandInset citation
LatexCommand citep
key "Riksen1992"

\end_inset

.
 In case of Poisson input, the Kramers-Moyal expansion has infinite number
 of terms.
 Truncating it after the second order yields the diffusion approximation.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 used the diffusion approximation to derive the stationary average firing
 rates in a recurrently randomly connected network of LIF neurons, mimicking
 a cortical column.
 The network in the study consists of an excitatory and inhibitory population
 (EI-Network).
 The populations receive additional uncorrelated stationary excitatory input
 from the external surrounding of the network.
 This external input represents the global spontaneous ongoing activity
 observed in cortex which has typically low firing rates 
\begin_inset Formula $1$
\end_inset

-
\begin_inset Formula $5$
\end_inset

 Hz.
 The purely excitatory external input is motivated by the fact that excitatory
 pyramidal neurons tend to form longer axons compared to inhibitory inter
 neurons which connect more locally 
\begin_inset CommandInset citation
LatexCommand citep
key "Braitenberg2013"

\end_inset

.
 The stationary solution of the Fokker-Planck equation yields the stationary
 firing rate of the excitatory and inhibitory population for a given input
 rates 
\begin_inset CommandInset citation
LatexCommand citep
key "A.1953"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 showed that the equation for the stationary firing rage has a solution
 for which the average firing rate of the excitatory population matches
 the spontaneous activity of the external surrounding.
 This is desirable because neurons in the excitatory population are connected
 themselves to other cortical columns and the ongoing spontaneous activity
 is supposed to be global attractor.
 Finding the solution for which the output firing rate of the population
 in the stationary state matches the contribution to input firing from the
 same population is often referred to as self-consistent mean-field theory
 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

.
 Spontaneous activity is hypothesized to be a ground state of the brain.
 Compared to silent networks, a spontaneous active network has the advantage
 that it places neurons close to threshold, rather at their resting potential
 so that the network can respond faster to a stimulus.
 
\end_layout

\begin_layout Standard
The stability of the stationary state presented in 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 has been studied extensively in 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000,Brunel1999,Lindner2001"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 used linear stability analysis to study excursions of the population firing
 rate around the stationary firing rate.
 The made the ansatz 
\begin_inset Formula 
\begin{equation}
r(t)=r_{0}+r_{1}e^{\lambda t},
\end{equation}

\end_inset

where 
\begin_inset Formula $r_{0}$
\end_inset

 is the stationary firing rate, 
\begin_inset Formula $r_{1}$
\end_inset

 is amplitude of the modulation and 
\begin_inset Formula $\lambda$
\end_inset

 is complex number.
 Note that the complex notation is only used for convenience.
 In the end, one can only consider real part 
\begin_inset Formula $r(t)$
\end_inset

 to arrive at a physical solution
\begin_inset Formula 
\begin{equation}
\text{Re}r(t)=r_{0}+r_{1}e^{-\text{Re}(\lambda)\cdot t}\cos(\text{Im}(\lambda)\cdot t).
\end{equation}

\end_inset

The Fokker-Planck equation describing the dynamics of the network in the
 diffusion approximation is linear, i.e.
 it is sufficient to consider a sinusoidal input modulation.
 This is because any periodic function can expanded in a Fourier series
 and each frequency component of the Fourier series can be solved separately
 due to the linearity of the problem.
 
\end_layout

\begin_layout Standard
The amplitude of the modulation 
\begin_inset Formula $r_{1}$
\end_inset

 is assumed to be small compared the stationary firing rate so that it can
 be treated perturbatively 
\begin_inset CommandInset citation
LatexCommand citep
key "Knight2000a"

\end_inset

.
 If 
\begin_inset Formula $\text{Re}(\lambda)<0,$
\end_inset

 then the modulation will decay to zero over time and the network relaxes
 back to the stationary state.
 If 
\begin_inset Formula $\text{Re}(\lambda)>0$
\end_inset

, then the modulation will exponentially diverge and the stationary state
 loses its stability.
 Hence, 
\begin_inset Formula $\text{Re}(\lambda)=0$
\end_inset

 marks a transition from stable to unstable dynamics.
 If 
\begin_inset Formula $\text{Im}(\lambda)\neq0$
\end_inset

 at point of transition, then it is is called a Hopf bifurcation.
 It indicates the ability of the network to produce oscillations, i.e synchronize
d behavior, which is ubiquitously observed in cortex 
\begin_inset CommandInset citation
LatexCommand citep
key "Buzsaki2004"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 derived an first order approximation of the time dependent average firing
 rate of a sparsely randomly recurrently connected EI-Network.
 The derivation was based on the same simplifying assumptions made in 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

.
 Firstly, neurons receive an identical number of synaptic inputs from the
 local network and an identical number of synaptic inputs from the external
 surrounding.
 Relaxing this assumption, i.e.
 allowing for different number indegrees, results in broader distribution
 of firing rates but does impact the populations dynamics in qualitatively
 manner.
 Secondly, the synaptic current is approximated to be instantaneous.
 Despite the simplicity of the model, the derivation it is still quite involved.
 It boils down to solving an inhomogeneous partial differential equation
 with variable coefficients by separation of variables self-consistently.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 showed that the point where the stationary state loses stability marks
 the transition of the network into different dynamical regimes.
 Depending on the strength of external input, the balance between excitation
 and inhibition, and the time scale of the synaptic delay, the average firing
 rate of the populations can show oscillations in different frequency regimes.
 Independently of the global oscillations, the firing of individual neurons
 are still highly irregular.
 The work by 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 has been the first analytical study investigating the synchronization propertie
s of randomly recurrent spiking neural networks.
 
\end_layout

\begin_layout Standard
Several steps have been made to extend the population density methods to
 more complex neuron models.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Fourcaud2002"

\end_inset

 extended the work by 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 to include finite synaptic time scales.
 This introduces temporal correlations in the noise term, so that the white
 noise becomes colored noise.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Fourcaud2002"

\end_inset

 assumed that synaptic time scales are small compared to the membrane time
 scale so that the ratio between both can be used as an expansion parameter.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Apfaltrer2006"

\end_inset

 applied the population density method to LIF neurons connected via conductance
 based synapses.
 
\end_layout

\begin_layout Standard
In general, one can say that the difficulty with the problem scales drastically
 with the complexity of the neuron model.
 Instead of solving the partial differential directly 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand citep
key "Knight2000a"

\end_inset

 proposed a different method of solution.
 Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: J"

\end_inset

 can formally written as 
\begin_inset Formula 
\[
J=C\rho,
\]

\end_inset

where linear operator 
\begin_inset Formula $C$
\end_inset

 depends on the input rate 
\begin_inset Formula $\sigma$
\end_inset

.
 Note 
\begin_inset Formula $C$
\end_inset

 is a linear operator because Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: J_str"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: J_imp"

\end_inset

 only involve multiplication and integration both linear operations.
 Using Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: J"

\end_inset

, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 can be written as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{multline}
\frac{\partial\rho}{\partial t}=-Q(\sigma)\rho,\label{eq: rho operator}
\end{multline}

\end_inset

where 
\begin_inset Formula $Q=KC(\sigma)\rho$
\end_inset

 and 
\begin_inset Formula $K$
\end_inset

 is the familiar divergence operator.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Knight2000a"

\end_inset

 called 
\begin_inset Formula $Q$
\end_inset

 dynamical operator .
 For a specific input 
\begin_inset Formula $\sigma$
\end_inset

, the operator 
\begin_inset Formula $Q$
\end_inset

 has a set of eigenfunctions such that 
\begin_inset Formula 
\begin{equation}
Q\phi_{n}=\lambda_{n}\phi_{n}\label{eq: phi_n}
\end{equation}

\end_inset

Note that the dynamical operator is not Hermitian (self-adjoint), i.e.
 the eigenvalues 
\begin_inset Formula $\lambda_{n}$
\end_inset

 are in general complex and the eigenfunctions 
\begin_inset Formula $\phi_{n}$
\end_inset

 are not orthogonal.
 Taking the complex conjugate of the above equation and using that 
\begin_inset Formula $Q$
\end_inset

 is real, we find 
\begin_inset Formula 
\[
Q\phi_{n}^{*}=\lambda_{n}^{*}\phi_{n}^{*}.
\]

\end_inset

Hence, we see that eigenvalues and eigenfunctions come in complex conjugate
 pairs.
 We introduce the notation 
\begin_inset Formula $\phi_{-n}=\phi_{n}^{*}$
\end_inset

.
 Defining a inner product as a bilinear integral over state space 
\begin_inset Formula 
\begin{equation}
(u,w)=\int d\boldsymbol{v}\,u(\boldsymbol{v})^{*}w(\boldsymbol{v}),
\end{equation}

\end_inset

allows us to define the adjoint operator of 
\begin_inset Formula $Q^{\dagger}$
\end_inset

 as
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
(u,Qv)=(Q^{\dagger}u,v).\label{eq: Q adjoint}
\end{equation}

\end_inset

An operator and its adjoint operator share the same set of eigenvalues.
 The eigenfunctions 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 of the adjoint operator 
\begin_inset Formula $O^{\dagger}$
\end_inset

 are given by 
\begin_inset Formula 
\begin{equation}
Q^{\dagger}\tilde{\phi}_{n}=\lambda_{n}^{*}\tilde{\phi}_{n}
\end{equation}

\end_inset

where the labeling is chosen such that the label 
\begin_inset Formula $n$
\end_inset

 is associated with the complex conjugate eigenvalue 
\begin_inset Formula $\lambda_{n}$
\end_inset

 defined in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: phi_n"

\end_inset

.
 Using 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: Q adjoint"

\end_inset

, the following relation can be derived 
\begin_inset Formula 
\begin{equation}
(\lambda_{n}-\lambda_{m})(\tilde{\phi}_{m},\phi_{n})=0.
\end{equation}

\end_inset

Since one or the other factor must vanish, we see that set of eigenfunctions
 and adjoint eigenfunctions form biorthogonal sets.
 Using proper normalization, we can write 
\begin_inset Formula 
\begin{equation}
(\tilde{\phi}_{m},\phi_{n})=\delta_{nm}\label{eq: orthogonality}
\end{equation}

\end_inset


\begin_inset CommandInset citation
LatexCommand citep
key "Knight2000a"

\end_inset

 do not provide a proof if the eigenfunctions of the operator 
\begin_inset Formula $Q$
\end_inset

 exist in general, nor if they form a complete basis.
 However, if we assume they do, then we can expand the density 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 in this eigenbasis 
\begin_inset Formula 
\begin{equation}
\rho(\boldsymbol{v},t)=\sum_{n}c_{n}(t)\phi_{n},\label{eq: rho expansion}
\end{equation}

\end_inset

where 
\begin_inset Formula $c_{n}(t)$
\end_inset

 are the weighting coefficients of the individual modes and 
\begin_inset Formula $n$
\end_inset

 runs over positive and negative integers.
 Using bi-orthogonality 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: orthogonality"

\end_inset

, the initial values 
\begin_inset Formula $c_{n}(0)$
\end_inset

 for the weighting coefficients are given by 
\begin_inset Formula 
\[
c_{n}(0)=(\tilde{\phi}_{n},\rho(\boldsymbol{v},0)).
\]

\end_inset

Inserting the expansion into 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho expansion"

\end_inset

, yields a system of ordinary differential equations (ODE) for the coefficients
 
\begin_inset Formula $c_{n}(t)$
\end_inset

.
 The hope is that a small subset of eigenfunctions is sufficient for an
 adequate description of the network dynamics.
 This dimensionality reduction could provide a computational efficient tool
 to simulate 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho operator"

\end_inset

 on the one hand, and provide better understanding about the network dynamics
 on the other hand.
 
\end_layout

\begin_layout Standard
One crucial part to note is that the operator 
\begin_inset Formula $Q$
\end_inset

 depends on the input rate 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

 which itself depends on time.
 Hence, the eigenbasis of 
\begin_inset Formula $Q$
\end_inset

 changes with time which is referred to as a moving basis 
\begin_inset CommandInset citation
LatexCommand citet
key "Knight2000a"

\end_inset

.
 It is therefore necessary to know how the eigenvalues and eigenfunctions
 change as a function of the input rate.
 Finding an analytic expression of the eigenvalues and eigenfunctions is
 difficult and has so fare only been done for the perfect integrate-and-fire
 neuron with additional constant leak term 
\begin_inset CommandInset citation
LatexCommand citet
key "Mattia2002"

\end_inset

 and the leaky integrate-and-fire neuron 
\begin_inset CommandInset citation
LatexCommand citet
key "Brunel2000"

\end_inset

.
 Both derivation where carried out in the diffusion approximation.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2002"

\end_inset

 presented a way to include changes in the input rate due to recurrent connectio
ns in a self-consistent manner.
 As proof of principle, they showed in the subsequent work 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2004"

\end_inset

 that theory is capable of predicting population dynamics of randomly recurrent
 connected EI-Network.
 
\end_layout

\begin_layout Standard
So fare it is not known if eigenfunctions can be found for regimes where
 the diffusion approximation does not apply.
 Furthermore, more complex models including synaptic dynamics or adaptation
 have not been studied so far.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Biggio2017"

\end_inset

 developed a method to study a general integrate-and-fire model with exponential
 decaying synaptic currents.
 Their method reduces the inherently two dimension problem to a one dimensional.
 A sound mathematical motivation for this last step dimensionality reduction
 is so far lacking.
 However, theoretical predicted averaging firing rates show excellent agreement
 to simulation of PIF neurons.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "progress_report"
options "plain"

\end_inset


\end_layout

\end_inset


\begin_inset ERT
status open

\begin_layout Plain Layout


\backslash
printbibliography
\end_layout

\end_inset


\end_layout

\end_body
\end_document
