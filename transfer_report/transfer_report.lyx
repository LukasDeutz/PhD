#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine natbib
\cite_engine_type numerical
\biblio_style plainnat
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Transfer Report: Spectral analysis of the dynamics of neuronal networks
 using population-density techniques 
\end_layout

\begin_layout Author
Lukas Deutz
\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
Understanding the behavior of large recurrent networks of spiking neurons
 is one of the major challenges in computational neuroscience.
 A first step in understanding the dynamical properties of such networks
 is to determine the existence, location and stability of equilibria and
 how they depend on the connectivity profile and single neuron properties.
 A network may have different fixed points each associated with a different
 dynamical behavior, like asynchronous irregular spiking, global oscillatory
 or bursting activity all ubiquitously observed experimentally.
 To better understand how these different dynamical regimes emerge, and
 how the brain can transition between them 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
by e.g.
 changing the external drive to network or the interplay between excitation
 and inhibition within the network 
\end_layout

\end_inset

 is an important step towards understanding if and how these different states
 of activity can be used to explain different brain functions.
 
\end_layout

\begin_layout Standard
There are two complementary approaches to study the dynamics of neuronal
 networks which are referred to as computational and theoretical neuroscience.
 In computational neuroscience, the most commonly used method is to simulate
 neural circuits, referred to as direct simulations.
 This approach simulates individual neurons and all the interactions between
 them on a microscopic level.
 This has the advantage that observables of interest like spike times, firing
 rate statistics or correlation measures can be accessed on the level of
 single neurons.
 Before a neuronal network can be simulated, two questions need to be answered:
 
\end_layout

\begin_layout Enumerate
Which neuron model and synapse model should be used? 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Discuss what informs this decsion
\end_layout

\end_inset

 
\end_layout

\begin_layout Enumerate
What is the connectivity structure within the network? 
\end_layout

\begin_layout Standard
Choosing a neuron model is often a trade off between computational demand
 and biological realism or explanatory power.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
However, sometimes it is also advisable to choose a simpler model to narrow
 down the possible causes which could explain a certain observation of interest.
\end_layout

\end_inset

 To address the second question, it is common to think about the neuronal
 network in terms of different populations which represent neurons of a
 similar type, or with a similar function in a specific brain area of interest.
 The type of a neuron can be characterized by its morphology, its electrophysiol
ogical properties, or functional properties (e.g.
 receptivity to a specific stimulus feature).
 Neurons within a population are usually modeled by the same neuron model
 and considered to be statistical identical, i.e.
 they are equally likely to form connections with neurons in other populations.
 In this setting, one is usually not interested in the dynamical features
 of individual neurons, but instead in the dynamical features of the individual
 populations which can be characterized by e.g.
 the average population firing rate, interspike interval statistics (ISI),
 or the statistics of pairwise or higher order correlations.
 
\end_layout

\begin_layout Standard
The idea of approximating groups of neurons by homogeneous populations is
 often utilized in theoretical neuroscience as method to reduce the large
 number of degrees of freedom one is faced with in neuronal networks.
 From a mathematical viewpoint, describing how the network evolves in time
 boils down to solving a large system of coupled differential equation.
 Due to the non linearity of the neuron dynamics and their complex interactions,
 there is little hope of deriving an exact solution.
 Hence, approximation schemes are needed.
 A commonly used approach in theoretical neuroscience is mean-field theory
 which relies on the previously described homogeneity assumption.
 The main idea of mean-field theory is to decouple the system of differential
 equations which describes all neurons individually.
 This can be achieved by replacing the synaptic input to each neuron by
 the population-averaged input also referred to as the mean-field.
 If neurons belonging to the same population are assumed to be statistical
 identical, then they can all be described by the same the mean-field equation.
 Hence, mean-field theory reduces the high dimensional initial problem to
 a system of equations with size equal to number of populations in the network.
 Because neurons are recurrently connected, the synaptic input at a given
 time has an impact on the synaptic input at later time.
 Therefore, mean-field equations need to be solved self-consistently, such
 that the synaptic input a neuron receives on average produces an output
 which is consistent with the initial input.
 
\end_layout

\begin_layout Standard
The reminder of this report is structured as follows.
 First, we give an overview of the literature relating to population density
 methods, the diffusion approximation and the method of spectral decomposition
 and how these techniques are applied in a neuroscientific context.
 Then, we will formulate a preliminary research questions followed by a
 more detailed research proposal and present preliminary results towards
 answering these questions.
 Finally, we outline how to continue the project.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Finish sentence
\end_layout

\end_inset


\end_layout

\begin_layout Section
Literature Review 
\end_layout

\begin_layout Subsection
The population density method
\begin_inset CommandInset label
LatexCommand label
name "subsec:The-population-density"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Enumerate
Introduction
\end_layout

\begin_deeper
\begin_layout Itemize
Direct simulation vs population density
\end_layout

\begin_layout Itemize
Neuron models
\end_layout

\begin_layout Itemize
Integrate-and-fire
\end_layout

\begin_layout Itemize
Mean-field models
\end_layout

\end_deeper
\begin_layout Enumerate
Jump processes 
\end_layout

\begin_layout Enumerate
Diffusion approximation 
\end_layout

\begin_layout Enumerate
Fokker-Planck equation 
\end_layout

\begin_layout Enumerate
Spectral decomposition 
\end_layout

\begin_layout Enumerate
One dimensional integrate-and-fire
\end_layout

\begin_layout Enumerate
Perfect integrate-and-fire
\end_layout

\begin_layout Enumerate
Leaky integrate-and-fire
\end_layout

\begin_layout Enumerate
Exponential integrate-and-fire 
\end_layout

\begin_layout Enumerate
Numerical Algorithm 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Population density methods (PDMs) were introduced to neuroscience simultaneously
 by several authors at the end of the last century 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag,Knight2000a,Nykamp2000"

\end_inset

.
 PDMs make use of the fact that the brain usually encodes information by
 group of neurons rather than by single neurons 
\begin_inset CommandInset citation
LatexCommand cite
key "Mountcastle1979"

\end_inset

.
 Optical imaging studies showed that visual cortex is tiled by patches of
 neurons each responding to different stimulus features.
 Each of the patches contains in order of 
\begin_inset Formula $\mathcal{O}(10^{4})$
\end_inset

 neurons 
\begin_inset CommandInset citation
LatexCommand cite
key "Blasdel1992a,Blasdel1992b"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citet
key "Omurtag"

\end_inset

 used this finding as an basis to model a network of interacting neurons
 using a statistical description on the level of populations.
 To arrive at such description, several simplifying assumptions need to
 be made.
 
\end_layout

\begin_layout Standard
The PDM presented in 
\begin_inset CommandInset citation
LatexCommand citet
key "Omurtag"

\end_inset

 can be applied in principle to any point neuron model.
 Point neurons approximate the entire neuron by single compartment, i.e.
 the dentritric tree is collapsed to a single point.
 Hence, it can not account for dynamical features related to the specific
 morphology of a neuron.
 The state of an arbitrary point neuron is determined by a set of variables
 
\begin_inset Formula $\boldsymbol{v}=(v_{1},v_{2},\ldots,v_{n})$
\end_inset

 usually including the membrane potential.
 The time evolution of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 is described by first order kinetics 
\begin_inset Formula 
\begin{equation}
\frac{d\boldsymbol{v}}{dt}=\boldsymbol{F}(\boldsymbol{v})+\boldsymbol{S}(\boldsymbol{v},\boldsymbol{s}(t)),\label{eq: neuron dynamics}
\end{equation}

\end_inset

where the vector field 
\begin_inset Formula $\boldsymbol{F}(\boldsymbol{v})$
\end_inset

 describes the time evolution of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 due to the deterministic neuron dynamics and 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},\boldsymbol{s}(t))$
\end_inset

 models the incoming synaptic current invoked by synaptic arrivals 
\begin_inset Formula $\boldsymbol{s}(t)$
\end_inset

.
 A point neuron can be viewed as an input output-box.
 It receives excitatory and inhibitory inputs 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},s(t))$
\end_inset

 which arrive from other neurons by their associated synapses.
 These inputs are modeled either as injected currents or as a change in
 conductance.
 Current based synapses are simpler compared to conductance based models
 because they produce a current which is independent of the state of the
 neuron.
 Hence, multiple synaptic inputs can be summed linearly.
 Conductance based synapses provide a biological more realistic description
 
\begin_inset CommandInset citation
LatexCommand cite
key "Tuckwel1983"

\end_inset

.
 They are state dependent because the synaptic current produced by a conductance
 change depends on the difference between the membrane potential and the
 reversal potential of the respective synapse which makes the summation
 of synaptic inputs nonlinear.
 If a neuron receives sufficiently strong excitatory input such that the
 membrane potential exceeds a certain threshold value, then the neuron will
 generate an action potential (spike), followed by a reset mechanism and
 a refractory period.
 The output spike is then fed back into the network and contributes to the
 input to other neurons.
 
\end_layout

\begin_layout Standard
To give an example, for a Hodgkin-Huxley (H-H) type model 
\begin_inset CommandInset citation
LatexCommand cite
key "Hodgkin1952"

\end_inset

 in standard notation 
\begin_inset CommandInset citation
LatexCommand cite
key "Keener1998"

\end_inset

 with conductance based synapses Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

 becomes 
\begin_inset Formula 
\begin{align}
\frac{dV}{dt} & =\frac{1}{C}\left(g_{L}(V_{L}+V)+g_{n}m^{3}h(V_{N}-V)+g_{K}n^{4}(V_{K}-V)\right)+\frac{1}{C}\sum_{i=1}^{N}g_{i}(t)(V_{i}^{(s)}-V)\nonumber \\
\frac{dm}{dt} & =\frac{1}{\tau_{m}(V)}(m_{\infty}(V)-m),\nonumber \\
\frac{dh}{dt} & =\frac{1}{\tau_{h}(V)}(h_{\infty}(V)-h),\nonumber \\
\frac{dn}{dt} & =\frac{1}{\tau_{n}(V)}(n_{\infty}(V)-n).\label{eq: H-H}
\end{align}

\end_inset

The state of the neuron is determined by the set of variables 
\begin_inset Formula $\boldsymbol{v}=(V,m,h,n)$
\end_inset

, where 
\begin_inset Formula $V$
\end_inset

 is the membrane potential, 
\begin_inset Formula $m$
\end_inset

 governs the sodium activation, 
\begin_inset Formula $h$
\end_inset

 sodium inactivation, and 
\begin_inset Formula $n$
\end_inset

 the potassium activation.
 Hence, 
\begin_inset Formula $\boldsymbol{F}(\boldsymbol{v})$
\end_inset

 is four dimensional vector with 
\begin_inset Formula 
\begin{equation}
F_{1}(\boldsymbol{v})=\frac{1}{C}\left(g_{L}(V_{L}+V)+g_{n}m^{3}h(V_{N}-V)+g_{K}n^{4}(V_{K}-V)\right),
\end{equation}

\end_inset

and 
\begin_inset Formula $F_{2},F_{3}$
\end_inset

 and 
\begin_inset Formula $F_{4}$
\end_inset

 given by the last three lines in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

.
 Note that the synaptic current 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},\boldsymbol{s}(t))$
\end_inset

 only causes changes in the membrane potential.
 Hence, the only entry in 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},s(t))$
\end_inset

 which is nonzero is the first one 
\begin_inset Formula $S_{1}$
\end_inset

 which we define as 
\begin_inset Formula 
\begin{equation}
I(V,s(t))=\frac{1}{C}\sum_{j=1}^{K}g_{j}^{(s)}(t)(V_{j}^{(s)}-V),\label{eq: S conductance}
\end{equation}

\end_inset

where 
\begin_inset Formula $K$
\end_inset

 is the total number afferent connections which is depicted in Fig and 
\begin_inset Formula $V_{j}^{(s)}$
\end_inset

 is the reversal potential associated with synapse 
\begin_inset Formula $j$
\end_inset

.
 For the leaky integrate-and-fire neuron model 
\begin_inset CommandInset citation
LatexCommand citep
key "Lapicque1907,Stein1967"

\end_inset

, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

 simplifies to 
\begin_inset Formula 
\begin{equation}
\frac{dV}{dt}=-\frac{g_{L}}{C}(V-V_{L})+\frac{1}{C}\sum_{j=1}^{N}g_{j}(t)(V_{j}^{(s)}-V),
\end{equation}

\end_inset

Note that we considered only a single synapse type in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: S conductance"

\end_inset

 for simplicity.
 The synaptic conductance 
\begin_inset Formula $g_{i}^{(s)}(t)$
\end_inset

 is zero in absence of synaptic arrivals and becomes only nonzero for small
 time window after a spike has arrived.
 We represent all spike arrivals at the 
\begin_inset Formula $j$
\end_inset

th synapse by a sum of delta distributions
\begin_inset Formula 
\begin{equation}
s_{j}(t)=\sum_{n}\delta(t-t_{n}^{(j)}),\label{eq: s_i(t)}
\end{equation}

\end_inset

where 
\begin_inset Formula $t_{n}^{(j)}$
\end_inset

 is the time of the 
\begin_inset Formula $n$
\end_inset

th spike arrival.
 Assuming that synaptic time scales are short compared to the membrane time
 constant, 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Omurtag"

\end_inset


\end_layout

\end_inset

 approximate the conductance changes caused by arriving spike to be instantaneou
s 
\begin_inset Formula 
\begin{equation}
g_{j}(t)=\hat{g}_{j}\sum_{n}\delta(t-t_{n}^{(j)}).\label{eq: g_i(t)}
\end{equation}

\end_inset

This approximation is referred to as delta synapses.
 The parameter 
\begin_inset Formula $\hat{g}_{j}$
\end_inset

 represent the integrated countenance over time course of the synaptic event.
 If conductance changes are instantaneous, then the membrane potential makes
 a jump of 
\begin_inset Formula $\hat{g}_{j}(V_{s}-V(t))/C$
\end_inset

 whenever a spike arrives.
 
\end_layout

\begin_layout Standard
If we would subsitute Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: s_i(t)"

\end_inset

 into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

 and integrate the r.h.s., then we obtain the deterministic time evolution
 of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 for a given synaptic input 
\begin_inset Formula $\boldsymbol{s}(t)=\{s_{1}(t),s_{2}(t),\ldots,s_{N}(t)\}$
\end_inset

.
 However, 
\begin_inset Formula $\boldsymbol{s}(t)$
\end_inset

 is unknown unless we simulate all neurons in the network individually.
 
\end_layout

\begin_layout Standard
Since, we are dealing with a biological system which is subject to noise
 our goal is to approximate 
\begin_inset Formula $s_{j}(t)$
\end_inset

 by stochastic process.
 The membrane potential of a neuron is subject to two sources of noise:
 one intrinsic to the neuron, associated with stochastic nature of the mechanism
 controlling the release of neurotransmitter, the opening of ion channels
 and so forth.
 The other is extrinsic, arising from the apparently random arrival of individua
l spikes 
\begin_inset CommandInset citation
LatexCommand citet
key "Burkitt2006"

\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Mainen1995"

\end_inset


\end_layout

\end_inset

 showed in vitro, that neurons in rat cortex are able to reliably respond
 to an identical fluctuating input current injected directly into the cell
 body.
 Over several trials, neurons emitted spikes at roughly identical points
 in time with small deviations compared to the average length of interspike
 intervals.
 This suggests that intrinsic noise is insignificant compared to extrinsic
 noise associated with the stochastic synaptic input.
 
\end_layout

\begin_layout Standard
Consequently, the dominant source of randomness is assumed to be the stochastic
 arrival of spikes.
 These are usually approximated by a renewal process, i.e.
 interspike intervals (ISI) are identical and independently distributed
 
\begin_inset CommandInset citation
LatexCommand cite
key "Burkitt2006,Burkitt2006a"

\end_inset

.
 We introduce the instantaneous firing rate 
\begin_inset Formula $r_{j}(t)$
\end_inset

 which can be used to calculate the number of spikes 
\begin_inset Formula $N_{j}(t,t+\delta t)$
\end_inset

 in a small time interval 
\begin_inset Formula $[t,t+\delta t]$
\end_inset

 in the limit 
\begin_inset Formula $\delta t\rightarrow0$
\end_inset


\begin_inset Formula 
\begin{equation}
\lim_{\delta t\rightarrow0}N_{j}(t,t+\delta t)=\lim_{\delta t\rightarrow0}r_{j}(t)\delta t.
\end{equation}

\end_inset

Note that the spike trains which arrive at different synapses of a neuron
 are in general not independent 
\begin_inset CommandInset citation
LatexCommand citep
key "Poulet2008"

\end_inset

.
 Indeed, input correlations are an inevitable consequence of two neurons
 being part of the same network, and therefore likely to share some common
 synaptic input 
\begin_inset CommandInset citation
LatexCommand citep
key "Ostojic"

\end_inset

.
 However, if the network is sparsely connected, i.e.
 the number of indegrees is small compared to the network size, then the
 number of common inputs can assumed to be small.
 Furthermore, it has been shown that in recurrently connected networks inhibitio
n decorrelates neural activity 
\begin_inset CommandInset citation
LatexCommand citep
key "Tetzlaff2012,Renart2010"

\end_inset

.
 Excitation and inhibition tends to balance each other such that the membrane
 potential of individual neurons saturates below threshold.
 Threshold crossings in the balanced state are caused by random fluctuations
 in the input (noise driven regime) which lead to asynchronous irregular
 firing (AI), also referred to as spontaneous activity 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

.
 In such a setting, assuming the input at different synapses to be independent
 can be regarded as a zeroth order approximation.
 If input correlations are assumed to be small, then network dynamics can
 be studied perturbatively 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindner2001"

\end_inset

.
 For the remainder of this report, we assume synaptic inputs to be independent.
 
\end_layout

\begin_layout Standard
For an arbitrary neuron 
\begin_inset Formula $i$
\end_inset

, the synaptic input is given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: S conductance"

\end_inset

 
\begin_inset Formula 
\begin{equation}
I_{i}(V,s(t))=\frac{1}{C}\sum_{j=1}^{K_{i}}g_{ij}^{(s)}(t)(V_{i}^{(s)}-V),
\end{equation}

\end_inset

where 
\begin_inset Formula $g_{ij}^{(s)}(t)$
\end_inset

 describes the time evolution of the conductance associated with the synapse
 which connects neuron 
\begin_inset Formula $j$
\end_inset

 to 
\begin_inset Formula $i$
\end_inset

 
\begin_inset Formula 
\begin{equation}
g_{ij}(t)=\hat{g}_{ij}\sum_{n}\delta(t-t_{n}^{(j)}).\label{eq: g_ij(t)}
\end{equation}

\end_inset

To arrive at a description on the population level, 
\begin_inset CommandInset citation
LatexCommand cite
key "Omurtag"

\end_inset

 make a mean-field ansatz, i.e.
 they replace all single neuron quantities by their population averages
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\hat{g}_{ij} & \rightarrow\hat{g}=\bigl\langle\hat{g}_{ij}\bigr\rangle,\nonumber \\
V_{ij}^{(s)} & \rightarrow V_{s}=\bigl\langle V_{ij}^{(s)}\bigr\rangle\nonumber \\
K_{i} & \rightarrow K=\bigl\langle K_{i}\bigr\rangle,\nonumber \\
r_{i}(t) & \rightarrow r(t)=\bigl\langle r_{i}\bigr\rangle.
\end{align}

\end_inset

This simplifies Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: g_ij(t)"

\end_inset

 to
\begin_inset Formula 
\begin{equation}
g_{i}(t)=\hat{g}\sum_{n=1}^{K}s_{i}(t).
\end{equation}

\end_inset

The sum is a superposition of independent renewal processes all having the
 same firing rate 
\begin_inset Formula $r(t)$
\end_inset

.
 It can be well approximated by a Poisson process with firing rate 
\begin_inset Formula $Kr(t)$
\end_inset

 due to the pooling property of independent renewal processes 
\begin_inset CommandInset citation
LatexCommand citep
key "Gallager2011"

\end_inset

.
 Hence, on average each neuron feels the instantaneous firing rate 
\begin_inset Formula 
\begin{equation}
\sigma(t)=\sigma_{0}(t)+Kr(t),\label{eq: input rate}
\end{equation}

\end_inset

where 
\begin_inset Formula $\sigma_{0}(t)$
\end_inset

 is the average firing rate associated with connections from the external
 surrounding of the network.
 The mean-field ansatz is motivated by the fact that we are only interested
 in predicting the average behavior of the entire population.
 In the limit of large networks, the population dynamics are expected to
 be only mildly affected by the neglected heterogeneity in the connectivity.
 Indeed, 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997a"

\end_inset


\end_layout

\end_inset

 simulated a network with variable numbers of indegrees and stochastic synapses
 and showed that the PDM still reliably predicts the stationary firing rates
 for the individual populations in the network.
 
\end_layout

\begin_layout Standard
Having derived Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

, we introduce the probability density function 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 which how many neurons in the population are expected to be found in the
 state space volume 
\begin_inset Formula $[\boldsymbol{v},\boldsymbol{v}+d\boldsymbol{v}]$
\end_inset

 at given point in time.
 How 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 changes over time in a small state space volume 
\begin_inset Formula $D$
\end_inset

 is determined by the equation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\partial}{\partial t}\int_{D}\rho\,d\boldsymbol{v}=-\int_{\partial D}\rho\,\boldsymbol{F}(\boldsymbol{v})\cdot\boldsymbol{n}-\int_{D}d\boldsymbol{v}\left(\frac{\delta\rho}{\partial t}\right)^{-}+\int_{D}d\boldsymbol{v}\left(\frac{\delta\rho}{\partial t}\right)^{+}\label{eq: integral density}
\end{equation}

\end_inset

The first term on the r.h.s.
 represents the probability flow out of the surface area of 
\begin_inset Formula $D$
\end_inset

 due to the deterministic neuron dynamics.
 The next two terms represent changes in 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 due to synaptic arrivals.
 If 
\begin_inset Formula $D$
\end_inset

 is taken small enough that any neuron receiving a spike leaves 
\begin_inset Formula $D$
\end_inset

, then 
\begin_inset Formula 
\begin{equation}
\left(\frac{\delta\rho}{\partial t}\right)^{-}=\sigma(t)\rho(\boldsymbol{v},t).\label{eq: jump out}
\end{equation}

\end_inset

To determine the fraction of neurons which enter the volume 
\begin_inset Formula $D$
\end_inset

, we need to identify those regions in the state space 
\begin_inset Formula $D'(D)$
\end_inset

 which end up in 
\begin_inset Formula $D$
\end_inset

 after a synaptic arrival.
 Because synaptic arrivals only affect the membrane potential, we need to
 solve
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
V & =V''+h(V'-V_{s})\Leftrightarrow V'(V)=\frac{V+hV_{s}}{1+h}
\end{align}

\end_inset

where 
\begin_inset Formula $h=\hat{g}/C$
\end_inset

 is called synaptic efficacy.
 
\begin_inset Formula 
\begin{align}
\int_{D}d\boldsymbol{v}\left(\frac{\delta\rho}{\partial t}\right)^{+} & =\sigma(t)\int_{D'}d\boldsymbol{v}'\rho(\boldsymbol{v}')\nonumber \\
 & =\sigma(t)\int_{D}d\boldsymbol{v}\rho(\boldsymbol{v}'(\boldsymbol{v}))\frac{\partial\boldsymbol{v}'}{\partial\boldsymbol{v}}d\boldsymbol{v}\label{eq: jump in}
\end{align}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: jump out"

\end_inset

 and Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: jump in"

\end_inset

 into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integral density"

\end_inset

, using the theorem of Gauss one arrives at 
\begin_inset Formula 
\begin{equation}
\frac{\partial}{\partial t}\int_{D}\rho\,d\boldsymbol{v}=\int d\boldsymbol{v}\left\{ \frac{\partial}{\partial\boldsymbol{v}}(\rho\,\boldsymbol{F}(\boldsymbol{v}))-\sigma(t)\left(\rho(\boldsymbol{v},t)-\rho(\boldsymbol{v}'(\boldsymbol{v}))\frac{\partial\boldsymbol{v}'}{\partial\boldsymbol{v}}\right)\right\} 
\end{equation}

\end_inset

Because 
\begin_inset Formula $D$
\end_inset

 is small but otherwise arbitrary, we arrive at the partial differential
 equation (PDE)
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho}{\partial t}=-\frac{\partial}{\partial\boldsymbol{v}}\left(F(\boldsymbol{v})\rho\right)-\sigma(t)\times\left\{ \rho(\boldsymbol{v},t)-\rho(\boldsymbol{v}'(\boldsymbol{v}),t)\frac{\partial\boldsymbol{v}'}{\partial\boldsymbol{v}}\right\} .\label{eq: PDE}
\end{equation}

\end_inset

The above equation can be written as a continuity equation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=-\frac{\partial}{\partial\boldsymbol{v}}\boldsymbol{J}(\boldsymbol{v},t),\label{eq: continuity equation}
\end{equation}

\end_inset

where 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 is probability current which determines the flow of probability at point
 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 at a given time 
\begin_inset Formula $t$
\end_inset

.
 The probability flux has two contributions,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}=\boldsymbol{J}_{F}+\boldsymbol{J}_{\text{s}},\label{eq: J}
\end{equation}

\end_inset

one corresponds to the determinstic neuron dynamics
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}_{F}=\boldsymbol{F}(\boldsymbol{v})\rho(\boldsymbol{v},t),\label{eq: J_str}
\end{equation}

\end_inset

and the other corresponds the synaptic input, and therefore depends on the
 input rate given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}_{\text{s}}=-\sigma(t)\int_{V}^{V'(V)}\boldsymbol{e}_{V}\rho(W,v_{2},\ldots)dW.\label{eq: J_imp}
\end{equation}

\end_inset

To determine the firing rate 
\begin_inset Formula $r(t)$
\end_inset

 of the population, one needs to define a threshold value 
\begin_inset Formula $V=V_{\theta}$
\end_inset

 for the the membrane potential and construct a Poincare surface at this
 value.
 The firing rate 
\begin_inset Formula $r(t)$
\end_inset

 is given by the probability flux which goes through this surface at time
 
\begin_inset Formula $t$
\end_inset

.
 Hence, the we can express 
\begin_inset Formula $r(t)$
\end_inset

 as a functional of 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

: 
\begin_inset Formula 
\begin{equation}
r(t)=R[\boldsymbol{J}(\boldsymbol{v},t)]\label{eq: r}
\end{equation}

\end_inset

To ensure conservation of probability, the probability which passes the
 threshold needs to be reinserted at the reset potential 
\begin_inset Formula $V_{r}$
\end_inset

.
 This can be modeled by a introducing an absorbing boundary at the threshold.
 The crucial point is that 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 depends on 
\begin_inset Formula $\sigma(t)$
\end_inset

, and therefore on 
\begin_inset Formula $r(t)$
\end_inset

 due to Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

.
 Replacing 
\begin_inset Formula $r(t)$
\end_inset

 by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: r"

\end_inset

 and expressing 
\begin_inset Formula $\boldsymbol{J}$
\end_inset

 in terms of 
\begin_inset Formula $\rho(\boldsymbol{v},t$
\end_inset

) makes Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 a nonlinear integro partial differential equation.
 It can for example be solved by using the method of characteristics 
\begin_inset CommandInset citation
LatexCommand citep
key "DeKamps2003,DeKamps2013"

\end_inset

.
 As a proof of principle, 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset


\end_layout

\end_inset

 compared numerical results from the theory against direct simulations of
 a population of uncoupled (no recurrent connections) LIF neurons demonstrating
 excellent agreement for a large enough population 
\begin_inset Formula $\mathcal{O}(>10^{4})$
\end_inset

.
 
\end_layout

\begin_layout Standard
The importance of the work by 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset


\end_layout

\end_inset

 comes from the fact that their method can be in principle applied to any
 type of point neuron model.
 The macroscopic Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 for the dynamics on the population level can be derived from the microscopic
 details of the neuron model without introducing any additional parameter.
 It can be generalized to networks with multiple populations each described
 by a single density function.
 Synaptic delays can be included into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: r"

\end_inset

 to mimic a spatial arrangement of the populations within the network.
 
\end_layout

\begin_layout Standard
PDMs can not model synaptic plasticity, because all heterogeneity of the
 connectivity needs to be averaged out to arrive at a low dimensional descriptio
n on the level of populations.
 Nor can they be used to measure correlations between the activity of individual
 neurons because spike times are modeled as independent Poisson processes.
 
\end_layout

\begin_layout Standard
In theoretical neuroscience, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PDE"

\end_inset

 has been studied subsequently for more and more complex integrate-and-fire
 neurons 
\begin_inset CommandInset citation
LatexCommand cite
key "Amit1997,Brunel2000,Fourcaud2002,Fourcaud-Trocme2003,Brunel2003"

\end_inset

.
 All these studies are based on the diffusion approximation which we will
 introduce in the next section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Diffusion-approximation"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Diffusion approximation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Diffusion-approximation"

\end_inset


\end_layout

\begin_layout Standard
The diffusion approximation replaces the Poisson process represented by
 the second term in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PDE"

\end_inset

 by a diffusion advection process.
 The diffusion and drift coefficients can be derived by describing the time
 evolution of the probability density by the Chapman-Kolmogorov equation
 and expanding it in a Kramer-Moyals expansion 
\begin_inset CommandInset citation
LatexCommand citep
key "Riksen1992"

\end_inset

.
 For a Poisson process, the Kramers-Moyal expansion has infinitely many
 terms.
 Truncating it after the second order yields the diffusion approximation.
 We will illustrate how the diffusion approximation comes about for a general
 integrate-and-fire neuron model.
\end_layout

\begin_layout Standard
The state of an integrate-and-fire neuron is only described by the membrane
 potential 
\begin_inset Formula $V$
\end_inset

 which drastically simplifies the analysis if e.g.
 compared to the four dimensional H-H type model introduced in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

.
 Despite their simplicity, they are still able to capture important dynamical
 features observed on a single neuron level, or in a network context 
\begin_inset CommandInset citation
LatexCommand citep
key "Bernander1991"

\end_inset

.
 One of most commonly used point neuron models is leaky integrate-and-fire
 neuron 
\begin_inset CommandInset citation
LatexCommand citep
key "Lapicque1907,Stein1967"

\end_inset

 (LIF).
 It describes the subthreshold dynamics of the membrane potential which
 can be modeled by a RC circuit
\begin_inset Formula 
\begin{equation}
C\frac{dV}{dt}=-g_{L}(V-V_{L})+I_{\text{s}}(t),\label{eq: LIF}
\end{equation}

\end_inset

where 
\begin_inset Formula $I_{s}(t)$
\end_inset

 is the synaptic input current.
 The LIF neuron is not capable of modeling the generation of an action potential
 which needs to be included by introducing an artificial threshold 
\begin_inset Formula $V_{\text{th}}$
\end_inset

.
 If the membrane potential of the neuron exceeds 
\begin_inset Formula $V_{\text{th}}$
\end_inset

, a spike is emitted and the membrane potential is reset to a reset value
 
\begin_inset Formula $V_{\text{r}}$
\end_inset

.
 Other examples of integrate-and-fire models are the quadratic integrate-and-fir
e (QIF) 
\begin_inset CommandInset citation
LatexCommand citep
key "Ermentrout1996"

\end_inset

 
\begin_inset Formula 
\begin{equation}
C\frac{dV}{dt}=\frac{g_{L}}{2\Delta_{\text{th}}}(V-V_{L})(V-V_{\text{th}})+I_{\text{s}}(t),\label{eq: QIF}
\end{equation}

\end_inset

and exponential integrate-and-fire neuron model (EIF) 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset


\begin_inset Formula 
\begin{equation}
C\frac{dV}{dt}=-g_{L}(V-V_{L})+g_{L}\Delta_{\text{th}}\exp\left(\frac{V-V_{\text{th}}}{\Delta_{\text{th}}}\right)+I_{\text{s}}(t).\label{eq: EIF}
\end{equation}

\end_inset

The QIF and the EIF model both contain nonlinear dynamics to mimic the superthre
shold transients of the membrane potential due to spike initiation.
 In case of the QIF neuron, they are quadratic, and in case of the EIF,
 they are exponential.
 The parameter 
\begin_inset Formula $\Delta_{\text{th}}$
\end_inset

 is inversely proportional to the curvature of the 
\begin_inset Formula $I$
\end_inset

-
\begin_inset Formula $V$
\end_inset

 curve at threshold, i.e.
 it measures the sharpness of spike initiation.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Fourcaud-Trocme2003"

\end_inset


\end_layout

\end_inset

 compared the response of the LIF, QIF and EIF neuron to noisy input with
 the response of more realistic H-H type models and showed that the nonlinear
 dynamics must be included to achieve a good agreement.
 We can write Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: QIF"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: EIF"

\end_inset

 as 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=f(V)+I_{\text{s}}(t),\label{eq: integrate-and-fire}
\end{equation}

\end_inset

where 
\begin_inset Formula $\tau_{\text{m}}=C/g_{L}$
\end_inset

 is the membrane time constant and 
\begin_inset Formula $g_{L}$
\end_inset

 has been absorbed into synaptic current which is now in the units of voltage.
 The membrane time constant is typically in the order of 
\begin_inset Formula $10$
\end_inset

-
\begin_inset Formula $20$
\end_inset

ms.
 For simplicity, we assume that the network consists of a single population
 and that neurons are connected via current based synapses.
 Hence, for an arbitrary neuron 
\begin_inset Formula $i$
\end_inset

, the total incoming synaptic current is given by 
\begin_inset Formula 
\begin{equation}
I_{\text{s},i}(t)=\tau_{\text{m}}\sum_{j=1}^{K_{i}}I_{ij}(t),
\end{equation}

\end_inset

where we used that different synaptic currents superimpose linearly for
 current based synapses.
 We assume again that the time scale of the synapses is much smaller compared
 to the membrane time constant and approximate the synaptic current to be
 instantaneous (delta-synapses) 
\begin_inset Formula 
\begin{equation}
I_{ij}(t)=J_{ij}\sum_{n=1}^{K_{i}}\delta(t-t_{n}^{(ij)}).\label{eq: delta synapse-1}
\end{equation}

\end_inset

We discuss different current based synapse models with finite time scale
 in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec: current based synapse"

\end_inset

.
 In case of delta-synapses, whenever a spike arrives at a synapse, the membrane
 potential makes a jump by 
\begin_inset Formula $J_{ij}$
\end_inset

 followed by an exponential decay.
 Using the mean-field ansatz introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:The-population-density"

\end_inset

, we replace all quantities in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: delta synapse-1"

\end_inset

 by their population averages 
\begin_inset Formula 
\begin{equation}
I_{\text{s}}(t)=\tau_{\text{m}}J\sum_{n}^{K}\delta(t-t_{n}^{(i)}),\label{eq: synaptic current-1}
\end{equation}

\end_inset

where 
\begin_inset Formula $K=\bigl\langle K_{i}\bigr\rangle$
\end_inset

 and 
\begin_inset Formula $J=\bigl\langle J_{ij}\bigr\rangle$
\end_inset

.
 The spike times are Poisson distributed with rate 
\begin_inset Formula $\sigma(t)=Kr(t)+r_{\text{ext}}$
\end_inset

.
 The number of indegrees a cortical neuron receives are typically in the
 order of 
\begin_inset Formula $K\sim\mathcal{O}(10^{3}$
\end_inset

-
\begin_inset Formula $10^{4})$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Braitenberg2013"

\end_inset

 and firing rates are in the order of 
\begin_inset Formula $r(t)\sim\mathcal{O}(1$
\end_inset

-
\begin_inset Formula $10^{2})$
\end_inset

Hz 
\begin_inset CommandInset citation
LatexCommand cite
key "Zador1998"

\end_inset

.
 Hence, neurons receive a large number of inputs in a time interval equal
 to the size of the membrane time constant.
 If individual inputs cause only a small changes in the membrane potential,
 i.e.
 
\begin_inset Formula $J$
\end_inset

 is small compared to the distance from the reset value 
\begin_inset Formula $V_{\text{r}}$
\end_inset

 to threshold 
\begin_inset Formula $V_{\text{th}}$
\end_inset

, then 
\begin_inset Formula $I_{\text{s}}(t)$
\end_inset

 can be approximated by Gaussian white noise 
\begin_inset CommandInset citation
LatexCommand cite
key "Amit1997"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
I_{\text{s}}(t)\approx\mu(t)+\sqrt{\tau_{\text{m}}}\sigma(t)\xi(t),\label{eq: synaptic current diffusion}
\end{equation}

\end_inset

where 
\begin_inset Formula $\xi(t)$
\end_inset

 is Gaussian white noise with zero mean and unit variance 
\begin_inset Formula 
\begin{equation}
\left\langle \xi(t)\right\rangle =0,\quad\left\langle \xi(t)\xi(t')\right\rangle =\delta(t-t')
\end{equation}

\end_inset

The mean 
\begin_inset Formula $\mu(t)$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}(t)$
\end_inset

 of the noise depend on the firing rate, and model parameters
\begin_inset Formula 
\begin{align}
\mu(t) & =\tau_{\text{m}}KJr(t)+\mu_{\text{ext}},\label{eq: mu}\\
\sigma^{2}(t) & =\tau_{\text{m}}KJ^{2}r(t)+\sigma_{\text{ext}}^{2}.\label{eq: sig}
\end{align}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: synaptic current diffusion"

\end_inset

 into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integrate-and-fire"

\end_inset

 yields the Langevin equation 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=f(V)+\mu+\sqrt{\tau_{m}}\sigma^{2}\xi(t)\label{eq: integrate-and-fire diffusion approx}
\end{equation}

\end_inset

For the LIF neuron Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 describes a Ornstein-Uhlenbeck process 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=-(V-\mu)+\sqrt{\tau_{m}}\sigma^{2}\xi(t).
\end{equation}

\end_inset

Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: diffusion approximation"

\end_inset

 illustrates that the diffusion approximation is only valid for high input
 rates.
 The Langevin Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 can be equivalently by described by a Fokker-Planck equation which determines
 the time evolution of the probability density function 
\begin_inset Formula $\rho(V,t)$
\end_inset

 in the diffusion approximation 
\begin_inset CommandInset citation
LatexCommand cite
key "Riksen1992"

\end_inset

.
 By equivalently we mean that 
\begin_inset Formula $\rho(V,t)$
\end_inset

 yields the same moments 
\begin_inset Formula $\bigl\langle V^{m}\bigr\rangle$
\end_inset

 as we would obtain directly from the Langevin Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align left
\begin_inset Graphics
	filename figures/diffusion_approximation.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
The black curves show how the membrane potential of the LIF neuron changes
 due to synaptic arrivals.
 The incoming spikes (blue dots) are modeled as a homogeneous Poisson process.
 For high enough firing rates (bottom panel), the trace of membrane potential
 resembles a Ornstein-Uhlenbeck process, randomly fluctuating around the
 mean value 
\begin_inset Formula $\mu$
\end_inset

 given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: mu"

\end_inset

.
 The strength of the controlled by standard deviation 
\begin_inset Formula $\sigma$
\end_inset

 given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: sig"

\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig: diffusion approximation"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Fokker-Planck equation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Fokker-Planck-equation"

\end_inset


\end_layout

\begin_layout Standard
The Fokker-Planck equation (FPE) which corresponds to Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 reads
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{\partial\rho(V,t)}{\partial t}=-\frac{\partial}{\partial V}[f(V)+\mu(t)]\rho(V,t)+\frac{\sigma^{2}}{2}\frac{\partial^{2}}{\partial V}\rho(V,t),\label{eq: FPE}
\end{equation}

\end_inset

The FPE is a linear 2nd order partial differential equation which describes
 an advection diffusion process with time dependent drift 
\begin_inset Formula $D_{1}(V,t)$
\end_inset

 and diffusion coefficient 
\begin_inset Formula $D_{2}(v,t)$
\end_inset

 
\begin_inset Formula 
\begin{align}
D_{1}(V,t) & =-\frac{1}{\tau_{\text{m}}}[f(V)+\mu(t)],\quad D_{2}(t)=\frac{\sigma(t)^{2}}{2\tau_{\text{m}}}.
\end{align}

\end_inset

Note the that Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE"

\end_inset

 is equivalent to Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PDE"

\end_inset

, expect the second term is replaced by a diffusion process.
 The FPE can be written as 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(V,t)}{\partial t}=L\rho(V,t),\label{eq: FPE-1}
\end{equation}

\end_inset

where 
\begin_inset Formula $L$
\end_inset

 is called Fokker-Planck operator which is given by 
\begin_inset Formula 
\begin{align}
L(t) & =\frac{\partial}{\partial V}D_{1}(V,t)+D_{2}(t)\frac{\partial^{2}}{\partial V^{2}}\label{eq: FP operator}
\end{align}

\end_inset

The benefit of formulating the time evolution in terms of the FPE is that
 it allows us to incorporate the reset mechanism at the threshold value
 by appropriate boundary conditions.
 
\end_layout

\begin_layout Subsubsection
Boundary conditions
\begin_inset CommandInset label
LatexCommand label
name "subsec:Boundary-conditions"

\end_inset


\end_layout

\begin_layout Standard
A strength of formulating the problem in terms of a FPE is that the threshold
 and reset mechanism can be incorporated into the boundary conditions.
 To show this we rewrite Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE"

\end_inset

 as a continuity equation 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(V,t)}{\partial t}=-\frac{\partial}{\partial V}J(V,t),\label{eq: FPE continuity}
\end{equation}

\end_inset

where 
\begin_inset Formula 
\begin{equation}
J(V,t)=\frac{\mu+f(V)}{\tau_{\text{m}}}\rho(V,t)-\frac{\sigma^{2}}{2\tau_{\text{m}}}\frac{\partial}{\partial V}\rho(V,t).\label{eq: FPE flux}
\end{equation}

\end_inset

is the probability current through 
\begin_inset Formula $V$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

.
 Because a spike is emitted each time 
\begin_inset Formula $V$
\end_inset

 reaches 
\begin_inset Formula $V_{\text{th}}$
\end_inset

, neurons can not reach the region 
\begin_inset Formula $V>V_{\text{th}}$
\end_inset

.
 From this follows that 
\begin_inset Formula $\rho(V>V_{\text{th}},t)=0$
\end_inset

.
 The probability flux 
\begin_inset Formula $J(V_{\text{th}},t)$
\end_inset

 yields the fraction of neuron passing through threshold at a given time
 which is equivalent to the firing rate 
\begin_inset Formula $J(V_{\text{th}},t)=r(t)$
\end_inset

.
 From 
\begin_inset Formula $\rho(V>V_{\text{th}},t)=0$
\end_inset

 follows that 
\begin_inset Formula $\rho(V_{\text{th}},t)=0$
\end_inset

 because otherwise 
\begin_inset Formula $\rho(V,t)$
\end_inset

 would be discontinuous at the threshold and its derivative infinite.
 This would result into an infinite firing rate due to 
\begin_inset Formula $J(V_{\text{th}},t)\propto\frac{\partial}{\partial V}\rho(V_{\text{th}},t)$
\end_inset

.
 Neurons are reset immediately to 
\begin_inset Formula $V_{\text{r}}$
\end_inset

 after the spike emission.
 To ensure conservation of probability, the probability flux passing the
 threshold must be reinserted at the reset value 
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0}J(V_{\text{r}}+\epsilon,t)-J(V_{\text{r}}-\epsilon,t)=J(V_{\text{th}},t).
\end{equation}

\end_inset

which is illustrated in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: reset bc "

\end_inset

.
 Finally, neurons should not enter the system from the left boundary, i.e.
 the probability current needs to vanish 
\begin_inset Formula ${\displaystyle \lim_{V\rightarrow-\infty}}J(V,t)=0$
\end_inset

 for 
\begin_inset Formula $V\rightarrow-\infty$
\end_inset

.
 To summarize, we have in total three boundary boundary conditions (BC)
 
\end_layout

\begin_layout Enumerate
Left boundary condition: 
\begin_inset Formula 
\begin{equation}
\lim_{V\rightarrow-\infty}J(V,t)=0\label{eq: left bc}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Right boundary condition: 
\begin_inset Formula 
\begin{equation}
\rho(V_{\text{th}},t)=0\label{eq: right bc}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Reset boundary condition: 
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0}J(V_{\text{r}}+\epsilon,t)-J(V_{\text{r}}-\epsilon,t)=J(V_{\text{th}},t)=r(t).\label{eq: reset bc}
\end{equation}

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/reset_bc.svg

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Sketch of the reset boundary condition.
\begin_inset CommandInset label
LatexCommand label
name "fig: reset bc "

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
If the rate pooled inputs is large, and the change jumps caused in the synaptic
 current is small, then the can be approximated by a Gaussian white noise.
 This is illustrated in figure [] The normalized contribution of a single
 
\begin_inset Formula $\delta$
\end_inset

-function input is called postsynaptic response function 
\begin_inset CommandInset citation
LatexCommand cite
key "Burkitt2006a"

\end_inset


\begin_inset Formula 
\[
\epsilon(t)=\frac{1}{\tau_{\text{m}}}e^{-\frac{t}{\tau_{\text{m}}}}\theta(t)
\]

\end_inset

The normalized postsynaptic response function is given by 
\begin_inset Formula 
\begin{equation}
\epsilon(t)=\frac{e^{-\frac{t}{\tau_{\text{m}}}}-e^{-\frac{t}{\tau_{\text{s}}}}}{\tau_{\text{m}}-\tau_{\text{s}}}\theta(t)
\end{equation}

\end_inset


\end_layout

\begin_layout Plain Layout
It replaces the synaptic current in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: neuron dynamics"

\end_inset

 by an average current plus an additional Gaussian white noise.
 The diffusion approximation can be understood as an approximation of the
 Poisson input in the limes of large input rates and small synaptic efficacies
 
\begin_inset Formula $h$
\end_inset

.
 By small, we mean that the post synaptic potential PSP induced by spike
 arrival is small compared to the distance from the reset to the threshold
 potential.
 
\end_layout

\begin_layout Plain Layout
The strength of the noise and the average input current depend on the rate
 of the Poisson input and the parameters of the neuron model.
 In the diffusion approximation, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 reduces to a Fokker-Planck equation.
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Solving the Fokker-Planck equation
\end_layout

\begin_layout Standard
Solving the time dependent FPE is a difficult task for several reasons.
 Firstly, the probability current makes a jump at the reset value due to
 reset boundary condition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: reset bc"

\end_inset

.
 Secondly, the diffusion coefficient depends on time and the drift coefficient
 depends on the membrane potential and on time.
 The stationary solution for constant (time independent) input can be derived
 analytically for the LIF and QIF neuron and numerically for the EIF neuron
 
\begin_inset CommandInset citation
LatexCommand cite
key "Richardson2007,Richardson2008"

\end_inset

.
 We discuss common methods of solution in more detail in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec: FPE Details"

\end_inset

.
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 used the diffusion approximation to derive the stationary firing rates
 in a recurrent randomly connected network of LIF neurons, mimicking a cortical
 column.
 The network in the study consists of an excitatory and inhibitory population
 (EI-Network).
 The populations receive additional uncorrelated stationary excitatory input
 from the external surrounding of the network.
 This external input represents the global spontaneous ongoing activity
 observed in cortex which has typically low firing rates 
\begin_inset Formula $1$
\end_inset

-
\begin_inset Formula $5$
\end_inset

 Hz.
 The purely excitatory external input is motivated by the fact that excitatory
 pyramidal neurons tend to form longer axons compared to inhibitory neurons
 which connect more locally 
\begin_inset CommandInset citation
LatexCommand citep
key "Braitenberg2013"

\end_inset

.
 The stationary solution of the Fokker-Planck equation yields the stationary
 firing rate of the excitatory and inhibitory population for a given input
 rate 
\begin_inset CommandInset citation
LatexCommand citep
key "A.1953"

\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset


\end_layout

\end_inset

 showed that the equation for the stationary firing rage has a solution
 for which the average firing rate of the excitatory population matches
 the spontaneous activity of the external surrounding.
 This is desirable because the excitatory population is the external surrounding
 from the perspective of the neighboring cortical columns.
 Finding the solution for the output firing rate of a population which reproduce
s the initial input firing rate is often referred to as self-consistent
 mean-field theory 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

.
 Spontaneous activity is hypothesized to be a ground state of the brain.
 Compared to silent networks, a spontaneous active network has the advantage
 that it places neurons close to the threshold, rather at their resting
 potential so that the network can respond faster to a stimulus.
\end_layout

\begin_layout Standard
The stability of the stationary state presented in 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 has been studied extensively in 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000,Brunel1999,Lindner2001"

\end_inset

.
 If the temporal modulations of the firing rate are small compared to its
 stationary baseline 
\begin_inset Formula 
\begin{equation}
r(t)=r+\delta r(t),
\end{equation}

\end_inset

with 
\begin_inset Formula $\bigl|\delta r(t)\bigr|\ll r$
\end_inset

, then perturbation theory can be applied 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

.
 showed that the LIF neuron behaves like a linear filter in first order
 approximation.
 The most important steps of the derivation are presented in more detail
 in Sec 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec: FPE Details"

\end_inset

.
 The filter properties are characterized by the response-function 
\begin_inset Formula $T(t)$
\end_inset

 which determines how the time dependent part of the output firing rate
 
\begin_inset Formula $\delta\tilde{r}(t)$
\end_inset

 depends on the input firing rate 
\begin_inset Formula 
\begin{equation}
\delta\tilde{r}(t)=\int_{-\infty}^{t}T(t)\delta r(t).\label{eq: transfer}
\end{equation}

\end_inset

The gain (change in amplitude) of the response is related to the modulus
 
\begin_inset Formula $\left|T(f)\right|$
\end_inset

 and the phase shift to the argument 
\begin_inset Formula $\arg[T(f)]$
\end_inset

 of the Fourier transform of 
\begin_inset Formula $T(f)$
\end_inset

 also referred to as the transfer function.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 showed that the self-consistent solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: transfer"

\end_inset

 mark the points where the stationary state loses stability and network
 transitions into a regime which can sustain global oscillations.
 Depending on the strength of the external input, the balance between excitation
 and inhibition, and the time scale of the synaptic delay, the average firing
 rate of the populations can show oscillations in different frequency regimes.
 Independently of the global oscillations, the firing of individual neurons
 are still highly irregular.
 The work by 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset


\end_layout

\end_inset

 has been the first analytical study investigating the synchronization propertie
s of randomly connected recurrent spiking neural networks.
 
\end_layout

\begin_layout Standard
The transfer function 
\begin_inset Formula $T(\omega)$
\end_inset

 for the LIF neuron behaves like a low-pass filter decaying with 
\begin_inset Formula $1/\sqrt{f}$
\end_inset

 in the high frequency limit.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset


\end_layout

\end_inset

 studied the frequency response for nonlinear integrate-and-fire neurons
 and showed that EIF acts as a filter with constant gain in the low and
 intermediate frequency range followed by a 
\begin_inset Formula $1/f$
\end_inset

 drop off in high frequency limit.
 These results hold for current-based as well as conductance-based synapses,
 because the spike-generating currents dominate the neuronal dynamics and
 the synaptic input has little effect on what happens after spike initiation.
 Replacing the delta-synapses by synapses with finite synaptic time scale
 introduces temporal correlations into the input noise which decay on the
 order the synaptic time scale.
 The temporal correlations can be effectively modeled by replacing the Gaussian
 white noise in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 by colored noise with a auto-correlation function which decays exponentially
 on the same time scale as the synapse 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud2002"

\end_inset

.
 Using numerical simulations, 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset


\end_layout

\end_inset

 showed that the filtering properties of the EIF are in good agreement with
 those of more realistic H-H type models 
\begin_inset CommandInset citation
LatexCommand cite
key "Hansel2002"

\end_inset

.
 Knowing how the filtering properties of spiking neuronal model can be used
 to map spiking neuron models to rate based models as it has been done in
 
\begin_inset CommandInset citation
LatexCommand cite
key "Aviel2006,Ostojic2011a"

\end_inset

.
\end_layout

\begin_layout Standard
The results in presented studies are all leading approximation, i.e.
 they are only applicable if the temporal modulations of input firing rate
 are small compared to its baseline.
 Since the derivation for LIF neuron are already quite involved, it seems
 to likely that extending the results to more complex neuron models and
 higher orders would require a combination of analytical and numerical methods.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Deniz2017"

\end_inset


\end_layout

\end_inset

 recently solved the stationary FPE for the LIF neuron for arbitrary input
 correlations using the method of spectral decomposition.
 They showed that their method can be related to the perturbative approach
 used in 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindner2001"

\end_inset

 which relies on the assumption that correlations are small.
 Hence, using the method spectral decomposition may allows to derive higher
 order corrections for the transfer function in a similar manner.
 
\end_layout

\begin_layout Standard
The method of spectral decomposition expands the density function in terms
 of the eigenfunctions of the differential operator which describes its
 time evolution.
 It has been first introduced in the context of PDMs by 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset


\end_layout

\end_inset

.
\end_layout

\begin_layout Subsection
Spectral decomposition
\begin_inset CommandInset label
LatexCommand label
name "subsec:Spectral-decomposition"

\end_inset


\end_layout

\begin_layout Standard
In this section we follow the notation introduced in 
\begin_inset CommandInset citation
LatexCommand citep
key "Knight2000a"

\end_inset

.
 We start from equation Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PDE"

\end_inset

 and Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE"

\end_inset

 both of which can be written as 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=Q(\boldsymbol{v},r(t))\rho(\boldsymbol{v},t),\label{eq: rho operator}
\end{equation}

\end_inset

where 
\begin_inset Formula $Q$
\end_inset

 is called the dynamical operator which depends implicitly on time through
 its dependence on the input firing rate 
\begin_inset Formula $r(t)$
\end_inset

.
 In the diffusion approximation, 
\begin_inset Formula $Q$
\end_inset

 is equivalent to the Fokker-Planck operator introduced in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FP operator"

\end_inset

.
 The eigenfunctions 
\begin_inset Formula $\phi_{n}(\boldsymbol{v},t)$
\end_inset

 and eigenvalues 
\begin_inset Formula $\lambda_{n}(t)$
\end_inset

 of 
\begin_inset Formula $Q$
\end_inset

 are defined by 
\begin_inset Formula 
\begin{equation}
Q(\boldsymbol{v},r(t))\phi_{n}(\boldsymbol{v},t)=\lambda_{n}(t)\phi_{n}(\boldsymbol{v},t).\label{eq: phi_n}
\end{equation}

\end_inset

Note that both eigenfunctions and eigenvalues are time dependent because
 
\begin_inset Formula $Q$
\end_inset

 changes in time.
 Hence, we are dealing with moving basis.
 The dynamical operator 
\begin_inset Formula $Q$
\end_inset

 is not Hermitian (self-adjoint) due to the first derivative in the drift
 term in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PDE"

\end_inset

 and Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE"

\end_inset

.
 For non Hermitian operators, eigenvalues 
\begin_inset Formula $\lambda_{n}$
\end_inset

 are in general complex and the eigenfunctions 
\begin_inset Formula $\phi_{n}(\boldsymbol{v},t)$
\end_inset

 are not orthogonal.
 Taking the complex conjugate of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: phi_n"

\end_inset

 and using the fact that 
\begin_inset Formula $Q$
\end_inset

 is real, we find that 
\begin_inset Formula 
\begin{equation}
Q(\boldsymbol{v},t)\phi_{n}^{*}(\boldsymbol{v},t)=\lambda_{n}^{*}\phi_{n}^{*}(\boldsymbol{v},t).
\end{equation}

\end_inset

This shows that the eigenvalues and eigenfunctions of 
\begin_inset Formula $Q$
\end_inset

 come in complex conjugate pairs.
 If the set of eigenfunctions 
\begin_inset Formula $\{\phi_{n}(\boldsymbol{v})\}$
\end_inset

 are complete, then we can expand the density function in terms of eigenfunction
s
\begin_inset Formula 
\begin{equation}
\rho(\boldsymbol{v},t)=\sum_{n=-\infty}^{\infty}c_{n}(t)\phi_{n}(\boldsymbol{v},t),\label{eq: eigenfunction expansion}
\end{equation}

\end_inset

where we introduce the notation 
\begin_inset Formula $\phi_{-n}(\boldsymbol{v})=\phi_{n}^{*}(\boldsymbol{v})$
\end_inset

.
 Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: phi_n"

\end_inset

 into the firing rate is given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: r"

\end_inset

 and using that the functional 
\begin_inset Formula $R$
\end_inset

 is linear, we arrive at 
\begin_inset Formula 
\begin{equation}
r(t)=R[\boldsymbol{J}(\boldsymbol{v},t)]=R[C\rho(\boldsymbol{v},t)]=\sum_{n=-\infty}^{\infty}c_{n}(t)R[C\phi_{n}(\boldsymbol{v},t)].
\end{equation}

\end_inset

where 
\begin_inset Formula $C$
\end_inset

 is the linear current operator 
\begin_inset Formula 
\begin{equation}
J(\boldsymbol{v},t)=C\rho(\boldsymbol{v},t).\label{eq: probability current}
\end{equation}

\end_inset

The current operator 
\begin_inset Formula $C$
\end_inset

 is related to dynamical operator by 
\begin_inset Formula $Q=-KC$
\end_inset

, where 
\begin_inset Formula $K$
\end_inset

 is the familiar divergence operator of ordinary vector analysis 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

.
 The weighting coefficient 
\begin_inset Formula $c_{n}(t)$
\end_inset

 tell us how the 
\begin_inset Formula $n$
\end_inset

th mode contributes to 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 a given point in time.
 The density 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 must fulfill the boundary conditions introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Boundary-conditions"

\end_inset

, this means that each eigenfunction 
\begin_inset Formula $\phi_{n}(\boldsymbol{v},t)$
\end_inset

 must also fulfill the boundary conditions to ensure that any linear combination
 of eigenfunctions fulfills them as well.
 To determine the weighting coefficients 
\begin_inset Formula $c_{n}(t)$
\end_inset

, we need to construct a basis 
\begin_inset Formula $\left\{ \tilde{\phi}_{n}(\boldsymbol{v},t)\right\} $
\end_inset

 which is orthogonal to 
\begin_inset Formula $\{\phi_{n}(\boldsymbol{v},t)\}$
\end_inset

.
 It turns of that the desired basis 
\begin_inset Formula $\left\{ \tilde{\phi}_{n}(\boldsymbol{v},t)\right\} $
\end_inset

 is spanned by the eigenfunctions of the adjoint operator 
\begin_inset Formula $Q^{\dagger}$
\end_inset

.
 The set of eigenfunctions 
\begin_inset Formula $\left\{ \tilde{\phi}_{n}(\boldsymbol{v},t),\phi_{n}(\boldsymbol{v},t)\right\} $
\end_inset

 is referred to as a dual basis.
 The time evolution 
\begin_inset Formula $c_{n}(t)$
\end_inset

 is determined by a coupled system of linear equations.
 Details are presented in Sec 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition-1"

\end_inset

.
 
\end_layout

\begin_layout Standard
The hope is that a finite number of modes is sufficient to describe the
 dynamics of the population.
 This dimensionality reduction could provide a computational efficient tool
 to simulate Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho operator"

\end_inset

 on the one hand as envisioned by 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

, and provide a more intuitive understanding about the network dynamics
 in terms eigenmodes on the other hand.
 In order to achieve this it is necessary to know how the eigenvalues and
 eigenfunctions change as a function of the input rate.
 Finding an analytic expression of the eigenvalues and eigenfunctions is
 difficult and has so far only been achieved for the PIF neuron with additional
 constant leak term 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2002"

\end_inset

 and for the LIF neuron in the diffusion limit 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunel2000,Lindner2001,Deniz2017"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2002"

\end_inset

 presented a way to include changes in the input rate due to recurrent connectio
ns in a self-consistent manner.
 As a proof of principle, they showed in a subsequent work that the theory
 is capable of predicting the network dynamics of a recurrent connected
 EI-Network of PIF neurons 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2004"

\end_inset

.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand citep
key "Biggio2017"

\end_inset

 
\end_layout

\end_inset

 developed a method to study a general integrate-and-fire model with exponential
 decaying synaptic currents.
 Their method reduces the inherently two dimension problem to a one dimensional.
 Theoretical predicted averaging firing rates show excellent agreement to
 simulation of PIF neurons.
\end_layout

\begin_layout Standard
So far it is not known if eigenfunctions can be found for regimes where
 the diffusion approximation does not apply.
 Furthermore, more complex models including synaptic dynamics, adaptation
 or spike generating currents have not been studied yet.
 
\end_layout

\begin_layout Section
Research questions
\end_layout

\begin_layout Enumerate
Is it possible to efficiently simulate large scale neuronal networks on
 the population level by describing each population by a finite set of eigenmode
s? 
\begin_inset Note Note
status collapsed

\begin_layout Enumerate
Is it possible to develop an algorithm to numerically determine eigenfunctions
 and eigenvalues for a wide class of neuron models?
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Using the method of spectral decomposition, can we characterize the firing
 rate response of a large class of integrate-and-fire neuron models for
 arbitrary time dependent input rates? 
\end_layout

\begin_layout Enumerate
Can we derive a mapping between spiking and rate based neuron models in
 dynamical regimes which show highly non-stationery firing rates?
\end_layout

\begin_layout Subsection
Research proposal
\end_layout

\begin_layout Standard
In computational neuroscience, the most common method to simulate neural
 circuits is by means of direct simulation.
 This approach follows the dynamics of all neurons individually taking into
 account.
 Although direct simulations yield full information about the network state
 on the single neuron level at all times which is a significant upside,
 they also have shortcomings: They demand a fast amount of computational
 resources even in case of extremely simplified neuron models and large
 scale brain simulations need supercomputers to run 
\begin_inset CommandInset citation
LatexCommand citep
key "Schuecker2017"

\end_inset

.
 This makes it difficult to systematically investigate relationships between
 model parameters, connectivity structure and network dynamics.
 
\end_layout

\begin_layout Standard
The columnar organization hypothesis states that the cortical sheet is organized
 in cortical columns 
\begin_inset CommandInset citation
LatexCommand cite
key "Mountcastle1979"

\end_inset

.
 It is currently the most widely adopted hypothesis to explain the cortical
 processing of information 
\begin_inset CommandInset citation
LatexCommand cite
key "DeFelipe2013"

\end_inset

.
 Cortical columns are structured into layers, different types of neurons
 within the different layers are usually pooled into populations.
 In the simplest case, each layer is represented by an excitatory and inhibitory
 population 
\begin_inset CommandInset citation
LatexCommand cite
key "Potjans2012"

\end_inset

.
 Cortical column models are often used as an elementary building block,
 to represent larger brain areas.
 It is therefore desirable to have method which can efficiently simulate
 a cortical column on different levels of detail.
 
\end_layout

\begin_layout Standard
Population density methods (PMDs) seek to make us of the redundancy observed
 cortical networks.
 PDMs use a probabilistic description on the level of populations instead
 of modeling networks on the level of individual neurons.
 The state of each population is characterized by a probability density
 function which determines the fraction of neurons which are in a given
 state space volume at a given time.
 Populations interact by sending Poisson spike trains to each other.
 The firing rate of the Poisson process is given by the population average
 firing rate which can be determined from how the density function changes
 in time.
 PDMs reduce the dimensionalty of the problem from the number of neurons
 to the number of populations.
 
\end_layout

\begin_layout Standard
On the first glance, one may think that this should result in a massive
 simulation speed up.
 However, even for simple neuronal models, the time evolution of the density
 is governed by a complicated integro partial differential equation (iPDE)
 
\begin_inset CommandInset citation
LatexCommand cite
key "Omurtag"

\end_inset

.
 The complexity of solving the iPDE scales drastically with the dimension
 of the neuron model.
 Using the method of characteristics, 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "DeKamps2003"

\end_inset


\end_layout

\end_inset

 developed a generic and stable method to solve the iPDE.
 It relies on representing the density function on a geometric grid which
 mimics the deterministic neuron dynamics.
 Depending on the specifies of the neuron model, a large number of grid
 cells are needed to arrive at an accurate prediction.
 Roughly, the number of cells grows exponentially with the number of dimensions
 of the neuron model.
 For two dimensional models, simulation times are currently on the same
 time scale compared to direct simulations.
 
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset


\end_layout

\end_inset

 proposed a different method of solution based on the idea of expanding
 the probability density function in terms of eigenfunctions of the dynamical
 operator which describes the time evolution of the density.
 By doing so, the problem can be separated into two distinct parts.
 Firstly, a finite set of eigenfunctions and eigenvalues of the dynamical
 operator need to be determined for a given neuron model.
 This problem is time independent and can be solved prior to the actual
 simulation.
 Secondly, the time evolution of the weighting coefficients of the different
 modes need to be determined.
 The eigenfunction decomposition reduces the iPDE to a finite system of
 ordinary differential equations (ODEs) which can presumably be solved much
 faster than the iPDE.
 So far, analytic results for eigenvalues and eigenfunction are only known
 for the perfect integrate-and-fire model and the leaky integrate-and-fire
 model in the diffusion approximation 
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002,Brunel1999,Deniz2017"

\end_inset

.
 Hence, our first goal is to develop a generic numerical method to determine
 eigenvalues and eigenfunctions for more complex neuron models.
 Subsequently, we want to demonstrate that expanding the density function
 in terms of eigenfunctions allows us to efficiently simulate population
 dynamics in a cortical column.
 
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset

Deciphering how information is encoded in the brain requires a good understandin
g of how individual neurons emit action potentials in response to time-varying
 stimuli.
 Gain modulation describes how the amplitude of the output response of a
 system can be changed in a nonlinear way.
 Gain modulation allows information to be transformed, combined and compared
 in a nonlinear fashion, and consequently provides an important means by
 which an organism can process incoming information 
\begin_inset CommandInset citation
LatexCommand cite
key "Burkitt2006a"

\end_inset

.
 
\end_layout

\begin_layout Standard
In particular, we want to understand how the instantaneous firing rate of
 a neuron changes in response to a stimulus.
 Furthermore, we want to find out how the response of the neuron is affected
 by the underlying neuron model and the overall state of the network in
 which the neuron is embedded.
 
\end_layout

\begin_layout Standard
Imagine a typical setup in which a stimulus is repeatedly applied to a network,
 and action potentials of a neuron are recorded over many trials.
 By averaging over trials, we obtain the average firing rate of the neuron
 in response to the presented stimulus.
 For arbitrary stimuli, we can mimic this situation by looking at a single
 neuron which receives synaptic input which consists of two components:
 a time varying-input which represents the input signal, and a constant
 or time dependent background input that represents the stimulus unrelated
 activity of the surrounding network 
\begin_inset CommandInset citation
LatexCommand cite
key "Ostojic2011a"

\end_inset

.
 If the synaptic input is modeled by a Poisson process, then the average
 response of a neuron can be in principle determined from the Fokker-Planck
 equation introduced in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Fokker-Planck-equation"

\end_inset

.
 Several studies investigated the response of different neuron models assuming
 that the amplitude of the input signal is small compared to constant background
 activity 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunel2000,Fourcaud2002,Fourcaud-Trocme2003"

\end_inset

.
 Under this assumption, it has been shown that the relationship between
 input and output firing rate can be described as a linear filter.
 Due to linearity, the filter is fully characterized by the gain and phase
 response with respect to sinusoidal input at a given frequency.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Ostojic2011a"

\end_inset


\end_layout

\end_inset

 used these analytic results to establish a mapping between phenomenological
 rate based and biophysically motivated spiking neuron models.
 Rate neurons have the advantage that interactions between neurons are modeled
 by continuous signals, instead of spike trains, which makes them more accessibl
e for analytic studies.
 Among others, they have been used to investigate the relationship between
 the connectivity structure and correlations between neuronal activity in
 randomly connected recurrent networks 
\begin_inset CommandInset citation
LatexCommand cite
key "Tetzlaff2012,Grytskyy2013,Dahmen2017"

\end_inset

.
\end_layout

\begin_layout Standard
All presented results are not valid for strongly modulated input signals
 or time modulated background activity.
 In this regime, the neuron can presumably not be sufficiently described
 as a linear filter, but higher order nonlinear effects need to be taken
 into account.
 These nonlinear effects could be analyzed by solving the Fokker-Planck
 equation input rates which are strongly modulated in time.
 If we can solve the FPE in this regime, then this would allow us to establish
 a more complete relationship between spiking and rate based neuron models.
 
\end_layout

\begin_layout Section
Preliminary results 
\end_layout

\begin_layout Standard
Our first objective is to develop a numerical method to determine the eigenvalue
s and eigenfunctions of the dynamical operator introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

 for a large class of neuron models.
 In the diffusion approximation, eigenvalues and eigenfunctions of the perfect
 integrate-and-fire and the leaky integrate-and-fire neuron can be determined
 analytically 
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002,Deniz2017,Brunel1999"

\end_inset

.
 As a first step, we recover the known analytical results so that we can
 measure the performance of our numerical method by comparison.
 
\end_layout

\begin_layout Subsection
Perfect integrate-and-fire 
\end_layout

\begin_layout Standard
The perfect integrate-and-fire (PIF) with constant leak term is describe
 by the equation 
\begin_inset Formula 
\begin{equation}
\frac{dv}{dt}=-\alpha+I_{\text{s}}(t),
\end{equation}

\end_inset

where 
\begin_inset Formula $I_{s}(t)$
\end_inset

 is the synaptic input current 
\begin_inset CommandInset citation
LatexCommand cite
key "Fusi1999"

\end_inset

.
 The PIF neuron can be obtained from the leaky integrate-and-fire neuron
 by replacing the voltage dependent leak term by a constant 
\begin_inset Formula $\alpha$
\end_inset

.
 As discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Diffusion-approximation"

\end_inset

, in the diffusion approximation, the synaptic input is approximated as
 a Gaussian white noise 
\begin_inset Formula 
\begin{align}
\frac{dv}{dt} & \approx-\alpha+\mu(t)+\sqrt{\sigma(t)}\xi(t)=\eta(t)+\sqrt{\sigma(t)}\xi(t),\label{eq: PIF diffusion}
\end{align}

\end_inset

As discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Fokker-Planck-equation"

\end_inset

, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PIF diffusion"

\end_inset

 can be equivalently described by a FPE 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(v,t)}{\partial t}=L\rho(v,t),\quad L=-\eta(t)\frac{\partial}{\partial v}+\frac{\sigma^{2}(t)}{2}\frac{\partial^{2}}{\partial v}.
\end{equation}

\end_inset

The eigenfunctions of the FP operator 
\begin_inset Formula $L$
\end_inset

 are determined by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: phi_n"

\end_inset

 which can be written as 
\begin_inset Formula 
\begin{equation}
-\eta(t)\phi'_{n}(v,t)+\frac{\sigma^{2}(t)}{2}\phi_{n}''(v,t)=\lambda_{n}\phi_{n}(v,t),\label{eq: PIF phi_n}
\end{equation}

\end_inset

For a fixed point in time, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PIF phi_n"

\end_inset

 is a ODE with constant coefficients which can be solved using an exponential
 ansatz 
\begin_inset Formula $\phi_{n}(v,t)=e^{\alpha v}$
\end_inset

.
 The free coefficients of the general solution must be determined such that
 
\begin_inset Formula $\phi_{n}(v,t)$
\end_inset

 fulfills the boundary conditions of 
\begin_inset Formula $\rho(v,t)$
\end_inset

 discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Boundary-conditions"

\end_inset

.
 It should be noted that 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002"

\end_inset


\end_layout

\end_inset

 introduced a reflecting boundary at the reset value 
\begin_inset Formula $V_{\text{r}}$
\end_inset

 to simplify the derivation (i.e.
 the membrane potential of neurons can not become smaller than 
\begin_inset Formula $V_{\text{r}}$
\end_inset

).
 However, we show later for the LIF neuron that eigenfunctions can be derived
 without introducing this additional constraint.
 Skipping the details of the derivation, in the end, one arrives at an expressio
n for the eigenfunctions 
\begin_inset Formula $\phi_{n}(v)$
\end_inset

 and the eigenfunctions of the adjoint operator 
\begin_inset Formula $\tilde{\phi}_{n}(v)$
\end_inset

 
\begin_inset Formula 
\begin{align}
\phi_{0}(v,t) & =\frac{c}{\eta}\left(1-e^{\frac{-2\xi(\theta-v)}{\theta}}\right),\nonumber \\
\phi_{n}(v,t) & =c_{n}\sinh\left(\zeta_{n}\frac{\theta_{n}-v}{\theta}\right)e^{\frac{\xi v}{\theta}},\quad\text{for }n\neq0,\nonumber \\
\tilde{\phi}{}_{n}(v,t) & =\left[\zeta_{n}\cosh\left(\frac{\zeta_{n}v}{\theta}\right)+\xi\sinh\left(\frac{\zeta_{n}v}{\theta}\right)\right]e^{-\frac{\xi}{\theta}v},\quad\text{for }n\neq0,
\end{align}

\end_inset

where 
\begin_inset Formula $\xi$
\end_inset

 and 
\begin_inset Formula $\zeta_{n}$
\end_inset

 are given by
\begin_inset Formula 
\begin{equation}
\zeta_{n}=\frac{\theta}{\sigma^{2}}\sqrt{\eta^{2}+2\sigma^{2}\lambda_{n}},\quad\xi=\frac{\eta\theta}{\sigma^{2}}.
\end{equation}

\end_inset

 From the reset BC given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: reset bc"

\end_inset

, a characteristic equation for the eigenvalues can be derived 
\begin_inset Formula 
\begin{equation}
\zeta_{n}e^{\xi}=\zeta_{n}\cosh\left(\zeta_{n}\right)+\xi\sinh\left(\zeta_{n}\right).
\end{equation}

\end_inset

The solutions of this equation determine the infinite countable set of eigenvalu
es 
\begin_inset Formula $\{\lambda_{n}\}$
\end_inset

.
 Eigenvalues of the first three modes for different values of 
\begin_inset Formula $\eta$
\end_inset

 and 
\begin_inset Formula $\sigma=1$
\end_inset

 are shown in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: PIF spectrum"

\end_inset

.
 Eigenvalues are purely real for 
\begin_inset Formula $\eta<0$
\end_inset

 (noise dominated regime) and complex for 
\begin_inset Formula $\eta>0$
\end_inset

 (drift dominated) regime.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/PIF_spectrum.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Real part and imaginary part 
\begin_inset Formula $\lambda_{n}$
\end_inset

 for the first mode (blue), second mode (orange), third mode (green) for
 different values of 
\begin_inset Formula $\eta$
\end_inset

.
 Other model parameters are set to
\begin_inset Formula $\{\sigma=1,v_{\text{r}}=1,v_{\text{th}}=1\}$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig: PIF spectrum"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset

The first three eigenfunctions are shown as an example for two different
 values of 
\begin_inset Formula $\eta$
\end_inset

 (drift and noise dominated regime) in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: PIF eigenfunctions"

\end_inset

.
 Note that the eigenfunctions fulfill the boundary condition 
\begin_inset Formula $\phi_{n}(v_{\text{th}})=0$
\end_inset

 as desired.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/PIF_ef.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Real and imaginary part of the first three eigenfunctions 
\begin_inset Formula $\phi_{n}(v)$
\end_inset

 for 
\begin_inset Formula $\eta=-1$
\end_inset

 (left column) and 
\begin_inset Formula $\eta=1$
\end_inset

 (right) column.
 Other model parameters are set to
\begin_inset Formula $\{\sigma=1,v_{\text{r}}=0,v_{\text{th}}=1\}$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig: PIF eigenfunctions"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset

Knowing the eigenfunctions and eigenvalues, we can predict the time evolution
 of the density function and the population firing rate at any time for
 a given initial condition.
 Fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:PIF firing rate"

\end_inset

 shows the simulation results for a population of non-interacting PIF neurons
 which receive a constant external input.
 In the beginning of the simulation, all neurons are placed at the reset
 potential 
\begin_inset Formula $\rho(V,0)=\delta(v_{\text{r}})$
\end_inset

.
 We showed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition-1"

\end_inset

 that the initial value 
\begin_inset Formula $c_{n}(0)$
\end_inset

 of the weighting coefficients is determined by the inner product 
\begin_inset Formula $c_{n}(0)=(\tilde{\phi}_{n},\rho(V,0))$
\end_inset

.
 For 
\begin_inset Formula $\rho(V,0)=\delta(v_{\text{r}})$
\end_inset

, the inner product simplifies to
\begin_inset Formula 
\begin{equation}
c_{n}(0)=(\tilde{\phi}_{n},\delta(v_{\text{r}}))=\tilde{\phi}_{n}(v_{\text{r}}).
\end{equation}

\end_inset

This tells us that in the beginning of the simulation, all modes with 
\begin_inset Formula $\tilde{\phi}_{n}(v_{\text{r}})\neq0$
\end_inset

 contribute to 
\begin_inset Formula $\rho(V,0)$
\end_inset

.
 Indeed, an infinite number of modes is required to represent a delta-function
 
\begin_inset Formula $\delta(v_{\text{r}})$
\end_inset

.
 However, shortly after, the first three modes are already sufficient to
 predict the firing rate of the population.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/PIF_rate_density.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Top panel shows the firing rate of the population over time for 
\begin_inset Formula $\{\eta=1,\sigma=1,v_{\text{th}}=1,v_{\text{r}}=0\}$
\end_inset

.
 Theoretical results (black curve) have been calculated using the first
 three modes.
 The red dashed line shows the result from the Miind simulation.
 The background colors mark different time intervals in which only a certain
 subset of modes is still active while all other have already decayed to
 zero.
 In the blue time interval only the first mode is still active, in the yellow
 interval the first two modes are still active and in the green time interval
 the first three modes are still active.
 The bottom panel shows the probability density function centered around
 the stationary distribution 
\begin_inset Formula $\phi_{0}(V)$
\end_inset

 at two different time points indicated by the black crosses in the top
 panel.
 The theoretical result (black curve) in left panel has been calculated
 using the first two modes, and only the first mode in the right panel.
 The red dashed lines show the result from the Miind simulation.
 
\begin_inset CommandInset label
LatexCommand label
name "fig:PIF firing rate"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

The firing rate is zero at 
\begin_inset Formula $t=0$
\end_inset

 because all neurons are located at the reset potential 
\begin_inset Formula $V_{\text{r}}$
\end_inset

.
 The oscillation of the firing rate can be explained from the fact that
 the drift coefficient 
\begin_inset Formula $\eta$
\end_inset

 is much stronger compared to the diffusion coefficient 
\begin_inset Formula $\sigma$
\end_inset

 and the density function is still strongly peaked when neurons reach the
 threshold for the first times.
 However, the initial peak will diffuse eventually and both the density
 function and the firing rate converge to steady state.
 From a mathematical point of view, the oscillations of the firing rate
 can be explained from the fact that eigenvalues become complex for 
\begin_inset Formula $\eta>0$
\end_inset

.
 We observe that Miind and theoretical prediction are in good agreement.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
A strength of Miind compared to MC is that it produces smooth curves because
 it solves Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PDE"

\end_inset

 which describes the time evolution 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Leaky integrate-and-fire 
\begin_inset CommandInset label
LatexCommand label
name "subsec: LIF"

\end_inset


\end_layout

\begin_layout Standard
The FPE 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE"

\end_inset

 for LIF neuron reads 
\begin_inset Formula 
\begin{equation}
\partial_{t}\rho(V,t)=L\rho(V,t),\quad L=\partial_{V}\left(\frac{1}{\tau}\left[V-\mu(t)\right]+\frac{\sigma^{2}(t)}{2\tau}\partial_{V}\right),
\end{equation}

\end_inset

where we set the reversal potential 
\begin_inset Formula $V_{L}$
\end_inset

 of the leak channel to zero.
 Introducing the dimensionless variables 
\begin_inset Formula 
\begin{equation}
s=\frac{t}{\tau},\quad x=\frac{\sqrt{2}}{\sigma}(V-\mu),
\end{equation}

\end_inset

transforms the Fokker-Planck operator to 
\begin_inset Formula 
\begin{equation}
L=\partial_{x}\left(x+\partial_{x}\right).
\end{equation}

\end_inset

In the new variables, the eigenfunctions are determined by a linear second
 order ODE 
\begin_inset Formula 
\begin{equation}
\phi(x)+x\phi'(x)+\phi''(x)=\lambda\phi(x).
\end{equation}

\end_inset

The fact that the coefficient in front of the first derivative is not constant
 makes the derivation much more complicated compared to PIF neuron.
 Here, we present only the final results and refer to Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec: ef LIF"

\end_inset

 for more details.
 The eigenfunctions 
\begin_inset Formula $\phi_{n}(x)$
\end_inset

 are given by the piecewise solution 
\begin_inset Formula 
\begin{align}
\phi_{n}(x)=e^{-\frac{1}{4}x^{2}} & \begin{cases}
c_{n}U(z_{n},-x) & x<x_{\text{r}}\\
a_{n}V(z_{n},-x)+b_{n}U(z_{n},-x) & x_{\text{r}}\leq x<x_{\theta}
\end{cases},\label{eq: LIF phi_n}
\end{align}

\end_inset

where 
\begin_inset Formula $z_{n}=\lambda_{n}-1/2$
\end_inset

, 
\begin_inset Formula $x_{\text{r}}=\frac{\sqrt{2}}{\sigma}(V_{\text{r}}-\mu)$
\end_inset

 and 
\begin_inset Formula $x_{\theta}=\frac{\sqrt{2}}{\sigma}(V_{\text{th}}-\mu)$
\end_inset

 .
 The functions 
\begin_inset Formula $U(z,x)$
\end_inset

 and 
\begin_inset Formula $V(z,x)$
\end_inset

 are called parabolic cylinder functions 
\begin_inset CommandInset citation
LatexCommand cite
key "Abramowitz1965"

\end_inset

.
 Eigenfunctions are unique up to an arbitrary normalization constant.
 We define the normalization constant such that 
\begin_inset Formula $\phi_{n}(x)$
\end_inset

 fulfills the condition 
\begin_inset Formula 
\begin{equation}
\partial_{x}\phi(x_{\theta})=e^{-\frac{1}{4}x_{\theta}}\partial_{x}\varphi(x_{\theta})=\sqrt{\frac{2}{\pi}}.\label{eq: LIF normalization}
\end{equation}

\end_inset

The coefficients 
\begin_inset Formula $a_{n},b_{n}$
\end_inset

 and 
\begin_inset Formula $c_{n}$
\end_inset

 need to be chosen such that 
\begin_inset Formula $\phi_{n}(x)$
\end_inset

 fulfills the BCs introduced in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Boundary-conditions"

\end_inset

.
 For the normalization condition given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF normalization"

\end_inset

, the coefficients take a particular simple form 
\begin_inset Formula 
\begin{align}
a_{n} & =\frac{U(z_{n},y_{\theta})}{f(y_{\theta})},\nonumber \\
b_{n} & =-\frac{V(z_{n},y_{\theta})}{f(y_{\theta})},\nonumber \\
c_{n} & =\frac{V(z_{n},y_{\text{r}})}{f(y_{\text{r}})}-\frac{V(z_{n},y_{\theta})}{f(y_{\theta})}.
\end{align}

\end_inset

The eigenfunction of the adjoint operator is given by 
\begin_inset Formula 
\begin{equation}
\tilde{\phi}_{n}(x)=d_{n}e^{\frac{1}{4}x^{2}}U(z_{n},-x),
\end{equation}

\end_inset

where 
\begin_inset Formula $d_{n}$
\end_inset

 is defined as 
\begin_inset Formula 
\begin{equation}
d_{n}=(e^{\frac{1}{4}x^{2}}U(z_{n},-x),\phi_{n}(x)),
\end{equation}

\end_inset

to ensure that 
\begin_inset Formula $(\tilde{\phi}_{n},\phi_{n})=1$
\end_inset

.
 The BCs yield a characteristic equation for the eigenvalues 
\begin_inset Formula 
\begin{equation}
e^{-\frac{1}{4}x_{\text{r}}^{2}}U(z_{n},y_{\theta})-e^{-\frac{1}{4}x_{\theta}^{2}}U(z_{n},y_{\text{r}})=0\label{eq: characteristic equation}
\end{equation}

\end_inset

The solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: characteristic equation"

\end_inset

 yield the infinite countable set of eigenvalues 
\begin_inset Formula $\{\lambda_{n}\}$
\end_inset

.
 Finding solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: characteristic equation"

\end_inset

 is not an easy task because the real and imaginary parts of the parabolic
 cylinder functions exhibit rapid oscillations in the complex plane.
 A preliminary attempt to solve Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: characteristic equation"

\end_inset

 is illustrated in Fig.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "fig: LIF Spectrum "

\end_inset

.
 Panel 
\series bold
A
\series default
 shows the zero crossings of the real part (blue) and imaginary part (yellow)
 of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: characteristic equation"

\end_inset

 in the complex plane.
 We expect that solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: characteristic equation"

\end_inset

 can be found at points where the blue line crosses the real axis and at
 points where the blue and yellow line cross each other.
 Using the location of these points as an initial guess, we can solve Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: characteristic equation"

\end_inset

 numerically using a bisection method on the real axis and Newton's method
 in the complex plane.
 Panel 
\series bold
B
\series default
 shows a exemplary spectrum.
 The spectrum of the LIF neuron has both complex and purely real eigenvalues
 unlike the spectrum of the PIF neuron which is either purely real or complex.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/LIF_spectrum.png
	scale 55

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Panel 
\series bold
A
\series default
 shows the zero crossings of the real part (blue) and imaginary part (yellow)
 of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 in the complex plane.
 Panel 
\series bold
B
\series default
 shows the first eigenvalues of the spectrum which have been calculated
 by solving Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 numerically.
 Model parameters are set to
\begin_inset Formula $\{\mu=1.2,\sigma=0.2,v_{\text{r}}=0,v_{\text{th}}=1,\tau_{\text{m}}=10\text{ms}\}$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig: LIF Spectrum "

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset


\end_layout

\end_inset

 speculated that the 
\begin_inset Formula $n$
\end_inset

th eigenvalue should approximately be given by 
\begin_inset Formula 
\begin{equation}
\lambda_{n}\approx-\Gamma(r)n^{2}+in\omega_{0},
\end{equation}

\end_inset

where 
\begin_inset Formula $\Gamma(r)$
\end_inset

 is some unknown function which depends on the input rate and 
\begin_inset Formula $\omega_{0}$
\end_inset

 is called fundamental frequency.
 The fundamental frequency is given by 
\begin_inset Formula 
\begin{equation}
\omega_{0}=2\pi/T_{0},
\end{equation}

\end_inset

where 
\begin_inset Formula $T_{0}$
\end_inset

 is period which the membrane potential needs to go from the reset value
 
\begin_inset Formula $V_{\text{r}}$
\end_inset

 to threshold for mean input 
\begin_inset Formula $\mu$
\end_inset

 neglecting the input fluctuations 
\begin_inset Formula $\sigma$
\end_inset

.
 For the LIF neuron 
\begin_inset Formula $T_{0}$
\end_inset

 is given by 
\begin_inset Formula 
\begin{equation}
T_{0}=\tau_{\text{m}}\ln\left(\frac{\mu}{\mu-V_{\text{th}}}\right),
\end{equation}

\end_inset

where we set 
\begin_inset Formula $V_{\text{r}}=0$
\end_inset

.
 Note that 
\begin_inset Formula $T_{0}$
\end_inset

 is only defined if 
\begin_inset Formula $\mu>V_{\text{th}}$
\end_inset

 which is referred to as the mean-driven regime.
 Panel 
\series bold
A
\series default
 in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: LIF spectrum 2"

\end_inset

 shows the imaginary and real part of the complex eigenvalues shown in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: LIF Spectrum "

\end_inset

 as a function of 
\begin_inset Formula $n$
\end_inset

.

\series bold
 
\series default
Panel 
\series bold
B
\series default
 shows the eigenfunction of the first three complex modes for different
 values of 
\begin_inset Formula $\mu$
\end_inset

 and constant 
\begin_inset Formula $\sigma$
\end_inset

.
 The blue lines in panel 
\series bold
A
\series default
 confirms that the real part shows a quadratic, and the imaginary part a
 linear dependence on 
\begin_inset Formula $n$
\end_inset

.
 However, the slope of the straight line does not match the fundamental
 frequency as anticipated by 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset


\end_layout

\end_inset

.
 Furthermore, complex eigenvalues can still be found even if 
\begin_inset Formula $\mu<V_{\text{th}}$
\end_inset

 (noise driven regime).
 Interestingly, the real parts of the eigenvalues seem to be only mildly
 affected by changes in 
\begin_inset Formula $\mu$
\end_inset

 while the imaginary parts change linearly.
 This implies that the minimum frequency at which the population firing
 rate can oscillate increases with higher mean input 
\begin_inset Formula $\mu$
\end_inset

.
 Since Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: LIF spectrum 2"

\end_inset

 reveals a clear structure of the spectrum, we are confident that it is
 possible to find solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: LIF Spectrum "

\end_inset

 up to high mode numbers for different input rates by extrapolation.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/LIF_spectrum_2.png
	scale 45

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Panel 
\series bold
A 
\series default
shows the real and imaginary part for the complex eigenvalues plotted over
 
\begin_inset Formula $n$
\end_inset

 for 
\begin_inset Formula $\{\mu=1.2,\sigma=0.2,V_{\text{th}}=1,V_{\text{r}}=0\}$
\end_inset

.
 Panel 
\series bold
B
\series default
 shows the complex eigenvalues of the first (blue), second (green) and third
 (yellow) mode for different values of 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\{\sigma=0.2,V_{\text{th}}=1,V_{\text{r}}=1\tau_{\text{m}}=10\text{ms}\}$
\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig: LIF spectrum 2"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Fig 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: LIF eigenfunctions"

\end_inset

 shows the eigenfunctions for the first three eigenvalues (Panel 
\series bold
A
\series default
) and purely real eigenvalues (Panel 
\series bold
B
\series default
).
 We confirm that 
\begin_inset Formula $\phi_{n}(V)$
\end_inset

 fulfills the right BC given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: right bc"

\end_inset

.
 Note that 
\begin_inset Formula $\phi_{n}(V)$
\end_inset

 has a kink at the reset potential 
\begin_inset Formula $V_{\text{r}}=0$
\end_inset

 where its first derivative makes a jump.
 The size of the jump is equivalent to 
\begin_inset Formula $\sqrt{2/\pi}\approx0.8$
\end_inset

 as imposed by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF normalization"

\end_inset

.
 It must be equivalent to the value of the first derivative at threshold
 potential due to the reset BC given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: reset bc"

\end_inset

.
 The curve of the third eigenfunction (green) in panel 
\series bold
B
\series default
 shows that our implementation is numerically unstable.
 We assume that the error comes from the fact that the parabolic cylinder
 functions 
\begin_inset Formula $U(z_{n},x)$
\end_inset

 and 
\begin_inset Formula $V(z_{n},x)$
\end_inset

 rapidly change their values in the order of several magnitudes for small
 changes in 
\begin_inset Formula $V$
\end_inset

.
 This behavior becomes more extreme if 
\begin_inset Formula $z_{n}$
\end_inset

 is further away from the origin (i.e.
 for higher modes).
 In the interval 
\begin_inset Formula $V>V_{\text{r}}$
\end_inset

, the solution 
\begin_inset Formula $\phi_{n}(V)$
\end_inset

 is given by a weighted sum of 
\begin_inset Formula $U(z_{n},x)$
\end_inset

 and 
\begin_inset Formula $V(z_{n},x)$
\end_inset

 so that it is possible that the problems are due to adding extremely large
 and extremely small floating point numbers which is prone to numerical
 errors.
 We need to investigate this further to arrive at a numerically stable implement
ation.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/LIF_eigenfunctions.png
	scale 45

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Panel
\series bold
 A
\series default
 shows the eigenfunctions and 1st derivative for the first three purely
 real eigenvalues.
 Panel 
\series bold
B
\series default
 shows the eigenfunctions and 1st derivative of the first three complex
 eigenvalues.
 Model parameters are set to
\begin_inset Formula $\{\mu=1.2,\sigma=0.2,V_{\text{th}}=1,V_{\text{r}}=1\}$
\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig: LIF eigenfunctions"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Finding eigenvalues and eigenfunctions numerically 
\end_layout

\begin_layout Standard
Our goal is to develop a numerical method capable of finding a sufficient
 number of eigenfunctions and eigenvalues of the dynamical operator introduced
 in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

 for a large class of integrate-and-fire neuron models.
 The algorithm should not require too much fine tuning for individual models
 so as to make it accessible for other researchers.
 
\end_layout

\begin_layout Standard
We consider the following naive approach: First, solve the PDE given by
 Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho operator"

\end_inset

 numerically using Miind.
 We discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

 that the probability density function 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 can be decomposed into the contributions from individual modes.
 Hence, our goal is to reverse engineer the eigenfunctions and eigenvalues
 from the given solution for 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

.
 To do this we make use of the fact that the higher modes relax back to
 equilibrium on different time scales.
 If we order them from large to small time scales, i.e.
 from modes which decay slowly to modes which decay fast, then it may be
 possible to identify the first mode by looking at time window in which
 the system has almost relaxed back to equilibrium.
 In other words, we want to identify the time window in which only the zero
 and the first mode are active and all other modes are inactive.
 This would allow us to obtain an approximation for the first eigenfunction
 and the corresponding eigenvalue.
 After we know the first eigenvalue and eigenfunction, we can move on to
 the second eigenvalue and eigenfunction and so forth.
 Hence, it may be possible to find a sufficient number of eigenfunctions.
 Eigenvalues with larger imaginary parts are associated with higher frequencies,
 i.e.
 if one is interested in tracking transient non-stationary dynamics on fast
 time scales, then it will be presumably necessarily to include modes up
 to a high order in the expansion.
 
\end_layout

\begin_layout Standard
As a proof of principle, we want to test our proposed algorithm on the PIF
 and LIF neuron.
 Because the eigenfunctions and eigenvalues are known analytically for these
 models.
 Fig.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset

 shows the reconstruction of the first eigenfunction for the PIF neuron
 and compares it the to theoretical prediction.
 Although we are able successfully approximate the first eigenfunction,
 we identified the following problems.
 
\end_layout

\begin_layout Enumerate
The dynamical operator depends implicitly on time as the input rate is time
 dependent in a general setting.
 This means that eigenfunctions and eigenvalues change with time.
 To use the method of spectral decomposition in case of time dependent input,
 we need to know how the eigenfunctions change as a function of the input.
 A possible solution to this problem would be to determine the eigenfunctions
 and eigenvalues for a set of stationary inputs in a given range of interest.
 If we discretize the input range into a fine enough grid, then we may be
 able to arrive at a parameterized expression of the eigenfunctions as a
 function of the input rate.
 
\end_layout

\begin_layout Enumerate
The proposed method does not allow us to determine the eigenfunctions of
 the adjoint dynamical operator.
 The adjoint eigenfunctions are needed to determine the initial values of
 the weighting coefficients.
 They also appear in the linear system of equations which determines the
 time evolution of the weighting coefficient if the input rate is time dependent
 as discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition-1"

\end_inset

.
 One possibility would be to run the simulation for a fixed input, but different
 initial conditions for the density.
 If the initial condition corresponds to a delta-distribution at a point
 in the state space of the neuron model, then the initial value of an arbitrary
 weighting coefficient is given by the value of the associated adjoint eigenfunc
tion at this particular point.
 Suppose we would run a multitude of simulations.
 For each simulation the input is the same, but the initial value for density
 is given by a delta-distribution at different points in state space.
 If this set of points covers the entire state space, then it may be possible
 to obtain the adjoint eigenfunction.
 Note that this approach requires presumably a lot compute time if the state
 space of the neuron model is multidimensional.
 
\end_layout

\begin_layout Enumerate
The characteristic time scales on which neighboring modes decay become less
 and less distinguishable with increasing mode number (see Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:PIF firing rate"

\end_inset

).
 Hence, it will become increasingly difficult to identify time windows in
 which only one of the active modes is unknown.
 
\end_layout

\begin_layout Standard
The above concerns motivate us to explore alternative methods for determining
 eigenfunctions and eigenvalues.
 In the diffusion approximation, the dynamical operator simplifies to a
 2nd order linear differential operator.
 There exists a lot of literature on how to numerically find eigenvalues
 and eigenfunctions for differential operators subject to BCs.
 Finite difference methods and finite element methods approximate continuous
 eigenvalue problems in terms of matrix equations in a discretized representatio
n of the state space 
\begin_inset CommandInset citation
LatexCommand cite
key "Li2017"

\end_inset

.
 For an eigenvalue problem, BCs are usually incorporated into the matrix
 elements which represent the boundaries of the state space.
 For our problem, one difficulty arises from the fact that the reset BCs
 is quite exotic, and is therefore not commonly discussed in the standard
 literature.
 
\end_layout

\begin_layout Section
Outline 
\end_layout

\begin_layout Standard
In the following, we list long and short term goals we hope to achieve going
 forward.
 The project schedule is illustrated in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: Gantt-Chart"

\end_inset

.
\end_layout

\begin_layout Subsection
Long term objectives 
\end_layout

\begin_layout Standard
There are two long term objectives.
 Firstly, we want to demonstrate that describing the dynamics of neuronal
 populations in terms of the eigenmodes of of the dynamical operator introduced
 in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

 allows us to efficiently simulate large scale neuronal networks.
 Secondly, by analyzing the spectrum and the shape of the eigenfunctions
 for different neuronal models, we want to get a more intuitive understanding
 of the dynamical properties of these models.
 In particular, we are interested in how the relation between input and
 output firing rate depends on the details of the neuron model, and how
 it depends on the overall network state.
 
\end_layout

\begin_layout Subsubsection
Large scale simulations 
\end_layout

\begin_layout Standard
Everything which follows relies on the assumption that it is possible to
 develop a numerical method which allows us to determine a sufficient number
 of eigenvalues and eigenfunctions of the dynamical operator 
\begin_inset Formula $Q$
\end_inset

 introduced in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

 for a wide class of neuron models.
 Hence, this will be our main short term objective which we will discuss
 in more detail in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Short-term-objectives"

\end_inset

.
\end_layout

\begin_layout Standard
First, we want to show that it is possible to simulate a neuronal network
 of coupled populations by describing the dynamics of each population in
 terms of the time evolution of a finite set of eigenmodes.
 As a toy example, we want to look at a simple two population network consisting
 of a coupled excitatory and inhibitory population (EI-Network) both receiving
 additional external input 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunel2000"

\end_inset

.
 In particular, we want to show that our method is capable of predicting
 the network dynamics in transient regimes with non-stationary population
 firing rates are by comparing the results to direct simulations.
 If the firing rates are time dependent, then the dynamical operator will
 dependent on time as we discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

.
 As a consequence, eigenfunctions and eigenvalues will change in time which
 complicates the analysis tremendously as we discuss in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition-1"

\end_inset

.
 However, eigenfunctions and eigenvalues as a function of the input firing
 rate only need to be calculated once.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2004"

\end_inset


\end_layout

\end_inset

 simulated the population dynamics of an EI-Network of PIF neurons using
 the method of spectral decomposition.
 Hence, we are confident that once we know eigenfunctions and eigenvalues,
 network simulations for more complex neuron models should be possible.
 However, whether the method of spectral decomposition turns out be faster
 compared to other methods is still an open question.
 
\end_layout

\begin_layout Standard
Assuming that it is faster, we want to make it accessible to other researchers
 by implementing it into the Miind simulator.
 Combing multiple EI-Networks, we want to construct a simple model of a
 cortical column representing each cortical layer as an EI-Network 
\begin_inset CommandInset citation
LatexCommand cite
key "Potjans2012"

\end_inset

.
 Using such a model as an elementary building would allow for efficient
 simulations of large brain areas 
\begin_inset CommandInset citation
LatexCommand cite
key "Schuecker2017"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Mapping between spiking and rate based neuron models
\end_layout

\begin_layout Standard
As we discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition-1"

\end_inset

, expanding the density function in terms of eigenfunctions of the dynamical
 operator leads to a formal solution for the time evolution of the probability
 density function given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho operator"

\end_inset

.
 To evaluate this formal solution, we need to determine the time evolution
 of the weighting coefficients in the expansion.
 Our goal is to demonstrate that this is actually possible for a large class
 of integrate-and-fire models and arbitrary time dependent input rate.
 
\end_layout

\begin_layout Standard
Furthermore, we want to understand how the method of spectral decomposition
 relates to perturbation theory.
 The latter expands the density function in orders of the amplitude of the
 time dependent part of the input rate which is assumed to be small.
 In leading order approximation, a neuron act as a linear filter.
 The characteristic of the filter depend on the details of the neuron model
 and on the background activity in network.
 Using the analytic results known from perturbation theory, 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Ostojic2011a"

\end_inset


\end_layout

\end_inset

 established a mapping between spiking and rate based neuron models which
 only depends on the parameters of the bio-physiological motivated spiking
 neuron model.
 
\end_layout

\begin_layout Standard
Since the method of spectral decomposition does not rely on the assumption
 that the input rate is only weakly modulated in time, it can be used to
 analyze the higher order contributions which are neglected in the leading
 order results known from perturbation theory.
 Presumably, nonlinear effects will become more important if the amplitude
 of the time dependent part of input rate is increased and the neuron can
 not be sufficiently described as a linear filter.
 Finally, we want to extend the rate based neuron models introduced in 
\begin_inset CommandInset citation
LatexCommand cite
key "Ostojic2011a"

\end_inset

 such that they are capable of describing the behavior of firing rates of
 spiking neuron models in transient regimes with highly non-stationary firing
 rates.
 
\end_layout

\begin_layout Subsection
Short term objectives 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Short-term-objectives"

\end_inset


\end_layout

\begin_layout Subsubsection
Numerically stable implementation of the analytical results for the LIF
 neuron 
\end_layout

\begin_layout Standard
We discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec: LIF"

\end_inset

 that our current implementation the eigenfunctions of the LIF neuron is
 numerically unstable.
 However, 
\begin_inset CommandInset citation
LatexCommand cite
key "Deniz2017"

\end_inset

 showed that a numerical stable implementation exists.
 If the numerical problems are inherent to the behavior of the parabolic
 cylinder functions in the complex plane, then we will try to expand the
 eigenfunctions in a basis spanned by linear combinations of confluent hypergeom
etric functions as it has been done in 
\begin_inset CommandInset citation
LatexCommand cite
key "Deniz2017"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Eigenfunctions and eigenvalues of integrate-and-fire neurons
\end_layout

\begin_layout Standard
Our long term objectives depend on whether we are able to develop a numerical
 method which allows us to determine a sufficient number of eigenvalues
 and eigenfunctions of the dynamical operator 
\begin_inset Formula $Q$
\end_inset

 introduced in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

.
 Hence, this is our main objective going forward.
 
\end_layout

\begin_layout Standard
As already discussed, finite difference and finite element methods approximate
 continuous eigenvalue problems by matrix equations using a discretized
 representation of the state space.
 Mixed finite element methods treat the density and probability current
 as two separate entities.
 This formulation seems to be especially suitable for incorporating the
 reset BC given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: reset bc"

\end_inset

 which is expressed in terms of probability currents.
 Hence, as a starting point, we will try to recover the analytic results
 for the first eigenvalues and eigenfunctions of the PIF and LIF neuron
 using a mixed finite element method.
 Furthermore, we want show that our numerical method converges to the analytical
 results in the limit of vanishing grid spacing.
 
\end_layout

\begin_layout Standard
If it turns out that finite element methods are not applicable to our problem,
 then we will examine the numerical method developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Richardson2007,Richardson2008"

\end_inset

.
 It has been used to numerically determine the stationary solution of the
 FPE for one dimensional integrate-and-fire models like QIF and EIF neuron.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Ostojic2011"

\end_inset


\end_layout

\end_inset

 used this method by 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Richardson2007,Richardson2008"

\end_inset


\end_layout

\end_inset

 to determine the eigenfunctions of the EIF neuron neglecting the reset
 mechanism.
 Since we would need to investigate if it is possible to include the reset
 mechanism.
\end_layout

\begin_layout Subsubsection
One dimensional neuron models
\end_layout

\begin_layout Standard
Assuming that we can recover the eigenfunctions of the PIF and LIF neuron,
 we want to apply our numerical method to neuron models for which analytical
 results are lacking.
 It makes sense to first study the EIF and QIF neuron in the diffusion approxima
tion before moving to more complicated higher dimensional models.
 Since, analytical expressions for eigenvalues and eigenfunctions are not
 known for these models, we need to find an alternative way validate our
 results.
 As discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

, expanding the probability density function in terms of eigenmodes allows
 us to solve the time dependent FPE for arbitrary time dependent input rates.
 Knowing how the probability density function evolves in time is sufficient
 to predict the output firing rate of the neuron at all times.
 We can compare the predicted output firing rate against the firing rate
 obtained from Miind and MC simulations for validation.
\end_layout

\begin_layout Subsubsection
Higher dimensional neuron models
\end_layout

\begin_layout Standard
If we want to use the method of spectral decomposition to simulate neuronal
 networks on the population level, then it is of utmost importance to show
 that it is possible to determine eigenvalues and eigenfunctions for higher
 dimensional neuron models.
 For example, in an recurrently connected EI-Network with finite synaptic
 timescales three dimensions are needed to represent each population, the
 membrane potential, the excitatory synaptic current and the inhibitory
 synaptic current.
 
\end_layout

\begin_layout Standard
As an intermediate step, we first look at two dimensional models before
 moving to three or higher dimensional models.
 We are currently collaborating with Maurizio Mattia to study the dynamical
 properties of adaptive integrate-and-fire neuron models.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Brette2005"

\end_inset


\end_layout

\end_inset

 demonstrated that the adaptive exponential integrate-and-fire neuron can
 accurately predict the spike trains of more detailed regular spiking neuron
 model driven by realistic conductance based synaptic inputs.
 As already discussed, 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Biggio2017"

\end_inset


\end_layout

\end_inset

 presented a method to effectively reduce the dimensionality of the FPE
 by expanding the solution in terms of eigenfunctions associated with the
 membrane potential while treating the second dynamic variable as a constant.
 Integrating the solutions over the different values for the second variable
 allows them to approximate the dynamical behavior of the inherently two
 dimensional problem.
 Although this approach seems to be very promising, so far it is unclear
 under which conditions it is applicable.
 We believe that we can contribute to answering this question in two ways.
 Firstly, we can simulate two dimensional models with Miind and study the
 time evolution of the two dimensional density function and firing rates
 in full detail.
 Secondly, by providing a numerical approximation of the eigenvalues and
 eigenfunctions of the two dimensional system.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/gantt_chart.svg
	scale 40

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
#1 Develop spectral theory for adaptive integrate-and-fire neurons (collaboratio
n with Maurizio Mattia) #2 Prepare Miind tutorial for Computational Neuroscience
 Meeting (CNS) #3 Implement finite element method to find eigenvalues and
 eigenfunctions, #4 Stabilize numerical implementation for the analysis
 of the LIF neuron, #5 Study spectral decomposition of QIF and EIF neuron,
 #6 Study spectral decomposition of two dimensional neuron models, #7 Simulate
 EI-Netowrk, #8 Implementation of method of spectral decomposition into
 the Miind simulator, #9 Simulate a cortical column 
\begin_inset CommandInset label
LatexCommand label
name "fig: Gantt-Chart"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Risk assessment
\end_layout

\begin_layout Standard
Since eigenfunctions and eigenvalues can be derived analytically for the
 PIF and LIF neuron in the diffusion approximation, we are confident that
 complete sets of eigenfunctions should exist for other one dimensional
 integrate-and-fire neurons.
 However, since the analytical derivation for the LIF is already quite involved,
 it is questionable if a reliable numerical method can be developed to find
 eigenvalues and eigenfunctions for more complex models.
 For higher dimensional models, additional complexity is added.
 Not only is the state space multidimensional, it is also possible that
 boundary conditions are modified in a non trivial way as it is the case
 for models which include synapses with finite time scales 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud2002"

\end_inset

.
 
\end_layout

\begin_layout Standard
Nearly two decades ago, 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

 envisioned that the method of spectral decomposition could enable efficient
 simulations of the population dynamics of neuronal networks.
 Since then, not much progress has been made towards this goal except for
 the work of 
\begin_inset Note Note
status open

\begin_layout Plain Layout
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002,Mattia2004"

\end_inset


\end_layout

\end_inset

.
 This is maybe due to the fact that more complicated neuron models can not
 be studied analytically, and numerical methods have not been investigated
 so far.
 However, it may be very well be the case that the method of spectral decomposit
ion is not the right tool to describe the dynamics of integrate-and-fire
 models due to the noncontinuous reset mechanism.
 
\end_layout

\begin_layout Standard
If so, then we could redirect our focus towards continuous neuron including
 spike generation dynamics.
 This would simplify the analysis due to the absence of the reset boundary
 condition.
 However, continuous models need to be at least two dimensional because
 a limit cycle is needed to model the time evolution of the membrane during
 spike generation.
 
\end_layout

\begin_layout Standard
In the next three months of the project, we will focus on developing a numerical
 method to recover the known analytical results for the LIF and PIF neuron.
 After this period we should make a decision if it makes sense to continue
 further.
 If not, we can still continue the collaboration with Mattia Maurzio.
 Furthermore, we can study the input response of the LIF neuron for strongly
 temporal modulated input using the known analytical results for eigenvalues
 and eigenfunctions.
 This study would be of interest in its own right, even if the results can
 not be extended to more complex neuron models.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "transfer_report"
options "plain"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Newpage newpage
\end_inset


\end_layout

\begin_layout Section
Appendix
\end_layout

\begin_layout Subsection
Current-based synapses with finite time scale 
\begin_inset CommandInset label
LatexCommand label
name "subsec: current based synapse"

\end_inset


\end_layout

\begin_layout Standard
Current-based synapses do not dependent on the state of the neuron.
 Hence, contributions from individual synapses superimpose linearly and
 the synaptic input current 
\begin_inset Formula $I_{\text{s}}(t)$
\end_inset

 can be written as 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
I_{\text{s}}(t)=\tau_{\text{m}}\sum_{j=1}^{K}I_{j}(t).\label{eq: synaptic current}
\end{equation}

\end_inset

where 
\begin_inset Formula $I_{j}(t)$
\end_inset

 is the synaptic current associated with the 
\begin_inset Formula $j$
\end_inset

th synapse.
 Synaptic currents a characterized by a fast rise time followed by slower
 the decay time which is illustrated in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: current-based synapse"

\end_inset

.
 The time scale of the decay depends on the receptor type of the synapse.
 Common receptors are 
\end_layout

\begin_layout Enumerate
AMPA receptors which have decay time constants of the order of 
\begin_inset Formula $2$
\end_inset

ms 
\begin_inset CommandInset citation
LatexCommand cite
key "Angulo1999"

\end_inset


\end_layout

\begin_layout Enumerate
GABA
\begin_inset Formula $_{\text{A}}$
\end_inset

 receptors which have decay time constants typically 
\begin_inset Formula $5$
\end_inset

-
\begin_inset Formula $10$
\end_inset

ms 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiang1998"

\end_inset


\end_layout

\begin_layout Enumerate
NMDA which have time decay constants about 
\begin_inset Formula $100$
\end_inset

ms 
\begin_inset CommandInset citation
LatexCommand cite
key "Sah1990"

\end_inset


\end_layout

\begin_layout Standard
If the raise time of the synapse is much faster compared to its decay time,
 then the synaptic current can be approximated as a jump exponential decay
 
\begin_inset Formula 
\begin{equation}
\tau_{\text{s}}\frac{d}{dt}I_{j}(t)=-I_{j}(t)+\tau_{\text{m}}J_{j}\sum_{n}\delta(t-t_{n}^{()}),\label{eq: exponential synapse}
\end{equation}

\end_inset

where 
\begin_inset Formula $\tau_{\text{s}}$
\end_inset

 is the synaptic time constant.
 At each spike arrival, 
\begin_inset Formula $I_{i}(t)$
\end_inset

 makes a jump by 
\begin_inset Formula $J_{i}$
\end_inset

 followed by an exponential decay back to zero which is illustrated by the
 blue curve in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: current-based synapse"

\end_inset

.
 A synaptic raise time can be included by modeling 
\begin_inset Formula $I_{i}(t)$
\end_inset

 by the set of equations 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud2002"

\end_inset


\begin_inset Formula 
\begin{align}
\tau_{\text{s}}\frac{dI_{\text{s}}}{dt} & =-I_{\text{s}}(t)+I_{\text{r}}(t)\nonumber \\
\tau_{\text{r}}\frac{dI_{\text{r}}}{dt} & =-I_{\text{r}}(t)+\tau_{\text{m}}J_{i}\sum_{n}\delta(t-t_{n}^{(i)}).\label{eq: synaptic current raise}
\end{align}

\end_inset

The synaptic value for different ratios 
\begin_inset Formula $\tau_{\text{r}}$
\end_inset

 is shown in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: current-based synapse"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/current_based_synapse.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Synaptic current (Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: synaptic current raise"

\end_inset

) caused by single spike arrival for 
\begin_inset Formula $\tau_{\text{s}}=2.0$
\end_inset

 ms and different values for 
\begin_inset Formula $\tau_{\text{r}}=[0,\,0.5,\,1.0,\,2.0]$
\end_inset

 ms.
 Note that for 
\begin_inset Formula $\tau_{\text{r}}=0$
\end_inset

, we recover Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: exponential synapse"

\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig: current-based synapse"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Solving the Fokker-Planck equation 
\begin_inset CommandInset label
LatexCommand label
name "subsec: FPE Details"

\end_inset


\end_layout

\begin_layout Subsubsection
Stationary case 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Stationary-case"

\end_inset


\end_layout

\begin_layout Standard
To determine the stationary firing rate 
\begin_inset Formula $r(t)=r_{0}$
\end_inset

 of a network, we need to solve the stationary FPE.
 Setting time time derivative of the probability density function on the
 l.h.s.
 of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE continuity"

\end_inset

 to zero yields 
\begin_inset Formula 
\begin{equation}
0=-\frac{\partial}{\partial V}J(V,t).
\end{equation}

\end_inset

The above equation tells us that the flux must be constant.
 From left BC given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: left bc"

\end_inset

 follows that 
\begin_inset Formula $J(V,t)$
\end_inset

 must be zero for 
\begin_inset Formula $V\rightarrow-\infty$
\end_inset

.
 From the reset BC given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: reset bc"

\end_inset

 follows that the flux must be equivalent to the rate 
\begin_inset Formula $r_{0}$
\end_inset

 at threshold.
 Hence, 
\begin_inset Formula $J(V,t)$
\end_inset

 must be 
\begin_inset Formula $0$
\end_inset

 for 
\begin_inset Formula $V<V_{r}$
\end_inset

 and than makes a jump to 
\begin_inset Formula $r_{0}$
\end_inset

 at the reset the 
\begin_inset Formula $V_{r}$
\end_inset

 which can be written as
\begin_inset Formula 
\begin{equation}
J(V,t)=r_{0}\Theta(V-V_{\text{th}})\Theta(V-V_{\text{r}}).\label{eq: flux stationary}
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE flux"

\end_inset

 into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: flux stationary"

\end_inset

 yields the stationary probability density 
\begin_inset Formula $\rho_{0}(V)$
\end_inset

.
 Knowing 
\begin_inset Formula $\rho_{0}(V)$
\end_inset

, we can determine the stationary firing rate 
\begin_inset Formula $r_{0}$
\end_inset

 by calculating the probability current at threshold
\begin_inset Formula 
\begin{align}
r_{0} & =J(V_{\text{th}},t)=\Phi(\mu,\sigma^{2}),\label{eq: rate}
\end{align}

\end_inset

where 
\begin_inset Formula $\Phi(\mu,\sigma^{2})$
\end_inset

 is called gain-function.
 For the LIF neuron, 
\begin_inset Formula $\Phi(\mu,\sigma^{2})$
\end_inset

 is given by
\begin_inset Formula 
\begin{equation}
\Phi(\mu,\sigma^{2})=\frac{1}{\tau_{\text{m}}\sqrt{\pi}}\int_{\frac{V_{\text{r}}-\mu}{\sigma}}^{\frac{V_{\text{th}}-\mu}{\sigma}}(1+\text{erf}(x))e^{x^{2}}dx.
\end{equation}

\end_inset

It is important to notice that 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

 depend on the firing rate due to recurrent connections in the network.
 Hence, we need to solve Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rate"

\end_inset

 self-consistently to obtain the stationary firing rate.
 So far we only looked at a single population network.
 In a network with multiple populations 
\begin_inset Formula $\boldsymbol{\alpha}=\{1,2,\ldots,M\}$
\end_inset

, mean 
\begin_inset Formula $\mu$
\end_inset

 and variance 
\begin_inset Formula $\sigma$
\end_inset

 of the Gaussian white noise are given by 
\begin_inset Formula 
\begin{align}
\mu_{\alpha}(\boldsymbol{r}) & =\tau_{\text{m}}\sum_{\beta}K_{\alpha\beta}J_{\alpha\beta}r_{\beta}+\mu_{\text{ext}},\label{eq: mu multi}\\
\sigma_{a}^{2}(\boldsymbol{r}) & =\tau_{\text{m}}\sum_{\beta}K_{\alpha\beta}J_{\alpha\beta}r_{\beta}+\sigma_{\text{ext}}^{2}.\label{eq: sigma multi}
\end{align}

\end_inset

For the LIF neuron, the firing rate of population 
\begin_inset Formula $\alpha$
\end_inset

 is given by 
\begin_inset Formula 
\[
r_{\alpha}(\boldsymbol{r})=\Phi(\mu_{\alpha}(\boldsymbol{r}),\sigma_{\alpha}^{2}(\boldsymbol{r}))=\frac{1}{\tau_{\text{m}}\sqrt{\pi}}\int_{\frac{V_{\text{r}}-\mu_{\alpha}}{\sigma_{\alpha}}}^{\frac{V_{\text{th}}-\mu_{\alpha}}{\sigma_{\alpha}}}(1+\text{erf}(x))e^{x^{2}}dx,
\]

\end_inset

where 
\begin_inset Formula $\mu_{\alpha}$
\end_inset

 and 
\begin_inset Formula $\sigma_{\alpha}$
\end_inset

 depend on the average firing rates of all populations 
\begin_inset Formula $\boldsymbol{r}=\{r_{1},r_{2},\ldots,r_{M})$
\end_inset

.
 Solving the set of 
\begin_inset Formula $M$
\end_inset

 equations in self-consistent manner yields the stationary firing rates
 
\begin_inset Formula $\boldsymbol{r}$
\end_inset

 of the different populations.
 A priori, it is not clear if the stationary states are stable or unstable.
 
\end_layout

\begin_layout Subsubsection
Time dependent case 
\end_layout

\begin_layout Standard
To analyze the stability of the stationary state, we need to solve the FPE
 for a time dependent input firing rate 
\begin_inset Formula $r(t)$
\end_inset

.
 We split the firing rate into a stationary part 
\begin_inset Formula $r$
\end_inset

 and a time dependent part 
\begin_inset Formula $\delta r(t)$
\end_inset

 
\begin_inset Formula 
\begin{equation}
r(t)=r+\delta r(t),
\end{equation}

\end_inset

If the amplitude of temporal modulation 
\begin_inset Formula $\delta r(t)$
\end_inset

 of the firing rate is small compared to its baseline value 
\begin_inset Formula $\left|\delta r(t)\right|/r\ll$
\end_inset

1, then perturbation theory can be used approximate the solution of the
 FPE 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

.
 The split the Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: mu"

\end_inset

 for the mean and for the Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: sig"

\end_inset

 for variance of the Gaussian white noise into a constant and time dependent
 part 
\begin_inset Formula 
\begin{align}
\mu(t) & =\mu+\delta\mu(t),\\
\sigma^{2}(t) & =\sigma^{2}+\delta\sigma^{2}(t).
\end{align}

\end_inset

This allow us to write Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE"

\end_inset

 as
\begin_inset Formula 
\begin{align}
\frac{\partial\rho(V,t)}{\partial t} & =\left(-\frac{\partial}{\partial V}\frac{\mu+f(V)}{\tau_{\text{m}}}+\frac{\sigma^{2}}{2\tau_{\text{m}}}\frac{\partial^{2}}{\partial V^{2}}\right)\rho(V,t)+\left(-\delta\mu(t)\frac{\partial}{\partial V}+\frac{\delta\sigma^{2}(t)}{2}\frac{\partial^{2}}{\partial V^{2}}\right)\rho(V,t)\label{eq: FPE time dependent-3}
\end{align}

\end_inset

Note that 
\begin_inset Formula $\delta\mu(t)$
\end_inset

 and 
\begin_inset Formula $\delta\sigma(t)$
\end_inset

 both depend implicitly one time through 
\begin_inset Formula $\delta r(t)$
\end_inset

.
 We define the relative rate modulation 
\begin_inset Formula $\epsilon(t)=\delta r(t)/r$
\end_inset

 as a small parameter and write Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE time dependent-3"

\end_inset

 as
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(V,t)}{\partial t}=L_{0}\rho(V,t)+\epsilon(t)L_{1}\rho(V,t)\label{eq: FPE time dependent}
\end{equation}

\end_inset

The above equations has been be solved to first order in 
\begin_inset Formula $\epsilon(t)$
\end_inset

 using the following steps.
 Expand 
\begin_inset Formula $\rho(V,t)$
\end_inset

 around the stationary solution 
\begin_inset Formula $\rho_{0}(V)$
\end_inset

 discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Stationary-case"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\rho(V,t)=\rho_{0}(V)+\rho_{1}(V,t)+\rho_{2}(V,t)+\ldots\label{eq: rho expansion}
\end{equation}

\end_inset

with 
\begin_inset Formula $\rho_{n}(V,t)\sim\mathcal{O}(\epsilon(t)^{n})$
\end_inset

.
 Substitute Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho expansion"

\end_inset

 into Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE time dependent"

\end_inset

 and keep only terms up to first order in 
\begin_inset Formula $\epsilon(t)$
\end_inset

 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho_{1}(V,t)}{\partial t}=L_{0}\rho_{1}(V,t)+\epsilon(t)L_{1}\rho_{0}(V)+\mathcal{O}(\epsilon)\label{eq: FPE time dependent-1}
\end{equation}

\end_inset

where we used that 
\begin_inset Formula $L_{0}\rho(V)=0$
\end_inset

.
 The above equation is a linear second order inhomogeneous partial differential
 equation.
 Its solution is leading order time dependent correction 
\begin_inset Formula $\rho_{1}(V,t)$
\end_inset

 to the stationary solution for time dependent input rate 
\begin_inset Formula $r(t)$
\end_inset

.
 It is sufficient to consider only sinusoidal modulations, because we can
 replace by 
\begin_inset Formula $\epsilon(t)$
\end_inset

 its Fourier transform 
\begin_inset Formula 
\begin{equation}
\epsilon(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}d\omega\,\epsilon(\omega)e^{i\omega t},
\end{equation}

\end_inset

and solve each frequency component separately due to the linearity of the
 problem.
 Hence, we make a complex ansatz 
\begin_inset Formula 
\begin{equation}
\epsilon(t)=\epsilon(\omega)e^{i\omega t}
\end{equation}

\end_inset

Substituting this Ansatz into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE time dependent-1"

\end_inset

 and using separation of variables 
\begin_inset Formula $\rho_{1}(V,t)=\rho_{1}(V)e^{i\omega t}$
\end_inset

 yields an inhomogeneous linear ordinary differential equation for 
\begin_inset Formula $\rho_{1}(V)$
\end_inset


\begin_inset Formula 
\begin{equation}
\left(i\omega-L_{0}\right)\rho_{1}(V,t)=L_{1}\rho_{0}(V).\label{eq: FPE time dependent-2}
\end{equation}

\end_inset

The solution of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE time dependent-2"

\end_inset

 is given by a homogeneous solution plus a particular solution which reproduces
 the inhomogeneity on the r.h.s.
 The free coefficients of the homogeneous solution need to be determined
 such that the sum of the homogeneous and the particular solution fulfill
 the boundary conditions which we discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Boundary-conditions"

\end_inset

.
 From the solution of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE time dependent-2"

\end_inset

, the transfer function 
\begin_inset Formula $T(\omega)$
\end_inset

 can be derived which determines how a Fourier coefficient 
\begin_inset Formula $\epsilon(\omega)$
\end_inset

 on the input is related to the Fourier coefficient 
\begin_inset Formula $\hat{\epsilon}(\omega)$
\end_inset

 on the output side 
\begin_inset Formula 
\begin{equation}
\hat{\epsilon}(\omega)=T(\omega)\epsilon(\omega).\label{eq: transfer function}
\end{equation}

\end_inset

Taking the Fourier back transform of the above equation shows that the neurons
 act as linear filters in first order approximation 
\begin_inset Formula 
\begin{equation}
\delta\hat{r}(t)=r\int_{-\infty}^{t}T(t)\epsilon(t).
\end{equation}

\end_inset

The characteristics of the linear filter are determined by 
\begin_inset Formula $T(\omega)$
\end_inset

.
\end_layout

\begin_layout Subsection
Spectral decomposition 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Spectral-decomposition-1"

\end_inset


\end_layout

\begin_layout Standard
To determine the time evolution of the weighting coefficients 
\begin_inset Formula $c_{n}$
\end_inset

 in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: eigenfunction expansion"

\end_inset

, we need to construct a basis 
\begin_inset Formula $\left\{ \tilde{\phi}_{n}(\boldsymbol{v},t)\right\} $
\end_inset

 which is orthogonal to the basis spanned by the eigenfunctions 
\begin_inset Formula $\{\phi_{n}(\boldsymbol{v},t)\}$
\end_inset

 of the dynamical operator 
\begin_inset Formula $Q$
\end_inset

.
 We drop the time argument for the rest of this section for convenience.
 
\end_layout

\begin_layout Standard
In the following, we will show that this basis 
\begin_inset Formula $\left\{ \tilde{\phi}_{n}(\boldsymbol{v},t)\right\} $
\end_inset

 is spanned by the eigenfunctions of the adjoint operator 
\begin_inset Formula $Q^{\dagger}$
\end_inset

.
 We equip the state space with an inner product given by the bilinear form
 
\begin_inset Formula 
\begin{equation}
(\tilde{\phi},\phi)=\int d\boldsymbol{v}\,\tilde{\phi}(\boldsymbol{v})\phi(\boldsymbol{v}).\label{eq: inner product}
\end{equation}

\end_inset

For a given inner product, the adjoint operator 
\begin_inset Formula $Q^{\dagger}$
\end_inset

 of 
\begin_inset Formula $Q$
\end_inset

 is defined by the equation 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
(\tilde{\phi},Q\phi)=(Q^{\dagger}\tilde{\phi},\phi).\label{eq: Q adjoint}
\end{equation}

\end_inset

The eigenfunctions 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 of the adjoint operator 
\begin_inset Formula $O^{\dagger}$
\end_inset

 are given by 
\begin_inset Formula 
\begin{equation}
Q^{\dagger}\tilde{\phi}_{n}(\boldsymbol{v})=\tilde{\lambda}_{n}\tilde{\phi}_{n}(\boldsymbol{v}).
\end{equation}

\end_inset

The boundary conditions for the eigenfunctions 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 must be chosen such the surface terms in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: Q adjoint"

\end_inset

 vanish.
 We use that eigenvalues of an operator and its adjoint operator are equivalent
 
\begin_inset Formula $\tilde{\lambda}_{n}=\lambda_{n}$
\end_inset

 and write 
\begin_inset Formula 
\begin{equation}
\lambda_{n}(\tilde{\phi}_{m},\tilde{\phi}_{n})=(\tilde{\phi}_{m},Q\tilde{\phi}_{n})=(Q^{\dagger}\tilde{\phi}_{m},\tilde{\phi}_{n})=\lambda_{m}(\tilde{\phi}_{m},\tilde{\phi}_{n}),
\end{equation}

\end_inset

where we used Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: Q adjoint"

\end_inset

 in the third step.
 Subtracting the r.h.s.
 from the from the l.h.s.
 yields 
\begin_inset Formula 
\begin{equation}
(\lambda_{n}-\lambda_{m})(\tilde{\phi}_{m},\tilde{\phi}_{n})=0
\end{equation}

\end_inset

Since one or the other factor must vanish, we find that set the eigenfunctions
 of 
\begin_inset Formula $Q$
\end_inset

 and 
\begin_inset Formula $Q^{\dagger}$
\end_inset

 are orthogonal for 
\begin_inset Formula $n\neq m$
\end_inset

.
 Using proper normalization, we can write 
\begin_inset Formula 
\begin{equation}
(\tilde{\phi}_{m},\phi_{n})=\delta_{nm}\label{eq: orthogonality}
\end{equation}

\end_inset

Hence, the set of eigenfunctions 
\begin_inset Formula $\{\tilde{\phi}_{n}(\boldsymbol{v}),\phi_{n}(\boldsymbol{v})\}$
\end_inset

 form a biorthonormal set.
 Some remarks on the properties of spectrum of 
\begin_inset Formula $Q$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

: 
\end_layout

\begin_layout Enumerate
The real part of all eigenvalues is negative 
\begin_inset Formula $\text{Re}(\lambda_{n})\leq0$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\lambda_{0}=0$
\end_inset

 is a eigenvalue of 
\begin_inset Formula $Q$
\end_inset

 and the associated eigenfunction 
\begin_inset Formula $\phi_{0}(\boldsymbol{v})$
\end_inset

 is the stationary solution 
\begin_inset Formula $Q\rho_{0}(\boldsymbol{v})=0$
\end_inset


\end_layout

\begin_layout Enumerate
The corresponding eigenfunction 
\begin_inset Formula $\tilde{\phi}_{0}(\boldsymbol{v})$
\end_inset

 is a constant.
 It needs to be set to 
\begin_inset Formula $1$
\end_inset

 to ensure that 
\begin_inset Formula $\rho_{0}(\boldsymbol{v})$
\end_inset

 is properly normalized 
\begin_inset Formula $(\tilde{\phi}_{0}(\boldsymbol{v}),\phi_{0}(\boldsymbol{v}))=\int d\boldsymbol{v}\,\rho_{0}(\boldsymbol{v})=1$
\end_inset

 
\end_layout

\begin_layout Enumerate
From 
\begin_inset Formula $(\tilde{\phi}_{0}(\boldsymbol{v}),\phi_{n}(\boldsymbol{v}))=0$
\end_inset

 follows 
\begin_inset Formula $0=\int d\boldsymbol{v}\phi_{n}(\boldsymbol{v})$
\end_inset

, i.e.
 all probability is contained in the zero mode 
\begin_inset Formula $\phi_{0}(\boldsymbol{v})=\rho_{0}(\boldsymbol{v})$
\end_inset

 
\end_layout

\begin_layout Standard
We are now ready to determine the time evolution of the weighting coefficients
 for a given initial condition 
\begin_inset Formula $\rho(\boldsymbol{v},0)=f(\boldsymbol{v})$
\end_inset

.
 We start with the simplest example, a population of non-interacting neurons.
 
\end_layout

\begin_layout Subsubsection
Non-interacting neurons: Stationary input rate 
\end_layout

\begin_layout Standard
By non-interacting, we mean that all recurrent connections in the network
 are cut.
 In this case, the population can be viewed as a set of independent neurons
 all receiving the same constant external input rate 
\begin_inset Formula $r_{\text{ext}}=r$
\end_inset

.
 We start from Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho operator"

\end_inset


\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=Q(\boldsymbol{v},r)\rho(\boldsymbol{v},t).
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: eigenfunction expansion"

\end_inset

 into the above equation yields 
\begin_inset Formula 
\begin{equation}
\sum_{m=-\infty}^{\infty}\left(\frac{\partial}{\partial t}c_{m}(t)\right)\phi_{m}(\boldsymbol{v})=\sum_{m=-\infty}^{\infty}c_{m}(t)\lambda_{m}\phi_{m}(\boldsymbol{v})
\end{equation}

\end_inset

Note that the eigenvalues and eigenfunctions are both time independent because
 
\begin_inset Formula $r$
\end_inset

 is constant.
 Multiplying with 
\begin_inset Formula $\tilde{\phi}_{n}(\boldsymbol{v})$
\end_inset

 from the l.h.s.
 and integrating over the state space yields 
\begin_inset Formula 
\begin{align}
\sum_{m=-\infty}^{\infty}\left(\frac{\partial}{\partial t}c_{m}(t)\right)(\tilde{\phi}_{n},\phi_{m}) & =\sum_{m=-\infty}^{\infty}\lambda_{m}(\phi_{n},\tilde{\phi}_{m}).
\end{align}

\end_inset

Using that 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 and 
\begin_inset Formula $\tilde{\phi}$
\end_inset

 are orthogonal, we arrive at 
\begin_inset Formula 
\begin{equation}
\frac{\partial}{\partial t}c_{n}(t)=\lambda_{m}.
\end{equation}

\end_inset

Hence, we find that weighting coefficients 
\begin_inset Formula $c_{n}(t)$
\end_inset

 are given by 
\begin_inset Formula 
\begin{equation}
c_{n}(t)=c_{n}(0)e^{\lambda_{n}t}.\label{eq: c_n(t)}
\end{equation}

\end_inset

The initial value 
\begin_inset Formula $c_{n}(0)$
\end_inset

 of the weighting coefficients can be determined from the initial condition
 
\begin_inset Formula $\rho(\boldsymbol{v},0)=f(\boldsymbol{v})$
\end_inset

 
\begin_inset Formula 
\begin{equation}
c_{n}(0)=(\tilde{\phi},f(\boldsymbol{v})).
\end{equation}

\end_inset

From 
\begin_inset Formula $\text{Re}(\lambda_{n})<0$
\end_inset

 follows that 
\begin_inset Formula ${\displaystyle \lim_{t\rightarrow\infty}}c_{n}(t)=0$
\end_inset

 expect for 
\begin_inset Formula $c_{0}(t)=1$
\end_inset

.
 Hence, all modes except for the zero mode die out and 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 converges to the stationary solution 
\begin_inset Formula $\phi_{0}(\boldsymbol{v})=\rho_{0}(\boldsymbol{v}).$
\end_inset

 The time scale of the exponential decay 
\begin_inset Formula $\tau_{n}$
\end_inset

 is given by 
\begin_inset Formula $\tau_{n}=1/\left|\text{Re}(\lambda_{1})\right|$
\end_inset

.
 Hence, it makes sense to order the modes according to the magnitude of
 the real part of their associated eigenvalues 
\begin_inset Formula 
\begin{equation}
0\leq\left|\text{Re}(\lambda_{1})\right|\leq\left|\text{Re}(\lambda_{2})\right|\leq\left|\text{Re}(\lambda_{3})\right|\leq\ldots
\end{equation}

\end_inset


\end_layout

\begin_layout Subsubsection
Non-interacting neurons: Time dependent input rate
\end_layout

\begin_layout Standard
If the external rate is time dependent 
\begin_inset Formula $r_{\text{ext}}(t)=r(t)$
\end_inset

, then eigenvalues and eigenvectors will be time dependent as well.
 We start from Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho operator"

\end_inset


\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=Q(\boldsymbol{v},r(t))\rho(\boldsymbol{v},t).
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: eigenfunction expansion"

\end_inset

 into the above equation yields 
\begin_inset Formula 
\begin{align}
\sum_{m}\frac{\partial}{\partial t}\left(c_{m}(t)\phi_{m}(\boldsymbol{v},t)\right) & =\sum_{m}\lambda_{m}c_{m}(t)\phi_{m}(\boldsymbol{v},t),\nonumber \\
\sum_{m}\left\{ \frac{\partial c_{m}(t)}{\partial t}\phi_{m}(\boldsymbol{v},t)+c_{m}(t)\frac{\partial\phi_{m}(\boldsymbol{v},t)}{\partial r}\frac{\partial r(t)}{\partial t}\right\}  & =\sum_{m}\lambda_{m}c_{m}(t)\phi_{m}(\boldsymbol{v},t),
\end{align}

\end_inset

where we used the product and chain rule 
\begin_inset Formula 
\begin{equation}
\frac{\partial\phi_{m}(\boldsymbol{v},t)}{\partial t}=\frac{\partial\phi_{m}(\boldsymbol{v},t)}{\partial r}\frac{\partial r(t)}{\partial t},
\end{equation}

\end_inset

on the l.h.s.
 Multiplying from the left with 
\begin_inset Formula $\tilde{\phi}_{n}(\boldsymbol{v},t)$
\end_inset

 and integrating over the state space yields 
\begin_inset Formula 
\begin{align}
\sum_{m}\left\{ \frac{\partial c_{m}(t)}{\partial t}(\tilde{\phi}_{n},\phi_{m})+c_{m}(t)\frac{\partial r(t)}{\partial t}(\tilde{\phi}_{n},\frac{\partial\phi_{m}}{\partial r})\right\}  & =\sum_{m}\lambda_{m}(\tilde{\phi}_{n}(\boldsymbol{v},t),\phi_{m}(\boldsymbol{v},t))\nonumber \\
\frac{\partial c_{m}(t)}{\partial t}+\frac{\partial r(t)}{\partial t}(\tilde{\phi}_{n},\frac{\partial\phi_{m}}{\partial r})c_{m}(t) & =\lambda_{m}c_{m}(t)
\end{align}

\end_inset

Defining the matrix 
\begin_inset Formula $A_{mn}=(\tilde{\phi}_{n},\frac{\partial\phi_{m}}{\partial r})$
\end_inset

, the above set of equations can be written as matrix equation 
\begin_inset Formula 
\begin{equation}
\frac{\partial\boldsymbol{c}}{\partial t}=\left(\boldsymbol{\Lambda}-\frac{\partial r(t)}{\partial t}\boldsymbol{A}_{mn}\right)\boldsymbol{c}.
\end{equation}

\end_inset

Note that the matrices 
\begin_inset Formula $\boldsymbol{A}_{nm}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{\Lambda}$
\end_inset

 both depend on time due to the time dependence of 
\begin_inset Formula $\lambda_{n}(t)$
\end_inset

, 
\begin_inset Formula $\tilde{\phi}_{n}(t)$
\end_inset

 and 
\begin_inset Formula $\phi_{m}(t)$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Interacting-neurons 
\end_layout

\begin_layout Standard
To include the interaction between neurons due to recurrent connections,
 we need to express the output firing given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: r"

\end_inset

 
\begin_inset Formula 
\begin{equation}
r(t)=R[\boldsymbol{J}(\boldsymbol{v},t)],
\end{equation}

\end_inset

rate in terms of eigenfunctions.
 The probability current 
\begin_inset Formula $J(\boldsymbol{v},t)$
\end_inset

 can be expressed in terms of the probability density function using Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: probability current"

\end_inset


\begin_inset Formula 
\[
J(\boldsymbol{v},t)=C\rho(\boldsymbol{v},t).
\]

\end_inset

We expand 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 in terms of the eigenfunctions and arrive at the coupled set of equations
 
\begin_inset Formula 
\begin{align*}
\frac{\partial\boldsymbol{c}}{\partial t} & =\left(\boldsymbol{\Lambda}-\frac{\partial r(t)}{\partial t}\boldsymbol{A}\right)\boldsymbol{c},\\
r(t) & =\sum_{n}R\left[C\left(c_{n}(t)\phi_{n}(\boldsymbol{v},t)\right)\right],
\end{align*}

\end_inset

which needs to be solved self-consistently.
 For a one dimensional integrate-and-fire neuron model, the equation for
 the firing rate simplifies to 
\begin_inset Formula 
\[
r(t)=-\frac{1}{2}\sum_{n}\sigma^{2}(t)c_{n}(t)\left.\partial_{V}\phi_{n}(V,t)\right|_{V=\theta},
\]

\end_inset

which can be written as 
\begin_inset Formula 
\[
r(t)=\boldsymbol{f}\boldsymbol{c},
\]

\end_inset

where 
\begin_inset Formula $f_{n}=-\frac{1}{2}\sigma^{2}(t)c_{n}(t)$
\end_inset

.
 
\end_layout

\begin_layout Subsection
Spectrum and eigenfunctions of the leaky integrate-and-fire neuron 
\begin_inset CommandInset label
LatexCommand label
name "subsec: ef LIF"

\end_inset


\end_layout

\begin_layout Standard
The Fokker-Planck equation (FPE) for the LIF neuron is given by 
\begin_inset Formula 
\begin{equation}
\partial_{t}\rho(V,t)=L\rho(V,t),\quad L=\partial_{V}\left(\frac{1}{\tau}\left(V-\mu\right)+\frac{\sigma^{2}}{2\tau}\partial_{V}\right).\label{eq: LIF Fokker-Planck}
\end{equation}

\end_inset

The FP operator can be brought into a more simpler form by making the variable
 transformation
\begin_inset Formula 
\begin{equation}
s=\frac{t}{\tau},\quad x=\frac{\sqrt{2}}{\sigma}(V-\mu).
\end{equation}

\end_inset

Using
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\partial_{t}\rho & =\frac{1}{\tau}\rho_{s},\nonumber \\
\partial_{V}\rho & =\frac{\sqrt{2}}{\sigma}\partial_{x}\rho,\nonumber \\
\partial_{V}^{2}\rho & =\frac{2}{\sigma^{2}}\partial_{x}^{2}\rho,
\end{align}

\end_inset

Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF Fokker-Planck"

\end_inset

 becomes
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\partial_{s}\rho(x,s)=L\rho(x,s),\quad L=\partial_{x}\left(x+\partial_{x}\right).\label{eq: LIF Fokker-Planck x}
\end{equation}

\end_inset

Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF Fokker-Planck x"

\end_inset

 can be rewritten as a continuity equation 
\begin_inset Formula 
\begin{equation}
\partial_{s}\rho(x,s)=-\partial_{x}J(x,s).
\end{equation}

\end_inset

The probability current 
\begin_inset Formula $J(x,s)$
\end_inset

 in the new coordinates is given by 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
J(x,s)=-\left(x+\partial_{x}\right)\rho(x,s).
\end{equation}

\end_inset

In the new coordinates, the boundary conditions discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Boundary-conditions"

\end_inset

 can be written as:
\end_layout

\begin_layout Enumerate
Left boundary condition: We introduce a reflecting barrier at 
\begin_inset Formula $V_{\text{min}}$
\end_inset

, i.e the membrane potential 
\begin_inset Formula $V$
\end_inset

 can not take values smaller than 
\begin_inset Formula $V_{\text{min}}$
\end_inset

.
 Hence, neurons can not enter the system from left side of 
\begin_inset Formula $V_{\text{min}}$
\end_inset

, and therefore the probability current 
\begin_inset Formula $J(x,s)$
\end_inset

 must be zero at 
\begin_inset Formula $x_{\text{min}}=\sqrt{2}(V_{\text{min}}-\mu)/\sigma$
\end_inset


\begin_inset Formula 
\begin{equation}
0=J(x_{\text{min}},s)=\left.-\left(x+\partial_{x}\right)\rho(x,s)\right|_{x=x_{\text{min}}}\label{eq: left bc-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Right boundary condition: We introduce an absorbing boundary at 
\begin_inset Formula $V_{\text{max}}$
\end_inset

, i.e.
 neurons which go over threshold vanish, i.e.
 the density function 
\begin_inset Formula $\rho(x,t)$
\end_inset

 must be zero for values 
\begin_inset Formula $x\geq x_{\theta}=\sqrt{2}(V_{\text{th}}-\mu)/\sigma$
\end_inset


\begin_inset Formula 
\begin{equation}
\rho(x_{\theta},t)=0\label{eq: right bc-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Reset boundary condition: To ensure conversation of probability, neurons
 who vanish at the absorbing boundary at 
\begin_inset Formula $V_{\text{th}}$
\end_inset

 must be reinserted at the reset value 
\begin_inset Formula $V_{\text{r}}$
\end_inset

.
 Hence, the probability current on the right of the reset 
\begin_inset Formula $V_{\text{r}}+\epsilon$
\end_inset

 must be equal to the current from the left of the reset 
\begin_inset Formula $V_{\text{r}}-\epsilon$
\end_inset

 plus the probability current at the threshold 
\begin_inset Formula 
\begin{equation}
J(x_{\theta},t)=\lim_{\epsilon\rightarrow0^{+}}\left[J(x_{\text{r}}+\epsilon,t)-J(x_{\text{r}}-\epsilon,t)\right]\label{eq: reset bc-1}
\end{equation}

\end_inset

with 
\begin_inset Formula $x_{\text{r}}=\sqrt{2}(V_{\text{r}}-\mu)/\sigma$
\end_inset

 
\end_layout

\begin_layout Standard
The eigenfunctions of the FP operator are determined by 
\begin_inset Formula 
\begin{equation}
L\phi(x)=\partial_{x}\left(x+\partial_{x}\right)\phi(x)=\lambda\phi(x).\label{eq: eigenfunction x}
\end{equation}

\end_inset

Here, we dropped the subscript 
\begin_inset Formula $n$
\end_inset

 for convenience.
 Note that the FP operator contains a single derivative, i.e.
 it is not self-adjoint.
 However, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: eigenfunction x"

\end_inset

 can be transformed into a Schroedinger type equation 
\begin_inset Formula 
\[
\left(\partial_{x}^{2}\varphi(x)+V(x)\right)\varphi(x)=\lambda\varphi(x)
\]

\end_inset

with help of a similarity transformation 
\begin_inset Formula $f(x)$
\end_inset


\begin_inset Formula 
\begin{equation}
\varphi(x)=f^{-1}(x)\phi(x).\label{eq: phi2}
\end{equation}

\end_inset

Our goal is to determine 
\begin_inset Formula $f(x)$
\end_inset

 such that 
\begin_inset Formula 
\begin{equation}
f(x)^{-1}Lf(x)=\partial_{x}^{2}+V(x).\label{eq: L transformed}
\end{equation}

\end_inset

It turns out that 
\begin_inset Formula $f(x)=e^{-\frac{x^{2}}{4}}$
\end_inset

 and 
\begin_inset Formula 
\begin{align}
V(x) & =-\frac{1}{4}x^{2}+\frac{1}{2}.\label{eq: LIF potential}
\end{align}

\end_inset

We multiply Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: eigenfunction x"

\end_inset

 from the left with 
\begin_inset Formula $f^{-1}$
\end_inset

 and insert a one 
\begin_inset Formula $1=f\cdot f^{-1}$
\end_inset

 on the r.h.s of the FP operator
\begin_inset Formula 
\begin{equation}
f^{-1}Lf\cdot f^{-1}\phi=\lambda f^{-1}\phi.
\end{equation}

\end_inset

We now use Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: phi2"

\end_inset

 and Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: L transformed"

\end_inset

, to arrive at
\begin_inset Formula 
\begin{equation}
\left(\partial_{x}^{2}+V(x)\right)\varphi=\lambda\varphi.
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF potential"

\end_inset

 into above the equation yields 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\left(\partial_{x}^{2}-\frac{1}{4}x^{2}+\frac{1}{2}\right)\varphi & =\lambda\varphi,
\end{align}

\end_inset

which can be written as 
\begin_inset Formula 
\begin{equation}
\partial_{x}^{2}\varphi-\left(\frac{1}{4}x^{2}+z\right)\varphi=0,\label{eq: LIF eingefunction transformed}
\end{equation}

\end_inset

where 
\begin_inset Formula $z=\lambda-\frac{1}{2}$
\end_inset

.
 A numerical stable independent pair of solutions for the above equation
 are the parabolic cylinder functions 
\begin_inset Formula $U(z,x)$
\end_inset

 and 
\begin_inset Formula $V(z,x)$
\end_inset

 when 
\begin_inset Formula $x$
\end_inset

 is positive and 
\begin_inset Formula $U(z,-x)$
\end_inset

 and 
\begin_inset Formula $V(z,-x)$
\end_inset

 when 
\begin_inset Formula $x$
\end_inset

 is negative 
\begin_inset CommandInset citation
LatexCommand citep
key "Abramowitz1965"

\end_inset

.
 Hence, we can represent 
\begin_inset Formula $\varphi(x)$
\end_inset

 as a linear combination of 
\begin_inset Formula $U(z,x)$
\end_inset

 and 
\begin_inset Formula $V(z,x)$
\end_inset


\begin_inset Formula 
\begin{equation}
\varphi(x)=aV(z,\pm x)+bU(z,\pm x)
\end{equation}

\end_inset

Note that 
\begin_inset Formula $x\in[-\infty,\,x_{\theta}]$
\end_inset

 with 
\begin_inset Formula $x_{\theta}=\sqrt{2}(V_{\text{th}}-\mu)/\sigma$
\end_inset

 which is positive if 
\begin_inset Formula $V_{\text{th}}>\mu$
\end_inset

 and negative if 
\begin_inset Formula $V_{\text{th}}<\mu$
\end_inset

.
 In the following, we assume that 
\begin_inset Formula $x_{\text{min}}=-\infty$
\end_inset

.
 From Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: left bc-1"

\end_inset

 follows that 
\begin_inset Formula 
\begin{equation}
\lim_{x\rightarrow-\infty}x\phi(x)=\lim_{x\rightarrow-\infty}xf(x)\varphi(x)=0.\label{eq: LIF left bc}
\end{equation}

\end_inset

The asymptotic behavior of 
\begin_inset Formula $U(z,-x)$
\end_inset

 and 
\begin_inset Formula $V(z,-x)$
\end_inset

 for 
\begin_inset Formula $x\rightarrow-\infty$
\end_inset

 is
\begin_inset Formula 
\begin{align}
\lim_{x\rightarrow-\infty}U(z,-x) & \sim e^{-\frac{1}{4}x^{2}}x^{-z-\frac{1}{2}}\nonumber \\
\lim_{x\rightarrow-\infty}V(z,-x) & \sim e^{\frac{1}{4}x^{2}}x^{z-\frac{1}{2}}
\end{align}

\end_inset

Hence, asymptotic behavior of 
\begin_inset Formula $\phi(x)=xf(x)\varphi(x)$
\end_inset

 is given by 
\begin_inset Formula 
\begin{align}
\lim_{x\rightarrow-\infty}xf(x)U(z,-x) & \sim e^{-\frac{1}{2}x^{2}}x^{-z+\frac{1}{2}}\nonumber \\
\lim_{x\rightarrow-\infty}xf(x)V(z,-x) & \sim x^{z+\frac{1}{2}}
\end{align}

\end_inset

Note that the second term does not vanish if 
\begin_inset Formula $\lambda=0$
\end_inset

 due to 
\begin_inset Formula $z=\lambda-\frac{1}{2}$
\end_inset

.
 Hence, we need to construct a piece-wise solution in which 
\begin_inset Formula $V(z,-x)$
\end_inset

 does not contribute to the left branch 
\begin_inset Formula 
\begin{equation}
\varphi(x)=\begin{cases}
cU(z,-x) & x<x_{\text{r}}\\
aV(z,-x)+bU(z,-x) & x_{\text{r}}\leq x<x_{\theta}
\end{cases}\label{eq: LIF piecewise solution}
\end{equation}

\end_inset

to ensure that 
\begin_inset Formula $J_{0}(x)=-(x+\partial_{x})\phi_{0}(x)$
\end_inset

 goes to zero for 
\begin_inset Formula $x\rightarrow-\infty$
\end_inset

.
 Note that we separated the two branches of 
\begin_inset Formula $\varphi(x)$
\end_inset

 at the reset potential 
\begin_inset Formula $x_{r}$
\end_inset

 which will simplify the derivation going forward.
 The coefficients 
\begin_inset Formula $a,b$
\end_inset

 and 
\begin_inset Formula $c$
\end_inset

 need to be determined for each eigenfunction anew because the value of
 
\begin_inset Formula $z=\lambda-\frac{1}{2}$
\end_inset

 depends on 
\begin_inset Formula $\lambda$
\end_inset

.
 For each 
\begin_inset Formula $\lambda$
\end_inset

, the coefficients need be chosen such that 
\begin_inset Formula $\phi(x)=f(x)\varphi(x)$
\end_inset

 fulfills the boundary conditions of 
\begin_inset Formula $\rho(x,s)$
\end_inset

.
 Furthermore, we make the constraint that 
\begin_inset Formula $\varphi(x)$
\end_inset

 needs to be continuous at the reset value 
\begin_inset Formula $x_{\text{r}}$
\end_inset

.
 Using this additional constrain, the right boundary given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: right bc-1"

\end_inset

 and the reset boundary condition given by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: reset bc-1"

\end_inset

, we arrive at the following set of equations
\end_layout

\begin_layout Enumerate
Right boundary conditions:
\begin_inset Formula 
\begin{equation}
\phi(x_{\theta})=f(x)\varphi(x_{\theta})=0\Rightarrow\varphi(x_{\theta})=0\label{eq: LIF right bc}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Continuity at reset:
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0^{+}}\left\{ \phi(x_{r}-\epsilon)=\phi(x_{\text{r}}+\epsilon)\Rightarrow\varphi(x_{\text{r}}-\epsilon)=\varphi(x_{\text{r}}+\epsilon)\right\} \label{eq: LIF continuous}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Reset boundary condition: 
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0^{+}}\left\{ \partial_{x}\phi(x_{\text{r}}+\epsilon)-\partial_{x}\phi(x_{\text{r}}-\epsilon)\right\} =\partial_{x}\phi(x_{\theta})\Rightarrow f(x_{\theta})\partial_{x}\varphi_{n}(x_{\theta})=f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left\{ \partial_{x}\varphi_{n}(x_{\text{r}}+\epsilon)-\partial_{x}\varphi_{n}(x_{\text{r}}-\epsilon)\right\} \label{eq: LIF reset bc}
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Start from 
\begin_inset Formula 
\[
J_{n}(x_{\theta})=\lim_{\epsilon\rightarrow0^{+}}\left[J_{n}(x_{\text{r}}+\epsilon)-J_{n}(x_{\text{r}}-\epsilon)\right]
\]

\end_inset

with 
\begin_inset Formula $J_{n}(x)=-\left(x+\partial_{x}\right)\phi_{n}(v)=-(x+\partial_{x})f(x)\varphi(x)$
\end_inset

.
 We have
\begin_inset Formula 
\[
J_{n}(x_{\theta})=-x_{\theta}f(x_{\theta})\varphi(x_{\theta})-f(x_{\theta})\varphi'(x_{\theta})-f'(x_{\theta})\varphi(x_{\theta})
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Using 
\begin_inset Formula $\varphi(x_{\theta})=0$
\end_inset

, we find 
\begin_inset Formula 
\[
J_{n}(x_{\theta})=-f(x_{\theta})\varphi'(x_{\theta})
\]

\end_inset


\end_layout

\begin_layout Plain Layout
We have 
\begin_inset Formula 
\begin{align*}
 & \lim_{\epsilon\rightarrow0^{+}}\left[J_{n}(x_{\text{r}}+\epsilon)-J_{n}(x_{\text{r}}-\epsilon)\right]\\
= & \lim_{\epsilon\rightarrow0^{+}}\{-(x_{\text{r}}+\epsilon)f(x_{\text{r}}+\epsilon)\varphi(x_{\text{r}}+\epsilon)-f(x_{\text{r}}+\epsilon)\varphi'(x_{\text{r}}+\epsilon)-f'(x_{\text{r}}+\epsilon)\varphi(x_{\text{r}}+\epsilon)\\
 & +(x_{\text{r}}-\epsilon)f(x_{\text{r}}-\epsilon)\varphi(x_{\text{r}}-\epsilon)+f(x_{\text{r}}-\epsilon)\varphi'(x_{\text{r}}-\epsilon)+f'(x_{\text{r}}-\epsilon)\varphi(x_{\text{r}}-\epsilon)\}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
We use that all functions are continuous at 
\begin_inset Formula $x_{\text{r}}$
\end_inset

 except for the first derivative of 
\begin_inset Formula $\varphi'(x)$
\end_inset

 at 
\begin_inset Formula $x_{\text{r}}$
\end_inset


\begin_inset Formula 
\begin{align*}
\lim_{\epsilon\rightarrow0^{+}}\left[J_{n}(x_{\text{r}}+\epsilon)-J_{n}(x_{\text{r}}-\epsilon)\right]= & -x_{\text{r}}f(x_{\text{r}})\varphi(x_{\text{r}})-f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\varphi'(x_{\text{r}}+\epsilon)-f'(x_{\text{r}})\varphi(x_{\text{r}})\\
 & +(x_{\text{r}})f(x_{\text{r}})\varphi(x_{\text{r}})+f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\varphi'(x_{\text{r}}-\epsilon)-f'(x_{\text{r}})\varphi(x_{\text{r}})\}\\
= & f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left(\varphi'(x_{\text{r}}-\epsilon)-\varphi'(x_{\text{r}}+\epsilon)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Hence, we find 
\begin_inset Formula 
\begin{align*}
\varphi'(x_{\theta}) & =f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left(\varphi'(x_{\text{r}}-\epsilon)-\varphi'(x_{\text{r}}+\epsilon)\right)\\
f(x_{\theta})\varphi'(x_{\theta}) & =f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left(\varphi'(x_{\text{r}}+\epsilon)-\varphi'(x_{\text{r}}-\epsilon)\right)
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For the reset boundary condition, we used that 
\begin_inset Formula $\phi(x_{\theta})=0$
\end_inset

 and that 
\begin_inset Formula $\phi(x)$
\end_inset

 is continuous at reset 
\begin_inset Formula $x_{\text{r}}$
\end_inset

 to get rid of all terms except for the ones which contain a first derivative.
 We make the variable transformation 
\begin_inset Formula $x=-y$
\end_inset

 such that Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF piecewise solution"

\end_inset

 becomes 
\begin_inset Formula 
\begin{equation}
\varphi(y)=\begin{cases}
aV(z,y)+bU(z,y) & y_{\theta}<y<y_{\text{r}}\\
cU(z,y) & y>y_{\text{r}}
\end{cases}
\end{equation}

\end_inset

with 
\begin_inset Formula $y_{\theta}=-x_{\theta}$
\end_inset

 and 
\begin_inset Formula $y_{\text{r}}=-x_{\text{r}}$
\end_inset

.
 The constraints given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF right bc"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF continuous"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF reset bc"

\end_inset

 yield a system of equations for the coefficients 
\begin_inset Formula $a_{n},b_{n}$
\end_inset

 and 
\begin_inset Formula $c_{n}$
\end_inset


\begin_inset Formula 
\begin{align}
a_{n}V_{\theta}+b_{n}U_{\theta} & =0,\nonumber \\
a_{n}V_{\text{r}}+b_{n}U_{\text{r}}-c_{n}U_{\text{r}} & =0,\nonumber \\
a_{n}\left\{ f_{\theta}V_{\theta}'-f_{\text{r}}V_{\text{r}}'\right\} +b_{n}\left\{ f_{\theta}U_{\theta}'-f_{\text{r}}U_{\text{r}}'\right\} +c_{n}f_{\text{r}}U_{\text{r}}' & =0,\label{eq: LIF system of equations}
\end{align}

\end_inset

where we used that 
\begin_inset Formula $\partial_{x}V(z,-x)=-V'(z,y)$
\end_inset

, 
\begin_inset Formula $f(-y)=f(y)$
\end_inset

 and introduced the abbreviations 
\begin_inset Formula 
\begin{align*}
V_{\theta/\text{r}} & =V_{\theta}(z_{n},y_{\theta/\text{r}}),\\
U_{\theta/\text{r}} & =U(z_{n},y_{\theta/\text{r}}),\\
f_{\theta/\text{r}} & =f(y_{\theta/\text{r}}).
\end{align*}

\end_inset

In matrix notation, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF system of equations"

\end_inset

 can be written as 
\begin_inset Formula 
\begin{equation}
A_{n}\begin{pmatrix}a_{n}\\
b_{n}\\
c_{n}
\end{pmatrix}=\begin{pmatrix}V_{\theta} & U_{\theta} & 0\\
V_{r} & U_{r} & -U_{r}\\
f_{\theta}V_{\theta}'-f_{r}V_{r}' & f_{\theta}U_{\theta}'-f_{r}U_{r}' & f_{r}U_{r}'
\end{pmatrix}\begin{pmatrix}a_{n}\\
b_{n}\\
c_{n}
\end{pmatrix}=0
\end{equation}

\end_inset

This is homogeneous linear system of equations.
 If the matrix 
\begin_inset Formula $A_{n}$
\end_inset

 is invertible, the only solution to the system of equations is the trivial
 solution 
\begin_inset Formula 
\begin{equation}
A_{n}^{-1}A_{n}\begin{pmatrix}a_{n}\\
b_{n}\\
c_{n}
\end{pmatrix}=0\Leftrightarrow\begin{pmatrix}a_{n}\\
b_{n}\\
c_{n}
\end{pmatrix}=0.
\end{equation}

\end_inset

Hence, to obtain a non-trivial solution, we need to find those eigenvalues
 
\begin_inset Formula $\{\lambda_{n}\}$
\end_inset

 for which 
\begin_inset Formula $A_{n}$
\end_inset

 is singular (non invertible), i.e.
 
\begin_inset Formula 
\begin{equation}
\text{det}(A_{n})=0\label{eq: characteristic equation-1}
\end{equation}

\end_inset

 We find
\begin_inset Formula 
\begin{equation}
\text{det}\left(A_{n}\right)=\sqrt{\frac{2}{\pi}}\left[f(y_{\text{r}})U(z,y_{\theta})-f(y_{\theta})U(z,y_{\text{r}})\right],
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Using Leibniz formula for determinants, we find 
\begin_inset Formula 
\begin{align*}
 & \begin{vmatrix}V(z_{n},x_{\theta}) & U(z_{n},x_{\theta}) & 0\\
V(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
f(x_{\theta})V'(z_{n},x_{\theta})-f(x_{\text{r}})V'(z_{n},x_{\text{r}}) & U'(z_{n},x_{\theta})f(x_{\theta})-f(x_{\text{r}})U'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}\\
= & V(z_{n},x_{\theta})\begin{vmatrix}U(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
U'(z_{n},x_{\theta})f(x_{\theta})-f(x_{\text{r}})U'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}-U(z_{n},x_{\theta})\begin{vmatrix}V(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
f(x_{\theta})V'(z_{n},x_{\theta})-f(x_{\text{r}})V'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Making the calculation
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align*}
 & V(z_{n},x_{\theta})\begin{vmatrix}U(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
U'(z_{n},x_{\theta})f(x_{\theta})-f(x_{\text{r}})U'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}-U(z_{n},x_{\theta})\begin{vmatrix}V(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
f(x_{\theta})V'(z_{n},x_{\theta})-f(x_{\text{r}})V'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}\\
 & =V(z_{n},x_{\theta})\left\{ f(x_{\text{r}})U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+U(z_{n},x_{\text{r}})\left(U'(z_{n},x_{\theta})f(x_{\theta})-f(x_{\text{r}})U'(z_{n},x_{\text{r}})\right)\right\} \\
 & -U(z_{n},x_{\theta})\left\{ f(x_{\text{r}})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+U(z_{n},x_{\text{r}})\left(f(x_{\theta})V'(z_{n},x_{\theta})-f(x_{\text{r}})V'(z_{n},x_{\text{r}})\right)\right\} \\
 & =f(x_{\text{r}})V(z_{n},x_{\theta})U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+V(z_{n},x_{\theta})U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})f(x_{\theta})-V(z_{n},x_{\theta})U(z_{n},x_{\text{r}})f(x_{\text{r}})U'(z_{n},x_{\text{r}})\\
 & -f(x_{\text{r}})U(z_{n},x_{\theta})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})f(x_{\theta})V'(z_{n},x_{\theta})+U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})f(x_{\text{r}})V'(z_{n},x_{\text{r}})\\
 & =f(x_{\theta})\left(V(z_{n},x_{\theta})U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})-U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\right)+f(x_{r})\left(-U(z_{n},x_{\theta})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})\right)\\
 & =U(z_{n},x_{\text{r}})f(x_{\theta})\left(-U(z_{n},x_{\theta})V'(z_{n},x_{\theta})+V(z_{n},x_{\theta})U'(z_{n},x_{\theta})\right)+f(x_{\text{r}})U(z_{n},x_{\theta})\left(-V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})\right)\\
 & =\sqrt{\frac{2}{\pi}}\left(f(x_{\text{r}})U(z_{n},x_{\theta})-U(z_{n},x_{\text{r}})f(x_{\theta})\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
In the last line we used that the Wronskian 
\begin_inset Formula 
\[
\text{Wr}(U,V)=U(z,x)V'(z,x)-V(z,x)U(z,x)=\sqrt{\frac{2}{\pi}}
\]

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 which leads to the following characteristic equation 
\begin_inset Formula 
\begin{equation}
\frac{U(z_{n},y_{\theta})}{f(y_{\theta})}-\frac{U(z_{n},y_{\text{r}})}{f(y_{\text{r}})}=0,\label{eq: LIF characteristic equation}
\end{equation}

\end_inset

which determines the eigenvalues of our problem.
 The solutions to the above equation yield an infinite set of countably
 many isolated eigenvalues.
\end_layout

\begin_layout Standard
A singular matrix has always at least two dependent vectors.
 Indeed one can show that if Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF characteristic equation"

\end_inset

 is fulfilled, then 
\begin_inset Formula $A_{n}$
\end_inset

 has two dependent rows.
 From this follows that the row echelon form 
\begin_inset Formula $A_{n}$
\end_inset

 has one zero row.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Formula 
\[
A=\begin{pmatrix}V(z_{n},x_{\theta}) & U(z_{n},x_{\theta}) & 0\\
V(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
V'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}V'(z_{n},x_{\theta}) & U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U'(z_{n},x_{\theta}) & -U'(z_{n},x_{\text{r}})
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Swap the first and third column and the first and third row
\begin_inset Formula 
\[
\begin{pmatrix}0 & U(z_{n},x_{\theta}) & V(z_{n},x_{\theta})\\
-U(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}}) & V(z_{n},x_{\text{r}})\\
-U'(z_{n},x_{\text{r}}) & U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U'(z_{n},x_{\theta}) & V'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}V'(z_{n},x_{\theta})
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Multiply the second row by 
\begin_inset Formula $-U'(z_{n},x_{\text{r}})$
\end_inset

 and the third row by 
\begin_inset Formula $U(z_{n},x_{\text{r}})$
\end_inset

 and add second and third row 
\begin_inset Formula 
\[
\begin{pmatrix}0 & U(z_{n},x_{\theta}) & V(z_{n},x_{\theta})\\
0 & -\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta}) & U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\\
-U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta}) & U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Multiply the second row with 
\begin_inset Formula $U(z_{n},x_{\theta})$
\end_inset

 and the first row with 
\begin_inset Formula $\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})$
\end_inset

 and sum the first and second row
\begin_inset Formula 
\[
\begin{pmatrix}0 & 0 & \frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})V(z_{n},x_{\theta})+U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-U(z_{n},x_{\theta})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\\
0 & -\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})U(z_{n},x_{\theta}) & U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\\
-U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta}) & U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Show that 
\begin_inset Formula 
\begin{align*}
0 & =\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})V(z_{n},x_{\theta})+U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-U(z_{n},x_{\theta})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\\
0 & =\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})\left(U'(z_{n},x_{\theta})V(z_{n},x_{\theta})-U(z_{n},x_{\theta})V'(z_{n},x_{\theta})\right)+U(z_{n},x_{\theta})\left(U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-U'(z_{n},x_{\text{r}})V(z_{n},x_{\text{r}})\right)\\
0 & =\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})\text{Wr}(x_{\theta})-U(z_{n},x_{\theta})\text{Wr}(x_{\text{r}})
\end{align*}

\end_inset

Dividing the above equation by 
\begin_inset Formula $\text{Wr}(x_{\theta})\text{Wr}(x_{\text{r}})f(x_{\theta})$
\end_inset

 yields 
\begin_inset Formula 
\[
0=\frac{U(z_{n},x_{\text{r}})}{f(x_{\text{r}})\text{Wr}(x_{\text{r}})}-\frac{U(z_{n},x_{\theta})}{f(x_{\theta})\text{Wr}(x_{\theta})}
\]

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 Hence, the system of equations is not fully determined, but instead we
 can construct infinite many solutions by choosing an arbitrary value for
 one of the coefficients.
 This degree of freedom can be understood from the fact that eigenfunctions
 are only unique up to some ubiquitous normalization condition.
 First, we determine the coefficients 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

 as functions of the coefficient 
\begin_inset Formula $c$
\end_inset

.
 After that, we determine 
\begin_inset Formula $c$
\end_inset

 by a arbitrary normalization condition.
 Knowing 
\begin_inset Formula $c$
\end_inset

, we can than determine 
\begin_inset Formula $a$
\end_inset

 and 
\begin_inset Formula $b$
\end_inset

.
 We start from
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
0=\begin{pmatrix}V_{\theta} & U_{\theta} & 0\\
V_{r} & U_{r} & -U_{r}\\
f_{\theta}V_{\theta}'-f_{r}V_{r}' & f_{\theta}U_{\theta}'-f_{r}U_{r}' & f_{r}U_{r}'
\end{pmatrix}\begin{pmatrix}a\\
b\\
c
\end{pmatrix}.
\end{equation}

\end_inset

From the first two row follows 
\begin_inset Formula 
\begin{align}
a & =\frac{U_{\theta}/f_{\theta}}{V_{r}/f_{r}-V_{\theta}/f_{\theta}}c\label{eq: LIF a}\\
b & =-\frac{V_{\theta}/f\theta}{V_{r}/f_{r}-V_{\theta}/f_{\theta}}c\label{eq: LIF b}
\end{align}

\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
From the first row follows
\begin_inset Formula 
\[
V_{\theta}a=-U_{\theta}b
\]

\end_inset


\end_layout

\begin_layout Plain Layout
From the second row follows
\begin_inset Formula 
\begin{align*}
V_{r}a+U_{r}b-U_{r}c & =0\\
U_{r}b & =U_{r}c-V_{r}a\\
b & =\frac{U_{r}c-V_{r}a}{U_{r}}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Substituting into the first equation yields 
\begin_inset Formula 
\begin{align*}
V_{\theta}a & =-U_{\theta}\frac{U_{r}c-V_{r}a}{U_{r}}\\
V_{\theta}a & =\frac{U_{\theta}V_{r}a-U_{\theta}U_{r}c}{U_{r}}\\
\left(\frac{V_{\theta}U_{r}-U_{\theta}V_{r}}{U_{r}}\right)a & =-U_{\theta}c\\
a & =\frac{-U_{r}U_{\theta}}{V_{\theta}U_{r}-U_{\theta}V_{r}}c\\
a & =\frac{U_{r}U_{\theta}}{U_{\theta}V_{r}-V_{\theta}U_{r}}c
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Substituting into the equation for 
\begin_inset Formula $b$
\end_inset


\begin_inset Formula 
\begin{align*}
b & =\frac{U_{r}c-V_{r}\frac{U_{r}U_{\theta}}{U_{\theta}V_{r}-V_{\theta}U_{r}}c}{U_{r}}\\
 & =\frac{U_{r}(U_{\theta}V_{r}-V_{\theta}U_{r})-V_{r}U_{r}U_{\theta}}{U_{r}(U_{\theta}V_{r}-V_{\theta}U_{r})}c\\
 & =\frac{U_{r}U_{\theta}V_{r}-U_{r}V_{\theta}U_{r}-V_{r}U_{r}U_{\theta}}{U_{r}(U_{\theta}V_{r}-V_{\theta}U_{r})}c\\
 & =\frac{-U_{r}V_{\theta}U_{r}}{U_{r}(U_{\theta}V_{r}-V_{\theta}U_{r})}c\\
 & =\frac{V_{\theta}U_{r}}{V_{\theta}U_{r}-U_{\theta}V_{r}}c
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

.
 We determine the coefficient 
\begin_inset Formula $c$
\end_inset

 by choosing the normalization 
\begin_inset Formula 
\begin{equation}
\partial_{x}\phi(x_{\theta})=f_{\theta}\partial_{x}\varphi(x_{\theta})=-\sqrt{\frac{2}{\pi}}\label{eq: LIF normalization-1}
\end{equation}

\end_inset

from which follows 
\begin_inset Formula 
\begin{equation}
aV'_{\theta}+bU'_{\theta}=\sqrt{\frac{2}{\pi}}f_{\theta}^{-1}
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF a"

\end_inset

 and Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF b"

\end_inset

 into the above equation yields 
\begin_inset Formula 
\begin{equation}
c=V_{r}/f_{r}-V_{\theta}/f_{\theta}
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
We need to solve 
\begin_inset Formula 
\begin{align*}
\frac{\frac{1}{f_{\theta}}\left(U_{\theta}V'_{\theta}-V_{\theta}U'_{\theta}\right)}{V_{r}/f_{r}-V_{\theta}/f_{\theta}}c & =\sqrt{\frac{2}{\pi}}f_{\theta}^{-1}\\
\frac{U_{\theta}V'_{\theta}-V_{\theta}U'_{\theta}}{V_{r}/f_{r}-V_{\theta}/f_{\theta}} & c=\sqrt{\frac{2}{\pi}}
\end{align*}

\end_inset

Using 
\begin_inset Formula $U_{\theta}V'_{\theta}-V_{\theta}U'_{\theta}=$
\end_inset


\begin_inset Formula $\sqrt{2/\pi}$
\end_inset

, we find 
\begin_inset Formula 
\begin{align*}
\frac{1}{V_{r}/f_{r}-V_{\theta}/f_{\theta}}c & =1\\
c & =V_{r}/f_{r}-V_{\theta}/f_{\theta}
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

Hence, we arrive at 
\begin_inset Formula 
\begin{align}
a_{n} & =\frac{U(z_{n},y_{\theta})}{f(y_{\theta})},\nonumber \\
b_{n} & =-\frac{V(z_{n},y_{\theta})}{f(y_{\theta})},\nonumber \\
c_{n} & =\frac{V(z_{n},y_{\text{r}})}{f(y_{\text{r}})}-\frac{V(z_{n},y_{\theta})}{f(y_{\theta})},\label{eq: LIF coefficients}
\end{align}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Check 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
First equation
\begin_inset Formula 
\begin{align*}
V_{\theta}a+U_{\theta}b & =0\\
\frac{V_{\theta}U_{\theta}}{f_{\theta}}-\frac{V_{\theta}U_{\theta}}{f_{\theta}} & =0\\
0 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Second equation 
\begin_inset Formula 
\begin{align*}
V_{r}a+bU_{r}-cU_{r} & =0\\
V_{r}\frac{U_{\theta}}{f_{\theta}}-\frac{V_{\theta}}{f_{\theta}}U_{r}-\left(\frac{V_{r}}{f_{r}}-\frac{V_{\theta}}{f_{\theta}}\right)U_{r} & =0\\
\frac{V_{r}U_{\theta}}{f_{\theta}}-\frac{V_{r}U_{r}}{f_{r}} & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Using 
\begin_inset Formula $\frac{U_{\theta}}{f_{\theta}}=\frac{U_{r}}{f_{r}}$
\end_inset


\begin_inset Formula 
\[
\frac{V_{r}U_{\theta}}{f_{\theta}}-\frac{V_{r}U_{\theta}}{f_{\theta}}=0
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Third equation 
\begin_inset Formula 
\begin{align*}
(f_{\theta}V_{\theta}'-f_{r}V'_{r})a+('f_{\theta}U_{\theta}'-f_{r}U_{r}')b+f_{r}U_{r}'c & =0\\
(f_{\theta}V_{\theta}'-f_{r}V'_{r})\frac{U_{\theta}}{f_{\theta}}-(f_{\theta}U_{\theta}'-f_{r}U_{r}')\frac{V_{\theta}}{f_{\theta}}+f_{r}U_{r}'\left(\frac{V_{r}}{f_{r}}-\frac{V_{\theta}}{f_{\theta}}\right) & =0\\
V_{\theta}'U_{\theta}-\frac{f_{r}V'_{r}U_{\theta}}{f_{\theta}}-U_{\theta}'V_{\theta}+\frac{f_{r}U_{r}'V_{\theta}}{f_{\theta}}+U_{r}'V_{r}-\frac{V_{\theta}f_{r}U_{r}'}{f_{\theta}} & =0\\
U_{\theta}V_{\theta}'-U_{\theta}'V_{\theta}+\frac{f_{r}}{f_{\theta}}\left(-V'_{r}U_{\theta}+U_{r}'V_{\theta}-V_{\theta}U_{r}'\right)+U_{r}'V_{r} & =0\\
U_{\theta}V_{\theta}'-U_{\theta}'V_{\theta}-\frac{f_{r}}{f_{\theta}}V'_{r}U_{\theta}+U_{r}'V_{r} & =0\\
U_{\theta}V_{\theta}'-U_{\theta}'V_{\theta}-(U_{r}V'_{r}-U_{r}'V_{r}) & =0\\
\sqrt{\frac{2}{\pi}}-\sqrt{\frac{2}{\pi}} & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Continuity at reset 
\begin_inset Formula 
\begin{align*}
cU_{r} & =aV_{r}+bU_{r}\\
(c-b)U_{r} & =aV_{r}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Inserting coefficients yields 
\begin_inset Formula 
\begin{align*}
\left(\frac{V_{r}}{f_{r}}-\frac{V_{\theta}}{f_{\theta}}+\frac{V_{\theta}}{f_{\theta}}\right)U_{r} & =\frac{U_{\theta}}{f_{\theta}}V_{r}\\
\frac{V_{r}}{f_{r}}U_{r} & =\frac{U_{\theta}}{f_{\theta}}V_{r}\\
\frac{f_{\theta}}{f_{r}} & =\frac{U_{\theta}}{U_{r}}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
which this zero due to characteristic equation.
 
\end_layout

\end_inset


\end_layout

\end_inset

 and 
\begin_inset Formula 
\begin{equation}
\phi_{n}(x)=f(x)\begin{cases}
c_{n}U(z_{n},-x) & x<x_{\text{r}}\\
a_{n}V(z_{n},-x)+b_{n}U(z_{n},-x) & x_{\text{r}}\leq x<x_{\theta},
\end{cases}
\end{equation}

\end_inset

where 
\begin_inset Formula $f(x)=e^{-\frac{1}{4}x^{2}}$
\end_inset

and 
\begin_inset Formula $z_{n}=\lambda_{n}-1/2$
\end_inset

.
 The characteristic Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: characteristic equation-1"

\end_inset

 needs to be solved numerically.
 Once we determined an eigenvalue 
\begin_inset Formula $\lambda_{n}$
\end_inset

, we can determine the values for the corresponding coefficients 
\begin_inset Formula $a_{n},b_{n}$
\end_inset

 and 
\begin_inset Formula $c_{n}$
\end_inset

 via Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF coefficients"

\end_inset

.
 As already mentioned, the Fokker-Planck operator given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF Fokker-Planck"

\end_inset

 is not self-adjoint.
 Hence, in order to build a biorthogonal basis, we need to determine eigenfuncti
ons 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 of the adjoint operator 
\begin_inset Formula $L^{\dagger}$
\end_inset

 given by 
\begin_inset Formula 
\begin{equation}
L^{\dagger}\tilde{\phi}_{n}=\tilde{\lambda}_{n}\tilde{\phi}_{n}.\label{eq: LIF adjoint eigenfunction}
\end{equation}

\end_inset

The adjoint operator is defined by the equation 
\begin_inset Formula 
\begin{equation}
\bigl\langle\tilde{\phi},L\phi\bigr\rangle=\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle.\label{eq: adjoint operator}
\end{equation}

\end_inset

The adjoint operator and the boundary condition for its eigenfunctions need
 to determined from Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: adjoint operator"

\end_inset

.
 We find 
\begin_inset Formula 
\begin{equation}
L^{\dagger}=-x\partial_{x}+\partial_{x}^{2}
\end{equation}

\end_inset

and 
\begin_inset Formula $\tilde{\phi}(x_{\text{\ensuremath{\theta}}})=\tilde{\phi}(x_{\text{r}})$
\end_inset

 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status open

\begin_layout Plain Layout
We start from 
\begin_inset Formula 
\[
\bigl\langle\tilde{\phi},L\phi\bigr\rangle=\int_{-\infty}^{x_{t}}dx\tilde{\phi}L\phi=\int_{-\infty}^{x_{t}}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Split integral into two parts 
\begin_inset Formula 
\[
\int_{-\infty}^{x_{t}}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi=\lim_{\epsilon\rightarrow0^{+}}\left\{ \int_{-\infty}^{x_{r}-\epsilon}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi+\int_{x_{r}+\epsilon}^{\infty}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi\right\} 
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Our goal is to move the derivatives over to 
\begin_inset Formula $\tilde{\phi}_{m}$
\end_inset

 by partial integration 
\begin_inset Formula 
\begin{align*}
\int_{a}^{b}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi & =\left.\tilde{\phi}\left(x+\partial_{x}\right)\phi\right|_{a}^{b}-\int_{a}^{b}dx\left(\partial_{x}\tilde{\phi}\right)\left(x+\frac{\partial}{\partial x}\right)\phi\\
 & =\left.\tilde{\phi}\left(x+\partial_{x}\right)\phi\right|_{a}^{b}-\int_{a}^{b}dx\,\left\{ x\phi\partial_{x}\tilde{\phi}+\left(\partial_{x}\tilde{\phi}\right)\left(\frac{\partial}{\partial x}\phi\right)\right\} \\
 & =\left.\tilde{\phi}\left(x+\partial_{x}\right)\phi\right|_{a}^{b}-\int_{a}^{b}dx\,x\phi\partial_{x}\tilde{\phi}-\left.\left(\partial_{x}\tilde{\phi}\right)\phi\right|_{a}^{b}+\int_{a}^{b}dx\,\phi\partial_{x}^{2}\tilde{\phi}\\
 & =\left.\tilde{\phi}\left(x+\partial_{x}\right)\phi\right|_{a}^{b}-\left.\left(\partial_{x}\tilde{\phi}\right)\phi\right|_{a}^{b}+\int_{a}^{b}dx\,\left\{ -x\phi\partial_{x}\tilde{\phi}+\phi\partial_{x}^{2}\tilde{\phi}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
The last term shows us that 
\begin_inset Formula 
\[
L^{\dagger}=-x\partial_{x}+\partial_{x}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
The boundary conditions of 
\begin_inset Formula $\tilde{\phi}$
\end_inset

 need to be chosen such that the surface terms vanish.
 We use 
\begin_inset Formula $J(x)=-\left(x+\partial_{x}\right)\phi$
\end_inset

 so that 
\begin_inset Formula 
\begin{align*}
\bigl\langle\tilde{\phi},L\phi\bigr\rangle & =\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle-\lim_{\epsilon\rightarrow0^{+}}\left\{ \left.\tilde{\phi}J+\right|_{-\infty}^{x_{r}-\epsilon}+\left.\left(\partial_{x}\tilde{\phi}\right)\phi\right|_{-\infty}^{x_{r}-\epsilon}+\left.\tilde{\phi}J\right|_{x_{r}+\epsilon}^{x_{\theta}}+\left.\left(\partial_{x}\tilde{\phi}\right)\phi_{n}\right|_{x_{r}+\epsilon}^{x_{\theta}}\right\} \\
 & =\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle-\lim_{\epsilon\rightarrow0^{+}}\left\{ \tilde{\phi}(x_{\text{r}}-\epsilon)J(x_{\text{r}}-\epsilon)+\tilde{\phi}'(x_{\text{r}}-\epsilon)\phi(x_{\text{r}}-\epsilon)+\tilde{\phi}(x_{\text{\ensuremath{\theta}}})J(x_{\theta})-\tilde{\phi}(x_{\text{r}}+\epsilon)J(x_{\text{r}}+\epsilon)-\tilde{\phi}'(x_{\text{r}}+\epsilon)\phi(x_{\text{r}}+\epsilon)\right\} \\
 & =\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle-\lim_{\epsilon\rightarrow0^{+}}\left\{ \tilde{\phi}(x_{\text{\ensuremath{\theta}}})J(x_{\theta})+\tilde{\phi}(x_{\text{r}}-\epsilon)J(x_{\text{r}}-\epsilon)-\tilde{\phi}(x_{\text{r}}+\epsilon)J(x_{\text{r}}+\epsilon)+\tilde{\phi}'(x_{\text{r}}-\epsilon)\phi(x_{\text{r}}-\epsilon)-\tilde{\phi}'(x_{\text{r}}+\epsilon)\phi(x_{\text{r}}+\epsilon)\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Note that many of the terms vanish due to the boundary conditions 
\begin_inset Formula $\phi(x)$
\end_inset

.
 If 
\begin_inset Formula $\phi'(x)$
\end_inset

 is continuous at 
\begin_inset Formula $x_{\text{r}}$
\end_inset

, then the last term in the above equation vanishes and we are left with
\begin_inset Formula 
\[
\bigl\langle\tilde{\phi},L\phi\bigr\rangle=\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle-\lim_{\epsilon\rightarrow0^{+}}\left\{ \tilde{\phi}(x_{\text{\ensuremath{\theta}}})J(x_{\theta})+\tilde{\phi}(x_{\text{r}}-\epsilon)J(x_{\text{r}}-\epsilon)-\tilde{\phi}(x_{\text{r}}+\epsilon)J(x_{\text{r}}+\epsilon)\right\} 
\]

\end_inset


\end_layout

\begin_layout Plain Layout
If 
\begin_inset Formula $\tilde{\phi}(x_{\text{\ensuremath{\theta}}})=\tilde{\phi}(x_{\text{r}})$
\end_inset

, then 
\begin_inset Formula 
\[
\lim_{\epsilon\rightarrow0^{+}}\left\{ \tilde{\phi}(x_{\text{\ensuremath{\theta}}})J(x_{\theta})+\tilde{\phi}(x_{\text{r}}-\epsilon)J(x_{\text{r}}-\epsilon)-\tilde{\phi}(x_{\text{r}}+\epsilon)J(x_{\text{r}}+\epsilon)\right\} =\tilde{\phi}(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left\{ J(x_{\theta})-\left[J(x_{\text{r}}+\epsilon)-J(x_{\text{r}}-\epsilon)\right]\right\} =0
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Hence, we arrive at 
\begin_inset Formula 
\[
L^{\dagger}=-x\partial_{x}+\partial_{x}^{2}
\]

\end_inset

and 
\begin_inset Formula 
\[
\tilde{\phi}(x_{\text{\ensuremath{\theta}}})=\tilde{\phi}(x_{\text{r}})
\]

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

.
 We transform Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF adjoint eigenfunction"

\end_inset

 into a Schroedinger type equation 
\begin_inset Formula 
\begin{equation}
g^{-1}L^{\dagger}g=\partial_{x}^{2}+V(x)
\end{equation}

\end_inset

using the similarity transformation 
\begin_inset Formula 
\begin{equation}
\tilde{\varphi}(x)=g^{-1}(x)\tilde{\phi}(x).
\end{equation}

\end_inset

Note that we dropped the subscript 
\begin_inset Formula $n$
\end_inset

 for convenience.
 Choosing 
\begin_inset Formula $g(x)=e^{\frac{1}{4}x^{2}}$
\end_inset

, yields 
\begin_inset Formula 
\begin{equation}
V(x)=-\frac{1}{4}x^{2}+\frac{1}{2}
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Start from 
\begin_inset Formula 
\begin{align*}
g^{-1}\left(-x\partial_{x}+\partial_{x}^{2}\right)g\tilde{\varphi} & =g^{-1}\left(-xg'\tilde{\varphi}-xg\tilde{\varphi}'+g''\tilde{\varphi}+2g'\varphi'+g\varphi''\right)\\
 & =\left(-g^{-1}xg'+g^{-1}g''\right)\tilde{\varphi}+\left(-xg+2g'\right)\tilde{\varphi}'+\varphi''
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Choose 
\begin_inset Formula $g$
\end_inset

 such that 
\begin_inset Formula 
\[
-xg+2g'=0
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Separation of variables yields 
\begin_inset Formula 
\begin{align*}
-xg+2\frac{dg}{dx} & =0\\
\frac{1}{g}dg & =\frac{1}{2}x\,dx
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
We find
\begin_inset Formula 
\[
g(x)=e^{\frac{1}{4}x^{2}}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
First and second derivative 
\begin_inset Formula 
\begin{align*}
g' & =\frac{1}{2}xg\\
g'' & =\frac{1}{2}g+\frac{1}{4}x^{2}g
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Hence, we arrive at 
\begin_inset Formula 
\begin{align*}
V(x) & =\left(-g^{-1}x\frac{1}{2}xg+g^{-1}\left(\frac{1}{2}g+\frac{1}{4}x^{2}g\right)\right)\\
 & =\left(-\frac{1}{2}x^{2}+\frac{1}{2}+\frac{1}{4}x^{2}\right)\\
 & =-\frac{1}{4}x^{2}+\frac{1}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Check 
\begin_inset Formula 
\begin{align*}
 & g^{-1}\left(-x\partial_{x}+\partial_{x}^{2}\right)g\\
= & g^{-1}\left(-\frac{1}{2}x^{2}g+\frac{1}{2}g+\frac{1}{4}x^{2}g\right)\\
= & -\frac{1}{4}x^{2}+\frac{1}{2}
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 which is interestingly identical to Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF potential"

\end_inset

.
 Hence, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF adjoint eigenfunction"

\end_inset

 transforms into 
\begin_inset Formula 
\begin{equation}
\left(\partial_{x}^{2}-\frac{1}{4}x^{2}+\frac{1}{2}\right)\tilde{\varphi}=\lambda\tilde{\varphi}.
\end{equation}

\end_inset

We define 
\begin_inset Formula $z=\lambda-\frac{1}{2}$
\end_inset

 and write 
\begin_inset Formula 
\begin{equation}
\partial_{x}^{2}-\left(\frac{1}{4}x^{2}+z\right)\tilde{\varphi}=0,
\end{equation}

\end_inset

which is equivalent to Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF eingefunction transformed"

\end_inset

.
 Hence, the general solution is 
\begin_inset Formula 
\begin{equation}
\tilde{\varphi}(x)=aV(z,y)+bU(z,y).
\end{equation}

\end_inset

with 
\begin_inset Formula $y=-x$
\end_inset

.
 The back transform yields 
\begin_inset Formula 
\begin{equation}
\tilde{\phi}=g(y)\tilde{\varphi}(y)
\end{equation}

\end_inset

The asymptotic behavior of 
\begin_inset Formula $\phi(x)=g(x)\tilde{\varphi}(x)$
\end_inset

 for 
\begin_inset Formula $y\rightarrow\infty$
\end_inset

 is given by 
\begin_inset Formula 
\begin{align}
\lim_{y\rightarrow\infty}g(y)U(z,y) & \sim x^{-z-\frac{1}{2}}\nonumber \\
\lim_{y\rightarrow\infty}g(y)V(z,y) & \sim e^{\frac{1}{4}x^{2}}x^{z-\frac{1}{2}}
\end{align}

\end_inset

which shows that 
\begin_inset Formula $V(z,y)$
\end_inset

 divergeces.
 Hence, me make the ansatz
\begin_inset Formula 
\begin{equation}
\tilde{\phi}(y)=bg(y)U(z,y)
\end{equation}

\end_inset

 Note that this solution fulfills the boundary condition 
\begin_inset Formula $\tilde{\phi}(y_{\text{\ensuremath{\theta}}})=\tilde{\phi}(y_{\text{r}})$
\end_inset

 
\begin_inset Formula 
\begin{align}
b\left(g(y_{\theta})U(z,y_{\theta})-g(y_{\text{r}})U(z,y_{\text{r}})\right) & =0,
\end{align}

\end_inset

is fulfilled for arbitrary values of 
\begin_inset Formula $b$
\end_inset

 because the term
\begin_inset Formula 
\begin{equation}
g(y_{\theta})U(z,y_{\theta})-g(y_{\text{r}})U(z,y_{\text{r}})=0
\end{equation}

\end_inset

is equivalent to Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF characteristic equation"

\end_inset

.
 Hence, the coefficient 
\begin_inset Formula $b$
\end_inset

 needs to determined from the normalization condition 
\begin_inset Formula $\bigl\langle\tilde{\phi},\phi\bigr\rangle=1$
\end_inset


\begin_inset Formula 
\begin{equation}
b=\frac{1}{\bigl\langle g(x)U(z,-x),\phi(x)\bigr\rangle}.
\end{equation}

\end_inset

The inner product can be written as 
\begin_inset Formula 
\begin{equation}
\bigl\langle g(x)U(z,-x),\phi(x)\bigr\rangle=c_{n}\int_{-\infty}^{x_{\text{\text{r}}}}U(z,-x)U(z,-x)+\int_{x_{\text{r}}}^{x_{\theta}}U(z,-x)\left(aV(z,-x)+bU(z,-x)\right)
\end{equation}

\end_inset

We arrive at 
\begin_inset Formula 
\begin{equation}
\tilde{\phi}_{n}(x)=b_{n}g(x)U(z_{n},-x)
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Subsection
Higher order corrections to the transfer function 
\end_layout

\begin_layout Plain Layout
We discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Solving-the-Fokker-Planck"

\end_inset

 the response of neuron to a time modulated input rate can be characterized
 in leading order by the transfer function 
\begin_inset Formula $T(t)$
\end_inset

.
 Here, we want to investigate if we can obtain higher order corrections,
 i.e.
 in a regime where the amplitude of input modulations is not small compared
 to the stationary baseline, by expanding the probability density function
 
\begin_inset Formula $\rho(V,t)$
\end_inset

 in terms of eigenfunctions.
 We follow 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 and start from Eq.
 Our objective is to solve the Fokker-Planck equation if the neuron population
 receives time dependent input rate
\begin_inset Formula 
\begin{equation}
r(t)=r_{0}+\delta r(t).
\end{equation}

\end_inset

We assume that the time dependent input modulation 
\begin_inset Formula $\left|\delta r(t)\right|$
\end_inset

 is small compared to the baseline 
\begin_inset Formula $r_{0}$
\end_inset

.
 The diffusion approximation, Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire"

\end_inset

 becomes 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=f(V)+\mu(t)+\sqrt{\tau_{m}}\sigma^{2}(t)\xi(t),
\end{equation}

\end_inset

where 
\begin_inset Formula $\mu(t)$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}(t)$
\end_inset

 can be written as 
\begin_inset Formula 
\begin{align}
\mu & =\mu_{0}+\delta u(t)=\tau_{\text{m}}h(r_{0}+\delta r(t)),\nonumber \\
\sigma^{2} & =\sigma_{0}^{2}+\delta\sigma^{2}(t)=\tau_{\text{m}}h(r_{0}+h\delta r(t))
\end{align}

\end_inset

We introduce the expansion parameter 
\begin_inset Formula $\epsilon(t)=\delta r(t)/r_{0}$
\end_inset

 so that 
\begin_inset Formula $\delta\mu(t)$
\end_inset

 and 
\begin_inset Formula $\delta\sigma^{2}(t)$
\end_inset

 can be written as
\begin_inset Formula 
\begin{align}
\delta\mu(t) & =\epsilon(t)\frac{\tau h}{r_{0}},\nonumber \\
\delta\sigma^{2}(t) & =\epsilon(t)\frac{\tau h^{2}}{r_{0}}.
\end{align}

\end_inset

The Fokker-Planck operator 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FP operator"

\end_inset

 is given by
\begin_inset Formula 
\[
L(t)=-\frac{1}{\tau_{\text{m}}}\frac{\partial}{\partial V}[f(V)+\mu(t)]+\frac{\sigma(t)^{2}}{2\tau_{\text{m}}}\frac{\partial^{2}}{\partial V^{2}}.
\]

\end_inset

We split the FP operator into a constant and time dependent part 
\begin_inset Formula 
\begin{align}
L_{0} & =\partial_{V}\left(\frac{1}{\tau}\left[V-\mu_{0}\right]-\frac{1}{C}\psi(V)\right)+\frac{\sigma^{2}}{2\tau}\partial_{V}^{2},\\
\epsilon(t)L_{1} & =\epsilon(t)\left(-G\partial_{V}+H\partial_{V}^{2}\right),\label{eq: L1}
\end{align}

\end_inset

where we defined the constants 
\begin_inset Formula $G$
\end_inset

 and 
\begin_inset Formula $H$
\end_inset


\begin_inset Formula 
\begin{equation}
G=-\frac{h}{r_{0}},\quad H=\frac{h^{2}}{2r_{0}}.
\end{equation}

\end_inset

The FPE can be written as 
\begin_inset Formula 
\begin{equation}
\partial_{t}\rho(V,t)=L_{0}\rho(V,t)+\epsilon(t)L_{1}\rho(V,t)\label{eq: FPE-2}
\end{equation}

\end_inset

Expanding 
\begin_inset Formula $\rho(V,t)$
\end_inset

 in terms of the eigenfunctions of the constant operator 
\begin_inset Formula $L_{0}$
\end_inset


\begin_inset Formula 
\begin{equation}
\rho(V,t)=\sum_{n}c_{n}(t)\phi_{n}(V).
\end{equation}

\end_inset

and substituting the expansion into Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE-2"

\end_inset

 yields 
\begin_inset Formula 
\begin{equation}
\sum_{n}\dot{c}_{n}(t)\phi_{n}(V)=\sum_{n}c_{n}(t)L_{0}\phi_{n}(V)+\epsilon(t)\sum_{n}c_{n}(t)L_{1}\phi_{n}(V)
\end{equation}

\end_inset

Multiplying from left with 
\begin_inset Formula $\tilde{\phi}_{m}$
\end_inset

 eigenfunction of the adjoint operator and taking the inner product over
 
\begin_inset Formula $V$
\end_inset

 yields 
\begin_inset Formula 
\begin{align}
\dot{c}_{m}(t) & =\lambda_{m}c_{m}(t)+\epsilon(t)\sum_{n}c_{n}(t)(\tilde{\phi}_{m},L_{1}\phi_{n})
\end{align}

\end_inset

Using Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: L1"

\end_inset

, the inner product 
\begin_inset Formula $(\tilde{\phi}_{m},L_{1}\phi_{n}(V))$
\end_inset

 can be written as
\begin_inset Formula 
\begin{equation}
(\tilde{\phi}_{m},L_{1}\phi_{n}(V))=-G(\tilde{\phi}_{m},\phi_{n}')+H(\tilde{\phi}_{m},\phi''_{n}).
\end{equation}

\end_inset

We define the matrices 
\begin_inset Formula $\boldsymbol{G}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 as 
\begin_inset Formula 
\begin{align}
G_{mn} & =G(\tilde{\phi}_{m},\phi_{n}'),\nonumber \\
H_{nm} & =H\left(\tilde{\phi}_{m},\phi''_{n}\right),\label{eq: G and H}
\end{align}

\end_inset

and arrive at a linear system of equations for the weighting coefficients
 
\begin_inset Formula $c_{n}(t)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{equation}
\frac{\partial\boldsymbol{c}(t)}{\partial t}=\boldsymbol{\Lambda}\boldsymbol{c}(t)+\epsilon(t)(-\boldsymbol{G}+\boldsymbol{H})\boldsymbol{c}(t),
\end{equation}

\end_inset

where 
\begin_inset Formula $\Lambda_{nm}=\lambda_{n}\delta_{nm}$
\end_inset

.
 The formal solution to this systems of equations is given by a matrix exponenti
al
\begin_inset Formula 
\begin{equation}
\boldsymbol{c}(t)=c_{0}\exp\left[(\boldsymbol{\Lambda}+\epsilon(t)\boldsymbol{A})t\right],
\end{equation}

\end_inset

where we defined the matrix 
\begin_inset Formula $\boldsymbol{A}$
\end_inset

 as
\begin_inset Formula 
\begin{equation}
\boldsymbol{A}=(-\boldsymbol{G}+\boldsymbol{H}).
\end{equation}

\end_inset

 Expanding the matrix exponential to arrive at expression for the weighting
 coefficients 
\begin_inset Formula $c(t)$
\end_inset

 which can be systematically expanded in orders of 
\begin_inset Formula $\epsilon(t)$
\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{equation}
c(t)=c_{0}\sum_{n=0}^{\infty}\frac{(\boldsymbol{\Lambda}t+\epsilon(t)\boldsymbol{A}t)^{n}}{n!}t^{n}=c_{0}\sum_{n=0}^{\infty}\frac{\boldsymbol{A}^{n}}{n!}t^{n}.
\end{equation}

\end_inset

To evaluate the matrix powers 
\begin_inset Formula $\boldsymbol{A}^{n}$
\end_inset

, we need to know 
\begin_inset Formula $\lambda_{n},\phi_{n}$
\end_inset

 and 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 so that we can compute matrix elements 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: G and H"

\end_inset

 of matrix 
\begin_inset Formula $\boldsymbol{G}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

.
\end_layout

\end_inset


\end_layout

\end_body
\end_document
