#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Transfer Report: Spectral analysis of the dynamics of neuronal networks
 using population-density techniques 
\end_layout

\begin_layout Author
Lukas Deutz
\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
Understanding the behavior of large recurrent networks of spiking neurons
 is one of the major challenges in computational neuroscience.
 A first step in understanding the dynamical properties of such networks
 is to determine the location and stability of equilibria and how they depend
 on the connectivity profile and single neuron properties.
 A network may have different fix points each associated with a different
 dynamical behavior, like asynchronous irregular, global oscillatory or
 bursting activity all obsequiously observed in experiment.
 To better understand how these different dynamical regimes emerge, and
 how the network can transition between them by e.g.
 changing the external drive or the interplay between excitation and inhibition
 within the network is an important step towards understanding if and how
 these different states of activity can be used to implement functional
 properties.
 There are two complementary approaches to study the dynamics of neuronal
 networks which are referred to as computational and theoretical neuroscience.
 
\end_layout

\begin_layout Standard
In computational neuroscience, the most commonly used method is to simulate
 neural circuits by means of direct simulation.
 The direct approach simulates all neurons and their interactions individually.
 This has the huge advantage that they observables of interest like e.g.
 spike times, firing rate statistics or correlation measures can be all
 accessed on the level of single neurons.
 Before a neuronal network can be simulated, two questions need to be answered:
 
\end_layout

\begin_layout Enumerate
Which neuron model and synapse model should be used? 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Discuss what informs this decsion
\end_layout

\end_inset

 
\end_layout

\begin_layout Enumerate
What is the connectivity structure within the network? 
\end_layout

\begin_layout Standard
The first question is often between computational demand and explanatory
 power of the respective models.
 However, sometimes it also advisable to choose a simpler model to narrow
 down the possible causes which could explain a certain observation.
 To address the second question, it is common to think about the neuronal
 network in terms of different populations which represent neurons of a
 similar type, or with a similar function in a specific brain area of interest.
 The type of a neuron can e.g.
 be characterized by its morphology, its electrophysiological properties,
 or functional properties (e.g.
 receptivity to a specific stimulus feature).
 Neurons within a population are usually considered to be statistical identical,
 i.e.
 they are equally likely to from connections with neurons in other populations
 and are modeled by the same neuron model.
 In this setting, one is usually not interested in the dynamical features
 of individual neurons, but instead in the dynamical features of the individual
 populations which can be characterized by e.g.
 the average population firing rate, interspike interval statistics (ISI),
 or the statistics of pairwise or higher order correlations within or between
 populations.
 
\end_layout

\begin_layout Standard
The idea of approximating group of neurons by homogeneous populations is
 often utilized in theoretical neuroscience as method to reduce the large
 number of degrees of freedom faced in neuronal network.
 From a mathematical viewpoint, describing how the network evolves in time
 boils down to solving a large system coupled differential equation.
 Due to the non linearity of the neuron dynamics and their complex interactions,
 there is no hope to derive an exact solution.
 Hence, approximation schemes are needed.
 A commonly used method in theoretical neuroscience is mean-field theory
 which makes use of the previously described homogeneity assumption.
 The main idea of mean-field theory is to decouple the system of differential
 equations which describes all neurons individually.
 This can be done replacing the synaptic inputs a neuron receives from different
 neurons in the network by their population averaged counterparts.
 Since neurons belonging to the same population are assumed to be statistical
 identical, they can all be described by the same the mean-field equation.
 Hence, mean-field theory reduces the dimensionalty of the high dimensional
 initial problem to a system of equations with size equal to number of populatio
ns in the network.
 Because neurons are recurrently connected, the synaptic input at a given
 time causes neurons to spike which will then lead to more synaptic inputs
 at latter time.
 Hence, mean-field equations need to be solved self-consistently, such that
 the synaptic input a neuron receives on average produces an output which
 is consistent with the initial input.
 
\end_layout

\begin_layout Standard
The reminder of this report is structured as follows.
 First, we give an overview in the literature review about the population
 density method, the diffusion approximation and the method of spectral
 decomposition and how it used in neuroscientific context.
 Then, we will formulate a preliminary research question followed by a more
 detailed research proposal and present preliminaries results towards answering
 this questions.
 At least, we give an outline about future work.
 
\end_layout

\begin_layout Section
Literature Review 
\end_layout

\begin_layout Subsection
The population density method
\begin_inset CommandInset label
LatexCommand label
name "subsec:The-population-density"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Enumerate
Introduction
\end_layout

\begin_deeper
\begin_layout Itemize
Direct simulation vs population density
\end_layout

\begin_layout Itemize
Neuron models
\end_layout

\begin_layout Itemize
Integrate-and-fire
\end_layout

\begin_layout Itemize
Mean-field models
\end_layout

\end_deeper
\begin_layout Enumerate
Jump processes 
\end_layout

\begin_layout Enumerate
Diffusion approximation 
\end_layout

\begin_layout Enumerate
Fokker-Planck equation 
\end_layout

\begin_layout Enumerate
Spectral decomposition 
\end_layout

\begin_layout Enumerate
One dimensional integrate-and-fire
\end_layout

\begin_layout Enumerate
Perfect integrate-and-fire
\end_layout

\begin_layout Enumerate
Leaky integrate-and-fire
\end_layout

\begin_layout Enumerate
Exponential integrate-and-fire 
\end_layout

\begin_layout Enumerate
Numerical Algorithm 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
The population density method (PDM) was introduced to neuroscience simultaneousl
y by several authors 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag,Knight2000a,Nykamp"

\end_inset

 at the end of the last century.
 PDMs seek to make use of the redundancy observed in the cortex.
 This idea was originally motivated by optical imaging studies which showed
 that visual cortex is tiled by patches which can be mapped to different
 stimulus features.
 Each of the patches contains in order of 
\begin_inset Formula $\mathcal{O}(10^{4})$
\end_inset

 neurons
\begin_inset CommandInset citation
LatexCommand cite
key "Blasdel1992a,Blasdel1992b"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citet
key "Omurtag"

\end_inset

 used this finding as an basis to model a network of interacting neurons
 using a statistical description on the level of populations.
 To arrive at such description, several simplifying assumptions need to
 be made.
 
\end_layout

\begin_layout Standard
The PDE presented in 
\begin_inset CommandInset citation
LatexCommand citet
key "Omurtag"

\end_inset

 can be applied in principle to any point neuron model.
 Point neurons approximate the entire neuron by single compartment, i.e.
 the cell body is collapsed to a single point.
 Hence, it can not account for dynamical features related to the specific
 morphology of a neuron.
 The state of an arbitrary point neuron is determined by a set of variables
 
\begin_inset Formula $\boldsymbol{v}=(v_{1},v_{2},\ldots,v_{n})$
\end_inset

 usually including the membrane potential.
 The time evolution of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 is described by first order kinetics 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset


\begin_inset Formula 
\begin{equation}
\frac{d\boldsymbol{v}}{dt}=\boldsymbol{F}(\boldsymbol{v})+\boldsymbol{S}(\boldsymbol{v},s(t)),\label{eq: neuron dynamics}
\end{equation}

\end_inset

where the vector field 
\begin_inset Formula $\boldsymbol{F}(\boldsymbol{v})$
\end_inset

 describes the time evolution of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 due to the intrinsic neuron dynamics and 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},s(t))$
\end_inset

 models the incoming synaptic current invoked by synaptic arrivals 
\begin_inset Formula $s(t)$
\end_inset

.
 A point neuron can be viewed as an input output box.
 It receives excitatory and inhibitory inputs 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},s(t))$
\end_inset

 which arrive from other neurons by their associated synapses.
 These inputs are modeled either as injected currents or as a change in
 conductance.
 Current based synapses are simpler compared to conductance based models
 because they produce a current which is independent of the state of the
 neuron.
 Hence, multiple synaptic inputs can be summed linearly.
 Conductance based synapses provide a biological more realistic description
 
\begin_inset CommandInset citation
LatexCommand cite
key "Tuckwel1983"

\end_inset

.
 They are state dependent because the synaptic current produced by a conductance
 change depends on the difference between the membrane potential and the
 reversal potential of the respective synapse which makes the summation
 of synaptic inputs nonlinear.
 If a neuron receives sufficiently strong excitatory input such that the
 membrane potential exceeds a certain threshold value, then the neuron will
 emit action potential (spike), followed by a reset mechanism and a refractory
 period.
 The output spike is then fed back into the network and contributes to the
 input to other neurons.
 
\end_layout

\begin_layout Standard
To give an example, for a Hodgkin-Huxley (H-H) type model 
\begin_inset CommandInset citation
LatexCommand cite
key "Hodgkin1952"

\end_inset

 in standard notation 
\begin_inset CommandInset citation
LatexCommand cite
key "Keener1998"

\end_inset

 with a single conductance based synapse Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: neuron dynamics"

\end_inset

 becomes 
\begin_inset Formula 
\begin{align}
\frac{dV}{dt} & =\frac{1}{C}\left(g_{L}(V_{L}+V)+g_{n}m^{3}h(V_{N}-V)+g_{K}n^{4}(V_{K}-V)\right)+\frac{1}{C}\sum_{i=1}^{N}g_{i}(t)(V_{i}^{(s)}-V)\nonumber \\
\frac{dm}{dt} & =\frac{1}{\tau_{m}(V)}(m_{\infty}(V)-m),\nonumber \\
\frac{dh}{dt} & =\frac{1}{\tau_{h}(V)}(h_{\infty}(V)-h),\nonumber \\
\frac{dn}{dt} & =\frac{1}{\tau_{n}(V)}(n_{\infty}(V)-n).\label{eq: H-H}
\end{align}

\end_inset

The state of neuron is determined by the set of variables
\begin_inset Formula $\boldsymbol{v}=(V,m,h,n)$
\end_inset

, where 
\begin_inset Formula $V$
\end_inset

 is the membrane potential, 
\begin_inset Formula $m$
\end_inset

 governs the sodium activation, 
\begin_inset Formula $h$
\end_inset

 sodium inactivation, and 
\begin_inset Formula $n$
\end_inset

 the potassium activation.
 Hence, 
\begin_inset Formula $\boldsymbol{F}(\boldsymbol{v})$
\end_inset

 is four dimensional vector with 
\begin_inset Formula 
\begin{equation}
F_{1}(\boldsymbol{v})=\frac{1}{C}\left(g_{L}(V_{L}+V)+g_{n}m^{3}h(V_{N}-V)+g_{K}n^{4}(V_{K}-V)\right),
\end{equation}

\end_inset

and 
\begin_inset Formula $F_{2},F_{3}$
\end_inset

and 
\begin_inset Formula $F_{4}$
\end_inset

 given by the last three equations in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

.
 Note that the synaptic current 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},s(t))$
\end_inset

 only causes changes in the membrane potential.
 Hence, the only entry in 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},s(t))$
\end_inset

 which is nonzero is the first one 
\begin_inset Formula $S_{1}$
\end_inset

 which we define as 
\begin_inset Formula 
\begin{equation}
I(V,s(t))=\frac{1}{C}\sum_{j=1}^{K}g_{j}^{(s)}(t)(V_{j}^{(s)}-V),\label{eq: S conductance}
\end{equation}

\end_inset

where 
\begin_inset Formula $K$
\end_inset

 is the total number afferent connections which is depicted in figure and
 
\begin_inset Formula $V_{i}^{(s)}$
\end_inset

 is the reversal potential associated with synapse 
\begin_inset Formula $i$
\end_inset

.
 For the leaky integrate-and-fire neuron model 
\begin_inset CommandInset citation
LatexCommand citep
key "Lapicque1907,Stein1967"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: H-H"

\end_inset

 simplifies to 
\begin_inset Formula 
\begin{equation}
\frac{dV}{dt}=-\frac{g_{L}}{C}(V-V_{L})+\frac{1}{C}\sum_{j=1}^{N}g_{j}(t)(V_{j}^{(s)}-V),
\end{equation}

\end_inset

Note that we considered only a single synapse type in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: S conductance"

\end_inset

 for simplicity.
 The synaptic conductance 
\begin_inset Formula $g_{i}^{(s)}(t)$
\end_inset

 is zero in absence of synaptic arrivals and becomes only nonzero for small
 time window after a spike has arrived.
 We combine all spike arrival times to a sum of delta distributions
\begin_inset Formula 
\begin{equation}
s_{j}(t)=\sum_{n}\delta(t-t_{n}^{(j)}).\label{eq: s_i(t)}
\end{equation}

\end_inset

Assuming that synaptic time scales are short compared to the membrane time
 constant.
 Based on this assumption, they approximate the conductance changes caused
 by arriving spike to be instantaneous 
\begin_inset Formula 
\begin{equation}
g_{j}(t)=\hat{g}_{j}\sum_{n}\delta(t-t_{n}^{(j)}).\label{eq: g_i(t)}
\end{equation}

\end_inset

which is referred to as delta synapses.
 The parameter 
\begin_inset Formula $\hat{g}_{j}$
\end_inset

 represent the integrated integrated countenance over time course of the
 synaptic event.
 If conductance changes are instantaneous, then the membrane potential makes
 a jump of 
\begin_inset Formula $\hat{g}_{j}(V_{s}-V(t))/C$
\end_inset

 whenever a spike arrives.
 
\end_layout

\begin_layout Standard
If we would insert Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: s_i(t)"

\end_inset

 into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

 and integrate the r.h.s., then we would obtain the deterministic time evolution
 of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 for a given spike input 
\begin_inset Formula $\boldsymbol{s}(t)=\{s_{1}(t),s_{2}(t),\ldots,s_{N}(t)\}$
\end_inset

.
 However, 
\begin_inset Formula $\boldsymbol{s}(t)$
\end_inset

 is unknown unless we simulate all neurons in the network individually.
 Hence, we are dealing with a biological system which is subject to noise,
 our goal is to approximate 
\begin_inset Formula $s_{j}(t)$
\end_inset

 by stochastic process.
 The membrane potential of a neuron is subject to two sources of noise:
 one intrinsic to the neuron, associated with stochastic nature of mechanism
 controlling the release neurotransmitter, the opening of ion channels and
 so forth.
 The other is external, arising from the apparently random arrival of individual
 spikes 
\begin_inset CommandInset citation
LatexCommand citet
key "Burkitt2006"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Mainen1995"

\end_inset

 showed in vitro, that neurons in rat cortex are able to reliably respond
 to an identical fluctuating input current injected directly into the cell
 body.
 Over several trials, neurons emitted spikes at approximate identical points
 in time with small deviations compared to the average length of interspike
 intervals.
 This suggests that intrinsic noise is insignificant compared to external
 noise associated with the stochastic synaptic input.
 
\end_layout

\begin_layout Standard
Consequently, the dominant source of randomness is assumed to be the stochastic
 arrival of spikes.
 These are usually approximated by a renewal process, i.e.
 interspike intervals (ISI) are identical and independently distributed
 
\begin_inset CommandInset citation
LatexCommand citet
key "Burkitt2006"

\end_inset

.
 We introduce the instantaneous firing rate 
\begin_inset Formula $r_{j}(t)$
\end_inset

 which can be used to calculate the number of spikes 
\begin_inset Formula $\overline{N}_{j}(t,t+\delta t)$
\end_inset

 in a small time interval 
\begin_inset Formula $[t,t+\delta t]$
\end_inset

 in the limes 
\begin_inset Formula $\delta t\rightarrow0$
\end_inset


\begin_inset Formula 
\begin{equation}
\lim_{\delta t\rightarrow0}\overline{N}_{j}(t,t+\delta t)=\lim_{\delta t\rightarrow0}r_{j}(t)\delta t.
\end{equation}

\end_inset

Note that the spike trains which arrive at different synapses of a neuron
 are in general not independent 
\begin_inset CommandInset citation
LatexCommand citep
key "Poulet2008"

\end_inset

.
 Indeed, input correlations are an inevitable consequence of two neurons
 being part of the same network, and therefore sharing some common synaptic
 input 
\begin_inset CommandInset citation
LatexCommand citep
key "Ostojic"

\end_inset

.
 However, if the network is sparsely connected, i.e.
 the number of indegrees is small compared to the network size, then the
 number of common inputs can assumed to be small.
 Furthermore, it has been shown that in recurrently connected networks inhibitio
n decorrelates neural activity 
\begin_inset CommandInset citation
LatexCommand citep
key "Tetzlaff2012,Renart2010"

\end_inset

.
 Excitation and inhibition tends to balance each other such that the membrane
 potential of individual neurons saturates beneath threshold.
 Threshold crossings in the balanced state are caused by random fluctuations
 in the input (noise driven regime) which lead to asynchronous irregular
 firing (AI), also refereed to as spontaneous activity 
\begin_inset CommandInset citation
LatexCommand citet
key "Amit1997"

\end_inset

.
 In such a setting, assuming the input at different synapses to be independent
 can be regarded as a zeroth order approximation.
 Assuming input correlations to be small, network dynamics can be studied
 perturbatively 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindner2001"

\end_inset

.
 For the reminder, we assume synaptic inputs to be independent.
 
\end_layout

\begin_layout Standard
For an arbitrary neuron 
\begin_inset Formula $i$
\end_inset

, the synaptic input is given by Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: S conductance"

\end_inset

 
\begin_inset Formula 
\begin{equation}
I_{i}(V,s(t))=\frac{1}{C}\sum_{j=1}^{K_{i}}g_{ij}^{(s)}(t)(V_{ij}^{(s)}-V),
\end{equation}

\end_inset

where 
\begin_inset Formula $g_{ij}^{(s)}(t)$
\end_inset

 describes the time evolution of the conductance associated with synapse
 which connects neuron 
\begin_inset Formula $j$
\end_inset

 to 
\begin_inset Formula $i$
\end_inset

 
\begin_inset Formula 
\begin{equation}
g_{ij}(t)=\hat{g}_{ij}\sum_{n}\delta(t-t_{n}^{(j)}).\label{eq: g_ij(t)}
\end{equation}

\end_inset

To arrive at a description on the population level, 
\begin_inset CommandInset citation
LatexCommand cite
key "Omurtag"

\end_inset

 make a mean-field ansatz, i.e.
 they replace all single neuron quantities by their population averages
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\hat{g}_{ij} & \rightarrow\hat{g}=\bigl\langle\hat{g}_{ij}\bigr\rangle,\nonumber \\
V_{ij}^{(s)} & \rightarrow V_{s}=\bigl\langle V_{ij}^{(s)}\bigr\rangle\nonumber \\
K_{i} & \rightarrow K=\bigl\langle K_{i}\bigr\rangle,\nonumber \\
r_{i}(t) & \rightarrow r(t)=\bigl\langle r_{i}\bigr\rangle.
\end{align}

\end_inset

This simplifies Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: g_ij(t)"

\end_inset

 to
\begin_inset Formula 
\begin{equation}
g_{i}(t)=\hat{g}\sum_{n=1}^{K}s_{i}(t).
\end{equation}

\end_inset

The sum is a superposition of independent renewal processes with firing
 rate 
\begin_inset Formula $r(t)$
\end_inset

 which can be well approximated by a Poisson process with firing rate 
\begin_inset Formula $Kr(t)$
\end_inset

 due to the pooling property of independent renewal processes 
\begin_inset CommandInset citation
LatexCommand citep
key "Gallager2011"

\end_inset

.
 Hence, on average each neuron feels the instantaneous firing rate 
\begin_inset Formula 
\begin{equation}
\sigma(t)=\sigma_{0}(t)+Kr(t),\label{eq: input rate}
\end{equation}

\end_inset

where 
\begin_inset Formula $\sigma_{0}(t)$
\end_inset

 is the average firing rate associated with connections from the external
 surrounding of the network.
 The mean-field ansatz is motivated by the fact that 
\begin_inset CommandInset citation
LatexCommand cite
key "Omurtag"

\end_inset

 are only interested in predicting the average behavior of the entire population.
 In the limes of large networks, the population dynamics are expected to
 be only mildly affected by the neglected heterogeneity in the connectivity.
 Indeed, 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997a"

\end_inset

 simulated a network with variable number of indegrees and stochastic synapses
 and showed that the PDM still reliably predicts the stationary firing rates
 for the individual populations in the network.
 
\end_layout

\begin_layout Standard
Having derived Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: input rate"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 introduce the probability density function 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 which described which fraction of neurons in the population are in a certain
 state space volume 
\begin_inset Formula $[\boldsymbol{v},\boldsymbol{v}+d\boldsymbol{v}]$
\end_inset

 at given point in time.
 How 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 changes over time in a small state space volume 
\begin_inset Formula $D$
\end_inset

 is determined by the equation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\partial}{\partial t}\int_{D}\rho\,d\boldsymbol{v}=-\int_{\partial D}\rho\,\boldsymbol{F}(\boldsymbol{v})\cdot\boldsymbol{n}-\int_{D}d\boldsymbol{v}\left(\frac{\delta\rho}{\partial t}\right)^{-}+\int_{D}d\boldsymbol{v}\left(\frac{\delta\rho}{\partial t}\right)^{+}\label{eq: integral density}
\end{equation}

\end_inset

The first term on the r.h.s.
 represents the probability flow out of the surface area of 
\begin_inset Formula $D$
\end_inset

 due to the intrinsic neuron dynamics.
 The next to terms represent changes in 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 due to synaptic arrivals.
 If 
\begin_inset Formula $D$
\end_inset

 is taken small enough that any neuron receiving a spike leaves 
\begin_inset Formula $D$
\end_inset

, then 
\begin_inset Formula 
\begin{equation}
\left(\frac{\delta\rho}{\partial t}\right)^{-}=\sigma(t)\rho(\boldsymbol{v},t).\label{eq: jump out}
\end{equation}

\end_inset

To determine the fraction of neurons which end op in 
\begin_inset Formula $D$
\end_inset

 due to synaptic arrivals, we need to determine the state volume 
\begin_inset Formula $D''(D)$
\end_inset

 which ends up to in 
\begin_inset Formula $D$
\end_inset

.
 Because synaptic arrivals only affect the membrane potential, we need to
 solve
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
V & =V''+h(V''-V_{s})\Leftrightarrow V''(V)=\frac{V+hV_{s}}{1+h}
\end{align}

\end_inset

and we can write 
\begin_inset Formula 
\begin{align}
\int_{D}d\boldsymbol{v}\left(\frac{\delta\rho}{\partial t}\right)^{+} & =\sigma(t)\int_{D''}d\boldsymbol{v}''\rho(\boldsymbol{v}'')\nonumber \\
 & =\sigma(t)\int_{D}d\boldsymbol{v}\rho(\boldsymbol{v}''(\boldsymbol{v}))\frac{\partial\boldsymbol{v}''}{\partial\boldsymbol{v}}d\boldsymbol{v}\label{eq: jump in}
\end{align}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: jump out"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: jump in"

\end_inset

 into 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integral density"

\end_inset

, using the theorem of Gauss one arrives at 
\begin_inset Formula 
\begin{equation}
\frac{\partial}{\partial t}\int_{D}\rho\,d\boldsymbol{v}=\int d\boldsymbol{v}\left\{ \frac{\partial}{\partial\boldsymbol{v}}(\rho\,\boldsymbol{F}(\boldsymbol{v}))-\sigma(t)\left(\rho(\boldsymbol{v},t)-\rho(\boldsymbol{v}''(\boldsymbol{v}))\frac{\partial\boldsymbol{v}''}{\partial\boldsymbol{v}}\right)\right\} 
\end{equation}

\end_inset

Because 
\begin_inset Formula $D$
\end_inset

 is small but otherwise arbitrary, we arrive at the partial differential
 equation (PDE)
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho}{\partial t}=-\frac{\partial}{\partial\boldsymbol{v}}\left(F(\boldsymbol{v})\rho\right)-\sigma(t)\times\left\{ \rho(\boldsymbol{v},t)-\rho(\boldsymbol{v}''(\boldsymbol{v}),t)\frac{\partial\boldsymbol{v}''}{\partial\boldsymbol{v}}\right\} .\label{eq: PDE}
\end{equation}

\end_inset

The above equation can be written as a continuity equation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=-\frac{\partial}{\partial\boldsymbol{v}}\boldsymbol{J}(\boldsymbol{v},t),\label{eq: continuity equation}
\end{equation}

\end_inset

where 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 is probability current which determines the flow of probability at point
 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 at a given time 
\begin_inset Formula $t$
\end_inset

.
 The probability flux has two contributions,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}=\boldsymbol{J}_{\text{str}}+\boldsymbol{J}_{\text{imp}}\label{eq: J}
\end{equation}

\end_inset

one corresponds to the intrinsic neuron dynamics
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}_{\text{str}}=\boldsymbol{F}(\boldsymbol{v})\rho(\boldsymbol{v},t),\label{eq: J_str}
\end{equation}

\end_inset

and the other corresponds the synaptic input, and therefore depends on the
 input rate 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}_{\text{imp}}=-\sigma(t)\int_{V}^{V''(V)}\boldsymbol{e}_{V}\rho(W,v_{2},\ldots)dW.\label{eq: J_imp}
\end{equation}

\end_inset

To determine the firing rate 
\begin_inset Formula $r(t)$
\end_inset

 of the population, one needs to define a threshold value 
\begin_inset Formula $V=V_{\theta}$
\end_inset

 for the the membrane potential and construct a Poincare surface at the
 this value.
 The firing rate 
\begin_inset Formula $r(t)$
\end_inset

 is given by the probability flux which goes through at 
\begin_inset Formula $t$
\end_inset

.
 Hence, the we can express 
\begin_inset Formula $r(t)$
\end_inset

 as a functional of 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 
\begin_inset Formula 
\begin{equation}
r(t)=R[\boldsymbol{J}(\boldsymbol{v},t)]\label{eq: r}
\end{equation}

\end_inset

To ensure conversation of probability, the probability which passed through
 the threshold needs to be reinserted at the reset potential 
\begin_inset Formula $V_{r}$
\end_inset

.
 This can be modeled by a introducing a absorbing boundary at the threshold.
 The crucial point is that 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 depends on 
\begin_inset Formula $\sigma(t)$
\end_inset

, and therefore on 
\begin_inset Formula $r(t)$
\end_inset

 due to Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

.
 Replacing 
\begin_inset Formula $r(t)$
\end_inset

 by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: r"

\end_inset

 and expressing 
\begin_inset Formula $\boldsymbol{J}$
\end_inset

 in terms of 
\begin_inset Formula $\rho(\boldsymbol{v},t$
\end_inset

) makes Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 a nonlinear integro partial differential equation.
 It can be solved numerically e.g.
 by using the method of characteristics 
\begin_inset CommandInset citation
LatexCommand citep
key "DeKamps2003,DeKamps2013"

\end_inset

, or analyzed analytically for particular simple neuron models.
 As a proof of principle, 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 compared numerical results from the theory against direct simulations of
 a population of uncoupled (no recurrent connections) LIF neurons demonstrating
 excellent agreement for a large enough population 
\begin_inset Formula $\mathcal{O}(>10^{4})$
\end_inset

.
 
\end_layout

\begin_layout Standard
The importance of the work by 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 comes from the fact that their method can be in principle applied to any
 type of point neuron model.
 The macroscopic Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 for the dynamics on the population level can be derived from the microscopic
 details of the neuron model without introducing any additional parameter.
 It can be generalized to networks with multiple populations each described
 by a single density function.
 Different synaptic delays can be included into Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: r"

\end_inset

 to mimic a spatial arrangement of the populations within the network.
 A large drawback of the PDM is that it can not model synaptic plasticity,
 because all heterogeneity in the connectivity needs to be averaged out
 to arrive at description on a population level.
 
\end_layout

\begin_layout Standard
In theoretical neuroscience, Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PDE"

\end_inset

 has been studied subsequently for more and more complex integrate-and-fire
 neurons 
\begin_inset CommandInset citation
LatexCommand cite
key "Amit1997,Brunel2000,Fourcaud2002,Fourcaud-Trocme2003,Brunel2003"

\end_inset

.
 All these studies are based on the diffusion approximation which we will
 introduce in the next section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Diffusion-approximation"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Diffusion approximation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Diffusion-approximation"

\end_inset


\end_layout

\begin_layout Standard
The diffusion approximation replaces the Poisson process represented by
 the second term in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PDE"

\end_inset

 by a diffusion advection process.
 The diffusion and drift coefficients can be derived by describing the time
 evolution of the probability density by the Chapman-Kolmogorov equation
 and expanding it in a Kramer-Moyals expansion 
\begin_inset CommandInset citation
LatexCommand citep
key "Riksen1992"

\end_inset

.
 For a Poisson process, the Kramers-Moyal expansion has a infinite many
 terms.
 Truncating it after the second order yields the diffusion approximation.
 We will illustrate how the diffusion approximation comes about for a general
 integrate-and-fire neuron model.
\end_layout

\begin_layout Standard
The state of an integrate-and-fire neuron is only described by the membrane
 potential 
\begin_inset Formula $V$
\end_inset

 which drastically simplifies the analysis if e.g.
 compared to the four dimensional H-H type model introduced in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: H-H"

\end_inset

.
 Despite their simplicity, they are still able to capture important dynamical
 features observed on a single neuron level, or in a network context.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Bernander1991"

\end_inset

.
 One of most commonly used point neuron models is leaky integrate-and-fire
 neuron 
\begin_inset CommandInset citation
LatexCommand citep
key "Lapicque1907,Stein1967"

\end_inset

 (LIF).
 It only describes the subthreshold dynamics of the membrane potential which
 can be modeled by RC circuit
\begin_inset Formula 
\begin{equation}
C\frac{dV}{dt}=-g_{L}(V-V_{L})+I_{\text{s}}(t),\label{eq: LIF}
\end{equation}

\end_inset

where 
\begin_inset Formula $I_{s}(t)$
\end_inset

 is the synaptic input current.
 The LIF neuron is not capable of modeling the generation of an action potential
 which needs to be included by introducing an artificial threshold 
\begin_inset Formula $V_{\text{th}}$
\end_inset

.
 If the membrane potential of the neuron exceeds 
\begin_inset Formula $V_{\text{th}}$
\end_inset

, a spike is emitted and the membrane potential is reset to a reset value
 
\begin_inset Formula $V_{\text{r}}$
\end_inset

.
 Other examples of integrate-and-fire models, are the quadratic integrate-and-fi
re 
\begin_inset CommandInset citation
LatexCommand citep
key "Ermentrout1996"

\end_inset

 (QIF) 
\begin_inset Formula 
\begin{equation}
C\frac{dV}{dt}=\frac{g_{L}}{2\Delta_{\text{th}}}(V-V_{L})(V-V_{\text{th}})+I_{\text{s}}(t),\label{eq: QIF}
\end{equation}

\end_inset

and exponential integrate-and-fire neuron model 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 (EIF)
\begin_inset Formula 
\begin{equation}
C\frac{dV}{dt}=-g_{L}(V-V_{L})+g_{L}\Delta_{\text{th}}\exp\left(\frac{V-V_{\text{th}}}{\Delta_{\text{th}}}\right)+I_{\text{s}}(t),\label{eq: EIF}
\end{equation}

\end_inset

The QIF and the EIF model both contain nonlinear dynamics to mimic the superthre
shold transients of the membrane potential due to spike initiation.
 In case of the of the QIF neuron, they are quadratic, and in case of the
 EIF, they are exponential.
 The parameter 
\begin_inset Formula $\Delta_{\text{th}}$
\end_inset

 is inversely proportional to the curvature of the 
\begin_inset Formula $I$
\end_inset

-
\begin_inset Formula $V$
\end_inset

 curve at threshold, i.e.
 it measures the sharpness of spike initiation.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Fourcaud-Trocme2003"

\end_inset

 compared the response of the LIF, QIF and EIF neuron to noisy input with
 the response of more realistic H-H type models and showed that the nonlinear
 dynamics must be included to achieve a good agreement.
 We can write Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: QIF"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: EIF"

\end_inset

 as 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=f(V)+I_{\text{s}}(t),\label{eq: integrate-and-fire}
\end{equation}

\end_inset

where 
\begin_inset Formula $\tau_{\text{m}}=C/g_{L}$
\end_inset

 is the membrane time constant and 
\begin_inset Formula $g_{L}$
\end_inset

 has been absorbed into synaptic current which is now in the units of voltage.
 The membrane time constant is typically in the order of 
\begin_inset Formula $10$
\end_inset

-
\begin_inset Formula $20$
\end_inset

ms.
 For simplicity, we assume that network consist only of a single population
 and that neurons are connected via current based synapses.
 Hence, for an arbitrary neuron 
\begin_inset Formula $i$
\end_inset

, the total incoming synaptic current is given by 
\begin_inset Formula 
\begin{equation}
I_{\text{s},i}(t)=\tau_{\text{m}}\sum_{j=1}^{K_{i}}I_{ij}(t),
\end{equation}

\end_inset

where used that the different synaptic currents superimpose linearly for
 current based synapses.
 We assume again that the time scale of the synapses is much smaller compared
 to membrane time constant and approximate the synaptic current to be instantane
ous also referred to as delta-synapses 
\begin_inset Formula 
\begin{equation}
I_{ij}(t)=J_{ij}\sum_{n=1}^{K_{i}}\delta(t-t_{n}^{(ij)})\label{eq: delta synapse-1}
\end{equation}

\end_inset

Hence, whenever a spike arrives a synapse, the membrane potential makes
 a jump by 
\begin_inset Formula $J_{ij}$
\end_inset

 followed by an exponential decay.
 Using the mean-field ansatz introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:The-population-density"

\end_inset

, we replace all quantities in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: delta synapse-1"

\end_inset

 by their population averages 
\begin_inset Formula 
\begin{equation}
I_{\text{s}}(t)=\tau_{\text{m}}J\sum_{n}^{K}\delta(t-t_{n}^{(i)}),\label{eq: synaptic current-1}
\end{equation}

\end_inset

where 
\begin_inset Formula $K=\bigl\langle K_{i}\bigr\rangle$
\end_inset

 and 
\begin_inset Formula $J=\bigl\langle J_{ij}\bigr\rangle$
\end_inset

.
 The spike times are Poisson distributed with rate 
\begin_inset Formula $\sigma(t)=Kr(t)+r_{\text{ext}}$
\end_inset

.
 The number of indegrees a cortical neuron receives are typically in the
 order of 
\begin_inset Formula $K\sim\mathcal{O}(10^{3}$
\end_inset

-
\begin_inset Formula $10^{4})$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Braitenberg2013"

\end_inset

 and firing rates are in the order of 
\begin_inset Formula $r(t)\sim\mathcal{O}(1$
\end_inset

-
\begin_inset Formula $10^{2})$
\end_inset

Hz 
\begin_inset CommandInset citation
LatexCommand cite
key "Zador1998"

\end_inset

.
 Hence, neurons receive a large number of inputs in a time interval equal
 to the size of the membrane time constant.
 If the individually inputs cause only a small changes in the membrane potential
, i.e.
 
\begin_inset Formula $J$
\end_inset

 is small compared to the distance from the reset value 
\begin_inset Formula $V_{\text{r}}$
\end_inset

 to threshold 
\begin_inset Formula $V_{\text{th}}$
\end_inset

, then 
\begin_inset Formula $I_{\text{s}}(t)$
\end_inset

 can be approximated by a Gaussian white noise which is illustrated in Fig.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset

.
 The mean 
\begin_inset Formula $\mu(t)$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}(t)$
\end_inset

 of the noise depend on the firing rate, and model parameter
\begin_inset Formula 
\begin{align}
\mu(t) & =\tau_{\text{m}}KJr(t)+\mu_{\text{ext}},\label{eq: mu}\\
\sigma^{2}(t) & =\tau_{\text{m}}KJ^{2}r(t)+\sigma_{\text{ext}}^{2}.\label{eq: sig}
\end{align}

\end_inset

Hence, we can write
\begin_inset Formula 
\begin{equation}
I_{\text{s}}(t)\approx\mu(t)+\sqrt{\tau_{\text{m}}}\sigma(t)\xi(t),\label{eq: synaptic current diffusion}
\end{equation}

\end_inset

where 
\begin_inset Formula $\xi(t)$
\end_inset

 is Gaussian white noise with zero mean and unit variance 
\begin_inset Formula 
\begin{equation}
\left\langle \xi(t)\right\rangle =0,\quad\left\langle \xi(t)\xi(t')\right\rangle =\delta(t-t')
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: synaptic current diffusion"

\end_inset

 into 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire"

\end_inset

 yields the Langevin equation 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=f(V)+\mu+\sqrt{\tau_{m}}\sigma^{2}\xi(t)\label{eq: integrate-and-fire diffusion approx}
\end{equation}

\end_inset

 The Langavin equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 can be equivalently by described by Fokker-Planck equation 
\begin_inset CommandInset citation
LatexCommand cite
key "Riksen1992"

\end_inset

 which determines the time evolution of the probability density function
 
\begin_inset Formula $\rho(V,t)$
\end_inset

 in the diffusion approximation.
 By equivalently we mean that 
\begin_inset Formula $\rho(V,t)$
\end_inset

 yields the same moments 
\begin_inset Formula $\bigl\langle V^{m}\bigr\rangle$
\end_inset

 as we would obtain directly from the Langevin equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Fokker-Planck equation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Fokker-Planck-equation"

\end_inset


\end_layout

\begin_layout Standard
The Fokker-Planck equation (FPE) which corresponds to Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 reads
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{\partial\rho(V,t)}{\partial t}=-\frac{\partial}{\partial V}[\mu+f(V)]\rho(V,t)+\frac{\sigma^{2}}{2}\frac{\partial^{2}}{\partial V}\rho(V,t),\label{eq: FPE}
\end{equation}

\end_inset

The FPE is a linear 2nd order partial differential equation which describes
 an advection diffusion process with time dependent drift 
\begin_inset Formula $D_{1}(V,t)$
\end_inset

 and diffusion coefficient 
\begin_inset Formula $D_{2}(v,t)$
\end_inset

 
\begin_inset Formula 
\begin{align}
D_{1}(V,t) & =-\frac{1}{\tau_{\text{m}}}[\mu(t)+f(V)],\quad D_{2}(t)=\frac{\sigma(t)^{2}}{2\tau_{\text{m}}}.
\end{align}

\end_inset

Note the that 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE"

\end_inset

 is equivalent to 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PDE"

\end_inset

, expect second term is replaced by a diffusion process.
 The FPE can be written as 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(V,t)}{\partial t}=L\rho(V,t),\label{eq: FPE-1}
\end{equation}

\end_inset

where 
\begin_inset Formula $L$
\end_inset

 is called Fokker-Planck operator which is given by 
\begin_inset Formula 
\begin{align}
L(t) & =\frac{\partial}{\partial V}D_{1}(V,t)+D_{2}(t)\frac{\partial^{2}}{\partial V^{2}}\label{eq: FP operator}
\end{align}

\end_inset


\end_layout

\begin_layout Subsubsection
Boundary conditions
\begin_inset CommandInset label
LatexCommand label
name "subsec:Boundary-conditions"

\end_inset


\end_layout

\begin_layout Standard
A strength of formulating the problem in terms of a FPE is that the threshold
 and reset mechanism can be incorporated into the boundary conditions.
 To show this we rewrite 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE"

\end_inset

 as a continuity equation 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(V,t)}{\partial t}=-\frac{\partial}{\partial V}J(V,t),\label{eq: FPE continuity}
\end{equation}

\end_inset

where 
\begin_inset Formula 
\begin{equation}
J(V,t)=\frac{\mu+f(V)}{\tau_{\text{m}}}\rho(V,t)-\frac{\sigma^{2}}{2\tau_{\text{m}}}\frac{\partial}{\partial V}\rho(V,t).\label{eq: FPE flux}
\end{equation}

\end_inset

is the probability current through 
\begin_inset Formula $V$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

.
 Because a spike is emitted each time 
\begin_inset Formula $V$
\end_inset

 reaches 
\begin_inset Formula $V_{\text{th}}$
\end_inset

, neurons can not reach the region 
\begin_inset Formula $V>V_{\text{th}}$
\end_inset

 from which follows that 
\begin_inset Formula $\rho(V>V_{\text{th}},t)=0$
\end_inset

.
 The probability flux 
\begin_inset Formula $J(V_{\text{th}},t)$
\end_inset

 yields the fraction of neuron passing through threshold at a given time
 which is equivalent to the firing rate 
\begin_inset Formula $J(V_{\text{th}},t)=r(t)$
\end_inset

.
 From 
\begin_inset Formula $\rho(V>V_{\text{th}},t)$
\end_inset

 follows that 
\begin_inset Formula $\rho(V_{\text{th}},t)=0$
\end_inset

 because 
\begin_inset Formula $\rho(V,t)$
\end_inset

 would otherwise be discontinuous at threshold and its derivative infinite.
 This would result into an infinite firing rate due to 
\begin_inset Formula $J(V_{\text{th}},t)\propto\frac{\partial}{\partial V}\rho(V_{\text{th}},t)$
\end_inset

.
 Neurons are reset immediately to the reset after the spike emission.
 To ensure conversation of probability, the probability flux passing the
 threshold must be reinserted at the reset value 
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0}J(V_{\text{r}}+\epsilon,t)-J(V_{\text{r}}-\epsilon,t)=J(V_{\text{th}},t).
\end{equation}

\end_inset

Finally, neurons should not enter the system from left boundary, i.e.
 the probability current needs to vanish 
\begin_inset Formula ${\displaystyle \lim_{V\rightarrow-\infty}}J(V,t)=0$
\end_inset

 for 
\begin_inset Formula $V\rightarrow-\infty$
\end_inset

.
 To summarize, we have in total three boundary boundary conditions (BC)
 illustrated in figure 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Left boundary condition: 
\begin_inset Formula 
\begin{equation}
\lim_{V\rightarrow-\infty}J(V,t)=0\label{eq: left bc}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Right boundary condition: 
\begin_inset Formula 
\begin{equation}
\rho(V_{\text{th}},t)=0\label{eq: right bc}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Reset boundary condition: 
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0}J(V_{\text{r}}+\epsilon,t)-J(V_{\text{r}}-\epsilon,t)=J(V_{\text{th}},t)=r(t).\label{eq: reset bc}
\end{equation}

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
If the rate pooled inputs is large, and the change jumps caused in the synaptic
 current is small, then the can be approximated by a Gaussian white noise.
 This is illustrated in figure [] The normalized contribution of a single
 
\begin_inset Formula $\delta$
\end_inset

-function input is called postsynaptic response function 
\begin_inset CommandInset citation
LatexCommand cite
key "Burkitt2006a"

\end_inset


\begin_inset Formula 
\[
\epsilon(t)=\frac{1}{\tau_{\text{m}}}e^{-\frac{t}{\tau_{\text{m}}}}\theta(t)
\]

\end_inset

The normalized postsynaptic response function is given by 
\begin_inset Formula 
\begin{equation}
\epsilon(t)=\frac{e^{-\frac{t}{\tau_{\text{m}}}}-e^{-\frac{t}{\tau_{\text{s}}}}}{\tau_{\text{m}}-\tau_{\text{s}}}\theta(t)
\end{equation}

\end_inset


\end_layout

\begin_layout Plain Layout
It replaces the synaptic current in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: neuron dynamics"

\end_inset

 by an average current plus an additional Gaussian white noise.
 The diffusion approximation can be understood as an approximation of the
 Poisson input in the limes of large input rates and small synaptic efficacies
 
\begin_inset Formula $h$
\end_inset

.
 By small, we mean that the post synaptic potential PSP induced by spike
 arrival is small compared to the distance from the reset to the threshold
 potential.
 
\end_layout

\begin_layout Plain Layout
The strength of the noise and the average input current depend on the rate
 of the Poisson input and the parameters of the neuron model.
 In the diffusion approximation, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 reduces to a Fokker-Planck equation.
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Solving the Fokker-Planck equation
\end_layout

\begin_layout Subsubsection
Stationary case 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Stationary-case"

\end_inset


\end_layout

\begin_layout Standard
To determine points of stationary activity 
\begin_inset Formula $r(t)=r_{0}$
\end_inset

, one needs to find the stationary solution of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE continuity"

\end_inset


\begin_inset Formula 
\begin{equation}
0=-\frac{\partial}{\partial V}J(V,t).
\end{equation}

\end_inset

The above equation tells us that the flux must be constant.
 From left BC follows 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: left bc"

\end_inset

 that 
\begin_inset Formula $J(V,t)$
\end_inset

 must be zero for 
\begin_inset Formula $V\rightarrow-\infty$
\end_inset

.
 From 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: reset bc"

\end_inset

 that the flux must be equivalent to the rate 
\begin_inset Formula $r_{0}$
\end_inset

 at threshold.
 Hence, 
\begin_inset Formula $J(V,t)$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

 from 
\begin_inset Formula $V<V_{r}$
\end_inset

 and makes a jump to 
\begin_inset Formula $r$
\end_inset

 at the reset the 
\begin_inset Formula $V_{r}$
\end_inset

 which we can write as
\begin_inset Formula 
\[
J(V,t)=r\Theta(V-V_{\text{th}})\Theta(V-V_{\text{r}}).
\]

\end_inset

Substituting 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE flux"

\end_inset

 into yields the stationary density 
\begin_inset Formula $\rho_{0}(V)$
\end_inset

 from which the stationary firing rate can be calculated 
\begin_inset CommandInset citation
LatexCommand cite
key "Amit1997"

\end_inset


\begin_inset Formula 
\begin{align}
r & =\Phi(\mu,\sigma^{2})\label{eq: rate}
\end{align}

\end_inset

where 
\begin_inset Formula $\Phi(\mu,\sigma^{2})$
\end_inset

 given by
\begin_inset Formula 
\begin{equation}
\Phi(\mu,\sigma^{2})=\frac{1}{\tau_{\text{m}}\sqrt{\pi}}\int_{\frac{V_{\text{r}}-\mu}{\sigma}}^{\frac{V_{\text{th}}-\mu}{\sigma}}(1+\text{erf}(x))e^{x^{2}}dx.
\end{equation}

\end_inset

It is crucial to notice that 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

 both depend on the firing themselves.
 Hence, we need to find self-consistent solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: rate"

\end_inset

.
 So far we only considered a single population network.
 In network with multiple populations 
\begin_inset Formula $\boldsymbol{\alpha}=\{1,2,\ldots,M\}$
\end_inset

, mean an variance are given by 
\begin_inset Formula 
\begin{align}
\mu_{\alpha}(\boldsymbol{r}) & =\tau_{\text{m}}\sum_{\beta}K_{\alpha\beta}J_{\alpha\beta}r_{\beta}+\mu_{\text{ext}},\label{eq: mu multi}\\
\sigma_{a}^{2}(\boldsymbol{r}) & =\tau_{\text{m}}\sum_{\beta}K_{\alpha\beta}J_{\alpha\beta}r_{\beta}+\sigma_{\text{ext}}^{2},\label{eq: sigma multi}
\end{align}

\end_inset

where 
\begin_inset Formula $\boldsymbol{r}=(r_{1},\ldots,r_{M})$
\end_inset

.
 The firing rate of population 
\begin_inset Formula $\alpha$
\end_inset

 is given by 
\begin_inset Formula 
\[
r_{\alpha}(\boldsymbol{r})=\Phi(\mu_{\alpha}(\boldsymbol{r}),\sigma_{\alpha}^{2}(\boldsymbol{r}))=\frac{1}{\tau_{\text{m}}\sqrt{\pi}}\int_{\frac{V_{\text{r}}-\mu_{\alpha}}{\sigma_{\alpha}}}^{\frac{V_{\text{th}}-\mu_{\alpha}}{\sigma_{\alpha}}}(1+\text{erf}(x))e^{x^{2}}dx,
\]

\end_inset

where 
\begin_inset Formula $\mu_{\alpha}$
\end_inset

 and 
\begin_inset Formula $\sigma_{\alpha}$
\end_inset

 depend on 
\begin_inset Formula $\boldsymbol{r}=\{r_{1},r_{2},\ldots,r_{M})$
\end_inset

 which can be seen from Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: mu multi"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: sigma multi"

\end_inset

.
 To find stationary states of the network, we need to find values for the
 vector 
\begin_inset Formula $\boldsymbol{r}$
\end_inset

 which solve the set of 
\begin_inset Formula $M$
\end_inset

 equations in a self-consistent manner.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 used the diffusion approximation to derive the stationary average rates
 in a recurrently randomly connected network of LIF neurons, mimicking a
 cortical column.
 The network in the study consists of an excitatory and inhibitory population
 (EI-Network).
 The populations receive additional uncorrelated stationary excitatory input
 from the external surrounding of the network.
 This external input represents the global spontaneous ongoing activity
 observed in cortex which has typically low firing rates 
\begin_inset Formula $1$
\end_inset

-
\begin_inset Formula $5$
\end_inset

 Hz.
 The purely excitatory external input is motivated by the fact that excitatory
 pyramidal neurons tend to form longer axons compared to inhibitory neurons
 which connect more locally 
\begin_inset CommandInset citation
LatexCommand citep
key "Braitenberg2013"

\end_inset

.
 The stationary solution of the Fokker-Planck equation yields the stationary
 firing rate of the excitatory and inhibitory population for a given input
 rate 
\begin_inset CommandInset citation
LatexCommand citep
key "A.1953"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 showed that the equation for the stationary firing rage has a solution
 for which the average firing rate of the excitatory population matches
 the spontaneous activity of the external surrounding.
 This is desirable because the excitatory population is the external surrounding
 from the perspective of the neighboring cortical columns.
 Finding the solution for the output firing rate of a population which reproduce
s the initial input firing rate is often referred to as self-consistent
 mean-field theory 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

.
 Spontaneous activity is hypothesized to be a ground state of the brain.
 Compared to silent networks, a spontaneous active network has the advantage
 that it places neurons close to the threshold, rather at their resting
 potential so that the network can respond faster to a stimulus.
\end_layout

\begin_layout Subsubsection
Time dependent case 
\end_layout

\begin_layout Standard
Solving the time dependent Fokker-Planck equation is a difficult task.
 The stability of the stationary state presented in 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 has been studied extensively in 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000,Brunel1999,Lindner2001"

\end_inset

.
 If the temporal modulation of the firing rate is small compare to its stationar
y baseline 
\begin_inset Formula 
\begin{equation}
r(t)=r+\delta r(t),
\end{equation}

\end_inset

with 
\begin_inset Formula $\bigl|\delta r(t)\bigr|\ll r$
\end_inset

, then perturbation theory 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 applicable.
 The mean 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: mu"

\end_inset

 and variance 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: sig"

\end_inset

 of the Gaussian white noise can be split into a constant and time dependent
 part 
\begin_inset Formula 
\begin{align}
\mu(t) & =\mu+\delta\mu(t)\\
\sigma^{2}(t) & =\sigma^{2}+\delta\sigma^{2}(t)
\end{align}

\end_inset

and Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE continuity"

\end_inset

 becomes
\begin_inset Formula 
\begin{align}
\frac{\partial\rho(V,t)}{\partial t} & =\left(-\frac{\partial}{\partial V}\frac{\mu+f(V)}{\tau_{\text{m}}}+\frac{\sigma^{2}}{2\tau_{\text{m}}}\frac{\partial^{2}}{\partial V^{2}}\right)\rho(V,t)+\left(-\delta\mu(t)\frac{\partial}{\partial V}+\frac{\delta\sigma^{2}(t)}{2}\frac{\partial^{2}}{\partial V^{2}}\right)\rho(V,t)\label{eq: FPE time dependent-3}
\end{align}

\end_inset

Note that 
\begin_inset Formula $\delta\mu(t)$
\end_inset

 and 
\begin_inset Formula $\delta\sigma(t)$
\end_inset

 both depend implicitly one time through 
\begin_inset Formula $\delta r(t)$
\end_inset

.
 We define the relative rate modulation 
\begin_inset Formula $\epsilon(t)=\delta r(t)/r$
\end_inset

 as a small parameter Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE time dependent-3"

\end_inset

 can be written
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(V,t)}{\partial t}=L_{0}\rho(V,t)+\epsilon(t)L_{1}\rho(V,t)\label{eq: FPE time dependent}
\end{equation}

\end_inset

The above equations has been be solved to first order in 
\begin_inset Formula $\epsilon(t)$
\end_inset

 in 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 using the following steps.
 Expand the 
\begin_inset Formula $\rho(V,t)$
\end_inset

 around the stationary solution derived in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Stationary-case"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\rho(V,t)=\rho_{0}(V)+\rho_{1}(V,t)+\rho_{2}(V,t)+\ldots
\end{equation}

\end_inset

with 
\begin_inset Formula $\rho_{n}(V,t)\sim\mathcal{O}(\epsilon(t)^{n})$
\end_inset

.
 Substituting into Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE time dependent"

\end_inset

 and keeping only those terms up to first order in 
\begin_inset Formula $\epsilon(t)$
\end_inset

 yields 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho_{1}(V,t)}{\partial t}=L_{0}\rho_{1}(V,t)+\epsilon(t)L_{1}\rho_{0}(V)+\mathcal{O}(\epsilon)\label{eq: FPE time dependent-1}
\end{equation}

\end_inset

where we used that 
\begin_inset Formula $\rho_{0}(V)$
\end_inset

 is time independent and 
\begin_inset Formula $L_{0}\rho(V)=0$
\end_inset

.
 The above equation is a first order inhomogeneous partial differential
 equation for 
\begin_inset Formula $\rho_{1}(V,t)$
\end_inset

.
 It is sufficient to consider only sinusoidal modulations, because we can
 Fourier transform 
\begin_inset Formula $\epsilon(t)$
\end_inset


\begin_inset Formula 
\[
\epsilon(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}d\omega\,\epsilon(\omega)e^{i\omega t}
\]

\end_inset

and solve each frequency component separately due to the linearity of the
 problem.
 Hence, we make a complex ansatz 
\begin_inset Formula 
\[
\epsilon(t)=\epsilon(\omega)e^{i\omega t}
\]

\end_inset

 Substituting into 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE time dependent-1"

\end_inset

 and using separation of variables 
\begin_inset Formula $\rho_{1}(V,t)=\rho_{1}(V)e^{i\omega t}$
\end_inset

 yields a inhomogeneous linear ordinary differential equation for 
\begin_inset Formula $\rho_{1}(V)$
\end_inset


\begin_inset Formula 
\begin{equation}
\left(i\omega-L_{0}\right)\rho_{1}(V,t)=L_{1}\rho_{0}(V).\label{eq: FPE time dependent-2}
\end{equation}

\end_inset

The solution of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE time dependent-2"

\end_inset

 is given by the homogeneous solution plus the particular solution which
 reproduces the inhomogeneity on the r.h.s.
 The free coefficients in the homogeneous solution need to be determined
 such that the sum of the homogeneous and the particular solution fulfill
 the boundary conditions which we discussed in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Boundary-conditions"

\end_inset

.
 Skipping the details of calculation, 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 derived the transfer function 
\begin_inset Formula $T(\omega)$
\end_inset

 which determines how a frequency component 
\begin_inset Formula $\epsilon(\omega)$
\end_inset

 on the input side is changed on the output side 
\begin_inset Formula $\overline{\epsilon}(\omega)$
\end_inset

 
\begin_inset Formula 
\begin{equation}
\overline{\epsilon}(\omega)=T(\omega)\epsilon(\omega).\label{eq: transfer function}
\end{equation}

\end_inset

Taking the Fourier back transform of the above equation shows that the neurons
 acts as a linear filter in first order approximation 
\begin_inset Formula 
\begin{equation}
\overline{r}(t)=\Phi(r)+r\int_{-\infty}^{t}T(t)\epsilon(t),
\end{equation}

\end_inset

where the kernel 
\begin_inset Formula $T(t)$
\end_inset

 is Fourier back transform of transfer function 
\begin_inset Formula $T(\omega)$
\end_inset

.
 The gain of response is related to the modulus 
\begin_inset Formula $\left|T(\omega)\right|$
\end_inset

 and the phase shift to the argument 
\begin_inset Formula $\arg[T(\omega)]$
\end_inset

 .
 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 showed that the self-consistent solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: transfer function"

\end_inset

  mark that the points where the stationary state loses stability and network
 network transitions into a regime which can sustain global oscillations.
 Depending on the strength of the external input, the balance between excitation
 and inhibition, and the time scale of the synaptic delay, the average firing
 rate of the populations can show oscillations in different frequency regimes.
 Independently of the global oscillations, the firing of individual neurons
 are still highly irregular.
 The work by 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 has been the first analytical study investigating the synchronization propertie
s of randomly connected recurrent spiking neural networks.
 
\end_layout

\begin_layout Standard
The transfer function 
\begin_inset Formula $T(\omega)$
\end_inset

 for LIF neuron behaves like a low-pass filter dropping of with 
\begin_inset Formula $1/\sqrt{\omega}$
\end_inset

 in the high frequency limit.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 studied the frequency response for nonlinear integrate-and-fire neurons
 and showed that EIF acts as a filter with constant gain in the low and
 intermediate frequency range followed by a 
\begin_inset Formula $1/\omega$
\end_inset

 drop off in high frequency limit.
 These results hold for current-based as well as conductance-based synapses,
 because the spike-generating currents dominate the neuronal dynamics and
 the synaptic input has little effect on what happens after spike initiation.
 Replacing the delta-synapses by synapses with finite synaptic time scale
 introduces temporal correlations into the input noise which decay on the
 order the synaptic time scale.
 The temporal correlations can be effectively modeled by replacing the Gaussian
 white noise in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 by colored noise 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud2002"

\end_inset

 with a auto-correlation function which decays exponentially on the same
 time scale as the synapse.
 Using numerical simulations, 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 showed that the filtering properties of the EIF are in good agreement with
 those of more realistic H-H type models used in 
\begin_inset CommandInset citation
LatexCommand cite
key "Hansel2002"

\end_inset

.
 
\end_layout

\begin_layout Standard
Knowing how the filtering properties of spiking neuronal model can be used
 to map spiking neuron models to rate based models as it has been done in
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset

.
 All the presented studies are only leading order results which are only
 valid if the temporal modulation are small.
 Since the derivation for LIF neuron are already quite involved, it seems
 to likely that extending the results to more complex neuron models and
 higher orders requires a combination of analytical and numerical tools.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Deniz2017"

\end_inset

 recently solved the stationary FPE for the LIF neuron for arbitrary input
 correlations using the method of spectral decomposition.
 They showed that their method can be related to arbitrary orders of the
 perturbative approach used in 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindner2001"

\end_inset

 who assumed small small correlations.
 The method of spectral decomposition expands the density function in terms
 of the eigenfunctions of the differential operator which describes its
 time evolution.
 It has been first introduced in the context of PDM by 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

.
\end_layout

\begin_layout Subsection
Spectral decomposition
\begin_inset CommandInset label
LatexCommand label
name "subsec:Spectral-decomposition"

\end_inset


\end_layout

\begin_layout Standard
In this section we follow the notation introduced in 
\begin_inset CommandInset citation
LatexCommand citep
key "Knight2000a"

\end_inset

.
 We start from equation Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PDE"

\end_inset

 and Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE"

\end_inset

 which both can be written as 
\begin_inset Formula 
\begin{multline}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=Q(\boldsymbol{v},r(t))\rho(\boldsymbol{v},t),\label{eq: rho operator}
\end{multline}

\end_inset

where 
\begin_inset Formula $Q$
\end_inset

 is called the dynamical operator which depends implicitly on time through
 its dependence on the input firing rate 
\begin_inset Formula $r(t)$
\end_inset

.
 In the diffusion approximation, 
\begin_inset Formula $Q$
\end_inset

 is equivalent to the Fokker-Planck operator introduced in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FP operator"

\end_inset

.
 For a given value of the input 
\begin_inset Formula $r(t)$
\end_inset

, 
\begin_inset Formula $Q$
\end_inset

 has a set of eigenfunctions 
\begin_inset Formula $\phi_{n}(\boldsymbol{v},t)$
\end_inset

 defined by 
\begin_inset Formula 
\begin{equation}
Q(\boldsymbol{v},r(t))\phi_{n}(\boldsymbol{v},t)=\lambda_{n}(t)\phi_{n}(\boldsymbol{v},t).\label{eq: phi_n}
\end{equation}

\end_inset

Note that both eigenfunctions and eigenvalues are time dependent because
 
\begin_inset Formula $Q$
\end_inset

 changes in time.
 Hence, we are dealing with moving basis.
 In the following, suppress the time argument for convenience.
 The dynamical operator 
\begin_inset Formula $Q$
\end_inset

 is not Hermitian (self-adjoint) due to the first derivative in the drift
 term in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PDE"

\end_inset

 and Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE"

\end_inset

.
 For non Hermitian operators, eigenvalues 
\begin_inset Formula $\lambda_{n}$
\end_inset

 are in general complex and the eigenfunctions 
\begin_inset Formula $\phi_{n}(\boldsymbol{v})$
\end_inset

 are not orthogonal.
 Taking the complex conjugate of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: phi_n"

\end_inset

 and using that 
\begin_inset Formula $Q$
\end_inset

 is real, we find that 
\begin_inset Formula 
\begin{equation}
Q(\boldsymbol{v})\phi_{n}^{*}(\boldsymbol{v})=\lambda_{n}^{*}\phi_{n}^{*}(\boldsymbol{v})
\end{equation}

\end_inset

that eigenvalues and eigenfunctions of 
\begin_inset Formula $Q$
\end_inset

 come in complex conjugate pairs.
 If the set of eigenfunctions 
\begin_inset Formula $\{\phi_{n}(\boldsymbol{v})\}$
\end_inset

 are complete, then we can expand the density function in terms of eigenfunction
s
\begin_inset Formula 
\begin{equation}
\rho(\boldsymbol{v},t)=\sum_{n=-\infty}^{\infty}c_{n}(t)\phi_{n}(\boldsymbol{v}),\label{eq: eigenfunction expansion}
\end{equation}

\end_inset

where introduced the notation 
\begin_inset Formula $\phi_{-n}(\boldsymbol{v})=\phi_{n}^{*}(\boldsymbol{v})$
\end_inset

.
 The weighting coefficient 
\begin_inset Formula $c_{n}(t)$
\end_inset

 describe how the 
\begin_inset Formula $n$
\end_inset

th mode contribute to 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 a given point in time.
 The density 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 must fulfill the boundary conditions introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Boundary-conditions"

\end_inset

, i.e.
 each eigenfunction 
\begin_inset Formula $\phi_{n}(\boldsymbol{v})$
\end_inset

 must fulfill the boundary conditions for 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 individually to ensure that any linear combination of eigenfunctions fulfills
 them as well.
 To determine the weighting coefficients 
\begin_inset Formula $c_{n}(t)$
\end_inset

, we need to construct a basis 
\begin_inset Formula $\left\{ \tilde{\phi}_{n}(\boldsymbol{v})\right\} $
\end_inset

which is orthogonal to 
\begin_inset Formula $\{\phi_{n}(\boldsymbol{v})\}$
\end_inset

.
 We equip the state space with an inner product given by the bilinear integral
 
\begin_inset Formula 
\begin{equation}
(\tilde{\phi},\phi)=\int d\boldsymbol{v}\,\tilde{\phi}(\boldsymbol{v})\phi(\boldsymbol{v}).\label{eq: inner product}
\end{equation}

\end_inset

For a given inner product, the adjoint operator 
\begin_inset Formula $Q^{\dagger}$
\end_inset

 of 
\begin_inset Formula $Q$
\end_inset

 is defined by the equation 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
(\tilde{\phi},Q\phi)=(Q^{\dagger}\tilde{\phi},\phi).\label{eq: Q adjoint}
\end{equation}

\end_inset

The eigenfunctions 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 of the adjoint operator 
\begin_inset Formula $O^{\dagger}$
\end_inset

 are given by 
\begin_inset Formula 
\begin{equation}
Q^{\dagger}\tilde{\phi}_{n}(\boldsymbol{v})=\tilde{\lambda}_{n}\tilde{\phi}_{n}(\boldsymbol{v}).
\end{equation}

\end_inset

The boundary conditions for eigenfunctions 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 must be chosen such the surface terms in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: Q adjoint"

\end_inset

 vanish.
 We use that eigenvalues of an operator and its adjoint operator are equivalent
 
\begin_inset Formula $\tilde{\lambda}_{n}=\lambda_{n}$
\end_inset

 and write 
\begin_inset Formula 
\[
\lambda_{n}(\tilde{\phi}_{m},\tilde{\phi}_{n})=(\tilde{\phi}_{m},Q\tilde{\phi}_{n})=(Q^{\dagger}\tilde{\phi}_{m},\tilde{\phi}_{n})=\lambda_{m}(\tilde{\phi}_{m},\tilde{\phi}_{n}),
\]

\end_inset

where we used Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: Q adjoint"

\end_inset

 in the third step.
 Subtracting the r.h.s.
 from the from the l.h.s.
 yields 
\begin_inset Formula 
\[
(\lambda_{n}-\lambda_{m})(\tilde{\phi}_{m},\tilde{\phi}_{n})=0
\]

\end_inset

Since one or the other factor must vanish, we find that set the eigenfunctions
 of 
\begin_inset Formula $Q$
\end_inset

 and 
\begin_inset Formula $Q^{\dagger}$
\end_inset

 are orthogonal for 
\begin_inset Formula $n\neq m$
\end_inset

.
 Using proper normalization, we can write 
\begin_inset Formula 
\begin{equation}
(\tilde{\phi}_{m},\phi_{n})=\delta_{nm}\label{eq: orthogonality}
\end{equation}

\end_inset

Hence, the set of eigenfunctions 
\begin_inset Formula $\{\tilde{\phi}_{n}(\boldsymbol{v}),\phi_{n}(\boldsymbol{v})\}$
\end_inset

 form a biorthonormal set.
 Some remarks on the properties of spectrum of 
\begin_inset Formula $Q$
\end_inset

 derived in 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

: 
\end_layout

\begin_layout Enumerate
The real part of all eigenvalues is negative 
\begin_inset Formula $\text{Re}(\lambda_{n})\leq0$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\lambda_{0}=0$
\end_inset

 is a eigenvalue of 
\begin_inset Formula $Q$
\end_inset

 and the associated eigenfunction 
\begin_inset Formula $\phi_{0}(\boldsymbol{v})$
\end_inset

 is the stationary solution 
\begin_inset Formula $Q(\boldsymbol{v},r)\rho_{0}(\boldsymbol{v})=0$
\end_inset


\end_layout

\begin_layout Enumerate
The corresponding eigenfunction 
\begin_inset Formula $\tilde{\phi}_{0}(\boldsymbol{v})$
\end_inset

 is constant which can be set to 
\begin_inset Formula $1$
\end_inset

 such that 
\begin_inset Formula $(\tilde{\phi}_{0}(\boldsymbol{v}),\phi_{0}(\boldsymbol{v}))=\int d\boldsymbol{v}\,\rho_{0}(\boldsymbol{v})=1$
\end_inset

 
\end_layout

\begin_layout Enumerate
From 
\begin_inset Formula $(\tilde{\phi}_{0}(\boldsymbol{v}),\phi_{n}(\boldsymbol{v}))=0$
\end_inset

 follows 
\begin_inset Formula $0=\int d\boldsymbol{v}\phi_{n}(\boldsymbol{v})$
\end_inset

, i.e.
 all probability is contained in the zero mode 
\begin_inset Formula $\phi_{0}(\boldsymbol{v})=\rho_{0}(\boldsymbol{v})$
\end_inset

 
\end_layout

\begin_layout Standard
We are now ready, to determine the time evolution of the weighting coefficients
 for a given initial condition 
\begin_inset Formula $\rho(\boldsymbol{v},0)=f(\boldsymbol{v})$
\end_inset

.
 We start with simplest example, a population of non-interacting neurons.
 
\end_layout

\begin_layout Subsubsection
Non-interacting neurons stationary input rate 
\end_layout

\begin_layout Standard
By non-interacting, we mean that all recurrent connections cut and all neurons
 receive the same constant external input 
\begin_inset Formula $r_{\text{ext}}=r$
\end_inset

.
 We start from Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: rho operator"

\end_inset


\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=Q(\boldsymbol{v},r)\rho(\boldsymbol{v},t).
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: eigenfunction expansion"

\end_inset

 for 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 on both sides yields 
\begin_inset Formula 
\begin{equation}
\sum_{m=-\infty}^{\infty}\left(\frac{\partial}{\partial t}c_{m}(t)\right)\phi_{m}(\boldsymbol{v})=\sum_{m=-\infty}^{\infty}c_{m}(t)\lambda_{m}\phi_{m}(\boldsymbol{v})
\end{equation}

\end_inset

Note that eigenvalues and eigenfunctions are both time independent because
 
\begin_inset Formula $r$
\end_inset

 is constant.
 Multiplying with 
\begin_inset Formula $\tilde{\phi}_{n}(\boldsymbol{v})$
\end_inset

 from the l.h.s.
 and integrating over the state space yields 
\begin_inset Formula 
\begin{align}
\sum_{m=-\infty}^{\infty}\left(\frac{\partial}{\partial t}c_{m}(t)\right)(\tilde{\phi}_{n},\phi_{m}) & =\sum_{m=-\infty}^{\infty}\lambda_{m}(\phi_{n},\tilde{\phi}_{m})
\end{align}

\end_inset

Using orthogonality 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: orthogonality"

\end_inset

, we arrive at 
\begin_inset Formula 
\begin{equation}
\frac{\partial}{\partial t}c_{n}(t)=\lambda_{m}.
\end{equation}

\end_inset

Hence, we find that 
\begin_inset Formula $c_{n}(t)$
\end_inset

 is given by 
\begin_inset Formula 
\begin{equation}
c_{n}(t)=c_{n}(0)e^{\lambda_{n}t}\label{eq: c_n(t)}
\end{equation}

\end_inset

The initial value 
\begin_inset Formula $c_{n}(0)$
\end_inset

 can be determined from initial condition 
\begin_inset Formula $\rho(\boldsymbol{v},0)=f(\boldsymbol{v})$
\end_inset

 
\begin_inset Formula 
\begin{equation}
c_{n}(0)=(\tilde{\phi},f(\boldsymbol{v})).
\end{equation}

\end_inset

From 
\begin_inset Formula $\text{Re}(\lambda_{n})<0$
\end_inset

 follows that all 
\begin_inset Formula ${\displaystyle \lim_{t\rightarrow\infty}}c_{n}(t)=0$
\end_inset

 expect for 
\begin_inset Formula $c_{0}(t)=1$
\end_inset

.
 Hence, all modes, except for zero mode, die out over time and 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 converges to 
\begin_inset Formula $\phi_{0}(\boldsymbol{v})=\rho_{0}(\boldsymbol{v}).$
\end_inset

 The the time of the exponential decay 
\begin_inset Formula $\tau_{n}$
\end_inset

 is given by 
\begin_inset Formula $\tau_{n}=1/\left|\text{Re}(\lambda_{1})\right|$
\end_inset

.
 Hence, it males sense to order the modes according to the magnitude of
 the real part of their associated eigenvalues 
\begin_inset Formula 
\[
0\leq\left|\text{Re}(\lambda_{1})\right|\leq\left|\text{Re}(\lambda_{2})\right|\leq\left|\text{Re}(\lambda_{3})\right|\leq\ldots
\]

\end_inset

The natural next step is consider a population of non-interacting neurons
 which receives a time dependent external input.
\end_layout

\begin_layout Subsubsection
Non-interacting neurons with time dependent input 
\end_layout

\begin_layout Standard
If the external rate is time dependent 
\begin_inset Formula $r_{\text{ext}}(t)=r(t)$
\end_inset

, then eigenvalues and eigenvectors will be time dependent.
 We start again from Eq.
 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=Q(\boldsymbol{v},r(t))\rho(\boldsymbol{v},t)
\end{equation}

\end_inset

Substituting 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: eigenfunction expansion"

\end_inset

 for 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 yields 
\begin_inset Formula 
\begin{align*}
\sum_{m}\frac{\partial}{\partial t}\left(c_{m}(t)\phi_{m}(\boldsymbol{v},t)\right) & =\sum_{m}\lambda_{m}c_{m}(t)\phi_{m}(\boldsymbol{v},t),\\
\sum_{m}\left\{ \frac{\partial c_{m}(t)}{\partial t}\phi_{m}(\boldsymbol{v},t)+c_{m}(t)\frac{\partial\phi_{m}(\boldsymbol{v},t)}{\partial r}\frac{\partial r(t)}{\partial t}\right\}  & =\sum_{m}\lambda_{m}c_{m}(t)\phi_{m}(\boldsymbol{v},t),
\end{align*}

\end_inset

where we used the chain rule for second term on the l.h.s.
 Multiplying from the left with 
\begin_inset Formula $\tilde{\phi}_{n}(\boldsymbol{v},t)$
\end_inset

 and integrating over the state space yields 
\begin_inset Formula 
\begin{align*}
\sum_{m}\left\{ \frac{\partial c_{m}(t)}{\partial t}(\tilde{\phi}_{n},\phi_{m})+c_{m}(t)\frac{\partial r(t)}{\partial t}(\tilde{\phi}_{n},\frac{\partial\phi_{m}}{\partial r})\right\}  & =\sum_{m}\lambda_{m}(\tilde{\phi}_{n}(\boldsymbol{v},t),\phi_{m}(\boldsymbol{v},t))\\
\frac{\partial c_{m}(t)}{\partial t}+\frac{\partial r(t)}{\partial t}(\tilde{\phi}_{n},\frac{\partial\phi_{m}}{\partial r})c_{m}(t) & =\lambda_{m}c_{m}(t)
\end{align*}

\end_inset

Following 
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002"

\end_inset

, defining the matrix 
\begin_inset Formula $A_{mn}=(\tilde{\phi}_{n},\frac{\partial\phi_{m}}{\partial r})$
\end_inset

, the above equation can be written as matrix equation 
\begin_inset Formula 
\[
\frac{\partial\boldsymbol{c}}{\partial t}=\left(\boldsymbol{\Lambda}-\frac{\partial r(t)}{\partial t}\boldsymbol{A}_{mn}\right)\boldsymbol{c}
\]

\end_inset

Note that matrix 
\begin_inset Formula $\boldsymbol{A}_{nm}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{\Lambda}$
\end_inset

 both depend on time.
 
\end_layout

\begin_layout Subsubsection
Interacting-neurons with time dependent input 
\end_layout

\begin_layout Standard
To include the interaction, we need to incoporate the firing rate 
\begin_inset Formula 
\[
r(t)=R[\boldsymbol{J}(\boldsymbol{v},t)]
\]

\end_inset

where is given by a linear operator 
\begin_inset Formula 
\[
J(\boldsymbol{v},t)=C\rho(\boldsymbol{v},t)
\]

\end_inset

Expanding 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 in terms of the eigenfunctions expresses 
\begin_inset Formula $r(t)$
\end_inset

 in terms of the eigenfunctions, and therefore in terms of the weighting
 coefficients 
\begin_inset Formula $\boldsymbol{c}$
\end_inset

.
 Hence, the set of equations need to be solved self-consistently 
\begin_inset Formula 
\begin{align*}
\frac{\partial\boldsymbol{c}}{\partial t} & =\left(\boldsymbol{\Lambda}-\frac{\partial r(t)}{\partial t}\boldsymbol{A}\right)\boldsymbol{c}\\
r(t) & =\sum_{n}R\left[C\left(c_{n}(t)\phi_{n}(\boldsymbol{v},t)\right)\right]
\end{align*}

\end_inset

For a general leaky integrate-and-fire model in diffusion approximation,
 the rate equation simplifies to 
\begin_inset Formula 
\[
r(t)=-\frac{1}{2}\sum_{n}\sigma^{2}(t)c_{n}(t)\left.\partial_{V}\phi_{n}(V,t)\right|_{V=\theta}.
\]

\end_inset

which can be written as 
\begin_inset Formula 
\[
r(t)=\boldsymbol{f}\boldsymbol{c}
\]

\end_inset

with 
\begin_inset Formula $f_{n}=-\frac{1}{2}\sigma^{2}(t)c_{n}(t)$
\end_inset

.
 
\end_layout

\begin_layout Subsubsection
Summary 
\end_layout

\begin_layout Standard
to use the method of spectral decomposition, we need to determine eigenvalues
 
\end_layout

\begin_layout Itemize
Eigenfunctions 
\begin_inset Formula $\phi_{n}(\boldsymbol{v},t)$
\end_inset

 and eigenvalues as a function of the input 
\begin_inset Formula $r(t)$
\end_inset


\end_layout

\begin_layout Itemize
Eigenfunctions of the adjoint operator 
\begin_inset Formula $\tilde{\phi}_{n}(\boldsymbol{v})$
\end_inset

 as a function of the input rate 
\begin_inset Formula $r(t)$
\end_inset


\end_layout

\begin_layout Standard
The hope is that a small subset of eigenfunctions is sufficient for an adequate
 description of the network dynamics.
 This dimensionality reduction could provide a computational efficient tool
 to simulate 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho operator"

\end_inset

 on the one hand, and provide more intuitive understanding about the network
 dynamics in terms eigenmodes on the other hand.
 It is therefore necessary to know how the eigenvalues and eigenfunctions
 change as a function of the input rate.
 Finding an analytic expression of the eigenvalues and eigenfunctions is
 difficult and has so far only been done for the perfect integrate-and-fire
 neuron with additional constant leak term 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2002"

\end_inset

 and the leaky integrate-and-fire neuron 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

.
 Both derivation where carried out in the diffusion approximation.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2002"

\end_inset

 presented a way to include changes in the input rate due to recurrent connectio
ns in a self-consistent manner.
 As a proof of principle, they showed in the subsequent work 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2004"

\end_inset

 that the theory is capable of predicting population dynamics of randomly
 recurrent connected EI-Network.
 
\end_layout

\begin_layout Standard
So fare it is not known if eigenfunctions can be found for regimes where
 the diffusion approximation does not apply.
 Furthermore, more complex models including synaptic dynamics or adaptation
 or spike generating currents has not been studied so far.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Biggio2017"

\end_inset

 developed a method to study a general integrate-and-fire model with exponential
 decaying synaptic currents.
 Their method reduces the inherently two dimension problem to a one dimensional.
 A sound mathematical motivation for the used dimensionality reduction is
 so far lacking.
 However, the theoretical predicted averaging firing rates show excellent
 agreement to simulation of PIF neurons.
 
\end_layout

\begin_layout Section*
Research question
\end_layout

\begin_layout Enumerate
Is it possible to to efficiently simulate large scale spiking neuronal networks
 on the population level by describing the network dynamics in terms of
 the eigenmodes associated with the neuron model.
 
\end_layout

\begin_layout Enumerate
Using the method of spectral decomposition, is it possible to go beyond
 the perturbative results which have been derived for pair-wise correlations,
 population firing rate, ISI statistics, bifurcation diagrams.
 
\end_layout

\begin_layout Enumerate
Is it possible to establish a mapping between spiking neuron models and
 rate based models by characterizing the input response of the spiking models
 using the method of spectral decomposition.
 
\end_layout

\begin_layout Section*
Research proposal
\end_layout

\begin_layout Standard
Understanding the behavior of large recurrent networks of spiking neurons
 is one of the major challenges in computational neuroscience.
 A first step in understanding the dynamical properties of such networks
 is to determine the location and stability of equilibria and how they depend
 on the connectivity profile and single neuron properties.
 In computational neuroscience, the most common method to simulate neural
 circuits is by means of direct simulation.
 This approach follows the dynamics of all neurons individually taking into
 account interactions modeled by connectivity blueprint and synaptic dynamics.
 Although, direct simulation yields full information about the network state
 on the single neuron level at all times, it also hast shortcomings: It
 becomes computationally very costly for large scale networks, and it contains
 a large number of degree of freedoms which makes it difficult to identify
 the relationships between model parameters and network properties.
 Hence, it is important to gain analytical insights into dynamical properties
 of neuronal networks which can inform model and parameter choices used
 in simulation.
 Integrate-and-fire neuron models are widely used for this purpose because
 they are simple enough to be studied analytically while still being able
 to capture important dynamical features observed on a single neuron level,
 or in a network context.
 However, even for fairly simple neuron models, one still is confronted
 with large set of coupled of differential equations.
 This makes it is necessary to apply homogeneity assumptions to reduce the
 dimensionalty of the problem.
 
\end_layout

\begin_layout Standard
Population density techniques have been applied to investigate the dynamics
 of large populations of interacting neurons.
 Most of the studies focus on single compartment integrate-and-fire neuron
 models, are simple enough to be studied analytically while still being
 able to capture important dynamical features observed on a single neuron
 level, or in a network context.
 The state of a integrate-and-fire neuron is described by a single set of
 biophysical variables usually including the membrane potential.
 The other variables can e.g.
 account for spike generating currents, synaptic dynamics, adaptive behavior
 of the neuron.
 Population density techniques employ the redundancy present in subpopulations
 of cortical networks to introduce a probabilistic description of the entire
 population.
 This means that the state of each population is described by a single density
 function instead of modeling the coupled dynamics of each neuron individually.
 The density functions gives information about the fraction of neurons located
 at a given dynamical state at a given point of time.
 Like other mean-field approaches, population density techniques drastically
 reduce the dimensionalty of the problem which makes them suitable for analytica
l treatment and computational less demanding in large scale simulations.
 However, even for simple neuronal models, the time evolution of the density
 is governed by a complicated partial differential equation (PDE).
 It can only be solved analytically for a view simple cases.
 For example, analytical expressions for the stationary distribution of
 the leaky integrate-and-fire neurons have been derived in the diffusion
 limit.
 Deviations from the stationary state, as well as models including synaptic
 dynamics have been studied perturbatively.
 Besides this analytical treatments, the PDE can also be solved numerically
 which allows for the study of more complicated models.
 However, using the numerical approach, it is more difficult and time consuming
 to get an insight into the relationship between system dynamics and the
 model parameter.
 To address this short come, it has been shown that the density can be decompose
d in terms eigenfunctions of the differential operator which defines the
 PDE.
 This decomposition reduces the PDE to a infinite system of ordinary differentia
l equations (ODEs).
 Depending on the question of interest, only a view modes can be sufficient
 to capture the dynamics of the system.
 Describing the system in terms of eigenfunctions offers a more intuitive
 description of non equilibrium dynamics of the system.
 Furthermore, the spectrum can be used to distinguish different dynamical
 regimes and to determine resonance frequencies of the network.
 So far, spectrum and eigenfunctions have only be derived for the perfect
 integrate-and-fire model in the diffusion limit.
 The eigenfunctions of the leaky integrate-and-fire are known, but the spectrum
 is still unknown.
 The goal of this project is to develop a general method to determine the
 spectra and eigenfunctions numerically for a given integrate-and-fire neuron
 model using the neuronal simulator Miind.
 As a next step, we would apply the method to different neuron models which
 e.g.
 include synaptic dynamics or adaptive behavior.
 Our hope is, that knowing the spectra and eigenfunctions of these models
 would enable us to get more insight into the dynamical properties of these
 models and how these properties differ.
 This includes relaxation dynamics due to change in the input, dynamical
 regimes like asynchronous irregular firing, global oscillations or bursting
 behavior, resonance frequencies and gain modulation.
 
\end_layout

\begin_layout Section
Preliminary Results 
\end_layout

\begin_layout Standard
Our objective is to develop a numerical algorithm to determine the eigenvalues
 and eigenfunctions of the dynamical operator introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

.
 For the perfect integrate-and-fire and the leaky integrate-and-fire neuron,
 eigenvalues and eigenfunctions can be determined analytically in the diffusion
 approximation.
 Hence, as a first step, we recover the results presented 
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002,Deniz2017"

\end_inset

 so that we can compare the performance of our algorithm against them.
 
\end_layout

\begin_layout Subsection
Perfect integrate-and-fire 
\end_layout

\begin_layout Standard
The perfect integrate-and-fire (PIF) also referred to as the simplest integrate-
and-fire model has been introduced in 
\begin_inset CommandInset citation
LatexCommand cite
key "Fusi1999"

\end_inset

 and is described by 
\begin_inset Formula 
\begin{equation}
\frac{dv}{dt}=-\alpha+I_{\text{s}}(t)
\end{equation}

\end_inset

It can be obtained from the leaky integrate-and-fire neuron by replacing
 the leak term by a constant.
 As discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Diffusion-approximation"

\end_inset

, in the diffusion approximation, the synaptic input is replaced by a Gaussian
 white noise 
\begin_inset Formula 
\begin{align}
\frac{dv}{dt} & =-\alpha+\mu(t)+\sqrt{\sigma(t)}\xi(t)=\eta(t)+\sqrt{\sigma(t)}\xi(t)\label{eq: PIF diffusion}
\end{align}

\end_inset

where defined 
\begin_inset Formula $\eta(t)=\mu(t)-\alpha$
\end_inset

.
 As discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Fokker-Planck-equation"

\end_inset

, Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PIF diffusion"

\end_inset

 can cast into a FPE 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(v,t)}{\partial t}=L\rho(v,t),\quad L=-\eta(t)\frac{\partial}{\partial v}+\frac{\sigma^{2}(t)}{2}\frac{\partial^{2}}{\partial v},
\end{equation}

\end_inset

The eigenfunctions of the FP operator 
\begin_inset Formula $L$
\end_inset

 are determined by Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: phi_n"

\end_inset

 which can be written as 
\begin_inset Formula 
\begin{equation}
-\eta\phi'_{n}(v)+\frac{\sigma^{2}}{2}\phi_{n}''(v)=\lambda_{n}\phi_{n}(v),\label{eq: PIF phi_n}
\end{equation}

\end_inset

where we suppressed the time argument for convenience.
 Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PIF phi_n"

\end_inset

 is a ODE with constant coefficients which can be solved using an exponential
 ansatz 
\begin_inset Formula $\phi_{n}(v)=e^{\alpha v}$
\end_inset

 .
 Without going into the details of the derivation, in the end one arrives
 at an expression for eigenfunctions and the eigenfunctions of the adjoint
 operator 
\begin_inset Formula 
\begin{align*}
\phi_{0}(v,t) & =\frac{c}{\eta}\left(1-e^{\frac{-2\xi(\theta-v)}{\theta}}\right),\\
\phi_{n}(v,t) & =c_{n}\sinh\left(\zeta_{n}\frac{\theta_{n}-v}{\theta}\right)e^{\frac{\xi v}{\theta}},\quad\text{for }n\neq0,\\
\tilde{\phi}{}_{n}(v,t) & =\left[\zeta_{n}\cosh\left(\frac{\zeta_{n}v}{\theta}\right)+\xi\sinh\left(\frac{\zeta_{n}v}{\theta}\right)\right]e^{-\frac{\xi}{\theta}v},
\end{align*}

\end_inset

where 
\begin_inset Formula $\xi$
\end_inset

 and 
\begin_inset Formula $\zeta_{n}$
\end_inset

 are 
\begin_inset Formula 
\[
\zeta_{n}=\frac{\theta}{\sigma^{2}}\sqrt{\eta^{2}+2\sigma^{2}\lambda_{n}},\quad\xi=\frac{\eta\theta}{\sigma^{2}}.
\]

\end_inset

 From the reset BC, a characteristic equation for the eigenvalues can be
 derived 
\begin_inset Formula 
\[
\zeta_{n}e^{\xi}=\zeta_{n}\cosh\left(\zeta_{n}\right)+\xi\sinh\left(\zeta_{n}\right).
\]

\end_inset

The roots of this equation determine the infinite countable set of eigenvalues
 
\begin_inset Formula $\{\lambda_{n}\}$
\end_inset

.
 Eigenfunctions 
\begin_inset Formula $\{\phi_{n},\tilde{\phi}_{n}\}$
\end_inset

 and eigenvalues 
\begin_inset Formula $\lambda_{n}$
\end_inset

 for different values of 
\begin_inset Formula $\mu,\sigma$
\end_inset

 are shown in Fig.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset

.
 Figure shows the simulation results of population of non-interacting PIF
 neurons which receive a constant external input.
 In the beginning of the simulation all neurons are placed at the reset
 potential, i.e.
 
\begin_inset Formula $\rho(V,0)=\delta(v_{\text{r}})$
\end_inset

.
 Hence, the initial value of the weighting coefficients 
\begin_inset Formula $c_{n}(0)=(\tilde{\phi}_{n},\delta(v_{\text{r}}))=\tilde{\phi}_{n}(v_{\text{r}})$
\end_inset

.
\end_layout

\begin_layout Subsubsection
Leaky integrate-and-fire 
\end_layout

\begin_layout Section
Outline 
\end_layout

\begin_layout Subsection
Short term objectives 
\end_layout

\begin_layout Subsection
Long term objectives 
\end_layout

\begin_layout Section
Appendix
\end_layout

\begin_layout Subsection
Current-based synapses 
\end_layout

\begin_layout Standard
Current-based synapses are state do not depend on the state of the neuron,
 i.e.
 contributions from individual synapses superimpose linearly so that 
\begin_inset Formula $I_{\text{s}}(t)$
\end_inset

 can be written as 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
I_{\text{s}}(t)=\tau_{\text{m}}\sum_{j=1}^{K}I_{j}(t),\label{eq: synaptic current}
\end{equation}

\end_inset

where 
\begin_inset Formula $I_{j}(t)$
\end_inset

 is the synaptic current associated with the 
\begin_inset Formula $j$
\end_inset

th synapse.
 Synaptic currents have due to a spike arrival have typically a fast raise
 time followed by slower the decay time Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: current-based synapse"

\end_inset

.
 The time scale of the decay time depends on the receptor type of the synapse.
 Common receptors are 
\end_layout

\begin_layout Enumerate
AMPA receptors which have decay time constants of the order of 
\begin_inset Formula $2$
\end_inset

ms 
\begin_inset CommandInset citation
LatexCommand cite
key "Angulo1999"

\end_inset


\end_layout

\begin_layout Enumerate
GABA
\begin_inset Formula $_{\text{A}}$
\end_inset

 receptors which have decay time constants typically 
\begin_inset Formula $5$
\end_inset

-
\begin_inset Formula $10$
\end_inset

ms 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiang1998"

\end_inset


\end_layout

\begin_layout Enumerate
NMDA which have time decay constants about 
\begin_inset Formula $100$
\end_inset

ms 
\begin_inset CommandInset citation
LatexCommand cite
key "Sah1990"

\end_inset


\end_layout

\begin_layout Standard
If the synaptic time constant is much smaller as the membrane time constant,
 then the simplest approximation is to assume that synaptic currents are
 instantaneous (delta-synapses)
\begin_inset Formula 
\begin{equation}
I_{j}(t)=\tau_{\text{m}}J_{j}\sum_{n}\delta(t-t_{n}^{(j)}),\label{eq: delta synapse}
\end{equation}

\end_inset

where 
\begin_inset Formula $J_{i}$
\end_inset

 is the synaptic efficacy of the respective synapse in mV.
 For delta-synapses, the membrane potential makes a jump by 
\begin_inset Formula $J_{i}$
\end_inset

 at each spike arrival followed by an exponential decay.
 If the raise time of the synapse is much faster compared to its decay time,
 then the synaptic current can be approximated as a jump exponential decay
 
\begin_inset Formula 
\begin{equation}
\tau_{\text{s}}\frac{d}{dt}I_{j}(t)=-I_{j}(t)+\tau_{\text{m}}J_{j}\sum_{n}\delta(t-t_{n}^{()}),\label{eq: exponential synapse}
\end{equation}

\end_inset

where 
\begin_inset Formula $\tau_{\text{s}}$
\end_inset

 synaptic time constant.
 At each spike arrival, 
\begin_inset Formula $I_{i}(t)$
\end_inset

 makes a jump by 
\begin_inset Formula $J_{i}$
\end_inset

 followed by an exponential decay back to zero which is illustrated by the
 blue curve in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: current-based synapse"

\end_inset

.
 A synaptic raise time can be included by modeling 
\begin_inset Formula $I_{i}(t)$
\end_inset

 by the set of equations 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud2002"

\end_inset


\begin_inset Formula 
\begin{align}
\tau_{\text{s}}\frac{dI_{\text{s}}}{dt} & =-I_{\text{s}}(t)+I_{\text{r}}(t)\nonumber \\
\tau_{\text{r}}\frac{dI_{\text{r}}}{dt} & =-I_{\text{r}}(t)+\tau_{\text{m}}J_{i}\sum_{n}\delta(t-t_{n}^{(i)}).\label{eq: synaptic current raise}
\end{align}

\end_inset

The synaptic value for different ratios 
\begin_inset Formula $\tau_{\text{r}}$
\end_inset

 is shown in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: current-based synapse"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/current_based_synapse.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Synaptic current (Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: synaptic current raise"

\end_inset

) caused by single spike arrival for 
\begin_inset Formula $\tau_{\text{s}}=2.0$
\end_inset

 ms and different values for 
\begin_inset Formula $\tau_{\text{r}}=[0,\,0.5,\,1.0,\,2.0]$
\end_inset

.
 Note that for 
\begin_inset Formula $\tau_{\text{r}}=0$
\end_inset

, we recover Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: exponential synapse"

\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig: current-based synapse"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "transfer_report"
options "plain"

\end_inset


\end_layout

\end_body
\end_document
