#LyX 2.2 created this file. For more info see http://www.lyx.org/
\lyxformat 508
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize 12
\spacing single
\use_hyperref false
\papersize default
\use_geometry true
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\index Index
\shortcut idx
\color #008000
\end_index
\leftmargin 1in
\topmargin 1in
\rightmargin 1in
\bottommargin 1in
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Transfer Report: Spectral analysis of the dynamics of neuronal networks
 using population-density techniques 
\end_layout

\begin_layout Author
Lukas Deutz
\end_layout

\begin_layout Section
Introduction 
\end_layout

\begin_layout Standard
Understanding the behavior of large recurrent networks of spiking neurons
 is one of the major challenges in computational neuroscience.
 A first step in understanding the dynamical properties of such networks
 is to determine the existence, location and stability of equilibria and
 how they depend on the connectivity profile and single neuron properties.
 A network may have different fixed points each associated with a different
 dynamical behavior, like asynchronous irregular spiking, global oscillatory
 or bursting activity all ubiquitously observed experimentally.
 To better understand how these different dynamical regimes emerge, and
 how the brain can transition between them 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
by e.g.
 changing the external drive to network or the interplay between excitation
 and inhibition within the network 
\end_layout

\end_inset

 is an important step towards understanding if and how these different states
 of activity can be used to explain different brain functions.
 
\end_layout

\begin_layout Standard
There are two complementary approaches to study the dynamics of neuronal
 networks which are referred to as computational and theoretical neuroscience.
 In computational neuroscience, the most commonly used method is to simulate
 neural circuits, referred to as direct simulations.
 This approach simulates individual neurons and all the interactions between
 them on a microscopic level.
 This has the advantage that observables of interest like spike times, firing
 rate statistics or correlation measures can be accessed on the level of
 single neurons.
 Before a neuronal network can be simulated, two questions need to be answered:
 
\end_layout

\begin_layout Enumerate
Which neuron model and synapse model should be used? 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Discuss what informs this decsion
\end_layout

\end_inset

 
\end_layout

\begin_layout Enumerate
What is the connectivity structure within the network? 
\end_layout

\begin_layout Standard
Choosing a neuron model is often a trade off between computational demand
 and biological realism or explanatory power.
 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
However, sometimes it is also advisable to choose a simpler model to narrow
 down the possible causes which could explain a certain observation of interest.
\end_layout

\end_inset

 To address the second question, it is common to think about the neuronal
 network in terms of different populations which represent neurons of a
 similar type, or with a similar function in a specific brain area of interest.
 The type of a neuron can be characterized by its morphology, its electrophysiol
ogical properties, or functional properties (e.g.
 receptivity to a specific stimulus feature).
 Neurons within a population are usually modeled by the same neuron model
 and considered to be statistical identical, i.e.
 they are equally likely to form connections with neurons in other populations.
 In this setting, one is usually not interested in the dynamical features
 of individual neurons, but instead in the dynamical features of the individual
 populations which can be characterized by e.g.
 the average population firing rate, interspike interval statistics (ISI),
 or the statistics of pairwise or higher order correlations.
 
\end_layout

\begin_layout Standard
The idea of approximating groups of neurons by homogeneous populations is
 often utilized in theoretical neuroscience as method to reduce the large
 number of degrees of freedom one is faced with in neuronal networks.
 From a mathematical viewpoint, describing how the network evolves in time
 boils down to solving a large system of coupled differential equation.
 Due to the non linearity of the neuron dynamics and their complex interactions,
 there is little hope of deriving an exact solution.
 Hence, approximation schemes are needed.
 A commonly used approach in theoretical neuroscience is mean-field theory
 which relies on the previously described homogeneity assumption.
 The main idea of mean-field theory is to decouple the system of differential
 equations which describes all neurons individually.
 This can be achieved by replacing the synaptic input to each neuron by
 the population-averaged input also referred to as the mean-field.
 If neurons belonging to the same population are assumed to be statistical
 identical, then they can all be described by the same the mean-field equation.
 Hence, mean-field theory reduces the high dimensional initial problem to
 a system of equations with size equal to number of populations in the network.
 Because neurons are recurrently connected, the synaptic input at a given
 time has an impact on the synaptic input at later time.
 Therefore, mean-field equations need to be solved self-consistently, such
 that the synaptic input a neuron receives on average produces an output
 which is consistent with the initial input.
 
\end_layout

\begin_layout Standard
The reminder of this report is structured as follows.
 First, we give an overview of the literature relating to population density
 methods, the diffusion approximation and the method of spectral decomposition
 and how these techniques are applied in a neuroscientific context.
 Then, we will formulate a preliminary research questions followed by a
 more detailed research proposal and present preliminary results towards
 answering these questions.
 Finally, we outline how to continue the project.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Finish sentence
\end_layout

\end_inset


\end_layout

\begin_layout Section
Literature Review 
\end_layout

\begin_layout Subsection
The population density method
\begin_inset CommandInset label
LatexCommand label
name "subsec:The-population-density"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Enumerate
Introduction
\end_layout

\begin_deeper
\begin_layout Itemize
Direct simulation vs population density
\end_layout

\begin_layout Itemize
Neuron models
\end_layout

\begin_layout Itemize
Integrate-and-fire
\end_layout

\begin_layout Itemize
Mean-field models
\end_layout

\end_deeper
\begin_layout Enumerate
Jump processes 
\end_layout

\begin_layout Enumerate
Diffusion approximation 
\end_layout

\begin_layout Enumerate
Fokker-Planck equation 
\end_layout

\begin_layout Enumerate
Spectral decomposition 
\end_layout

\begin_layout Enumerate
One dimensional integrate-and-fire
\end_layout

\begin_layout Enumerate
Perfect integrate-and-fire
\end_layout

\begin_layout Enumerate
Leaky integrate-and-fire
\end_layout

\begin_layout Enumerate
Exponential integrate-and-fire 
\end_layout

\begin_layout Enumerate
Numerical Algorithm 
\end_layout

\end_inset


\end_layout

\begin_layout Standard
Population density methods (PDMs) were introduced to neuroscience simultaneously
 by several authors 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag,Knight2000a,Nykamp"

\end_inset

 at the end of the last century.
 PDMs make use of the fact that the brain usually encodes information by
 group of neurons rather than by single neurons 
\begin_inset CommandInset citation
LatexCommand cite
key "Mountcastle1979"

\end_inset

.
 Optical imaging studies showed that visual cortex is tiled by patches of
 neurons each responding to different stimulus features.
 Each of the patches contains in order of 
\begin_inset Formula $\mathcal{O}(10^{4})$
\end_inset

 neurons 
\begin_inset CommandInset citation
LatexCommand cite
key "Blasdel1992a,Blasdel1992b"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citet
key "Omurtag"

\end_inset

 used this finding as an basis to model a network of interacting neurons
 using a statistical description on the level of populations.
 To arrive at such description, several simplifying assumptions need to
 be made.
 
\end_layout

\begin_layout Standard
The PDM presented in 
\begin_inset CommandInset citation
LatexCommand citet
key "Omurtag"

\end_inset

 can be applied in principle to any point neuron model.
 Point neurons approximate the entire neuron by single compartment, i.e.
 the dentritric tree is collapsed to a single point.
 Hence, it can not account for dynamical features related to the specific
 morphology of a neuron.
 The state of an arbitrary point neuron is determined by a set of variables
 
\begin_inset Formula $\boldsymbol{v}=(v_{1},v_{2},\ldots,v_{n})$
\end_inset

 usually including the membrane potential.
 The time evolution of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 is described by first order kinetics 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset


\begin_inset Formula 
\begin{equation}
\frac{d\boldsymbol{v}}{dt}=\boldsymbol{F}(\boldsymbol{v})+\boldsymbol{S}(\boldsymbol{v},\boldsymbol{s}(t)),\label{eq: neuron dynamics}
\end{equation}

\end_inset

where the vector field 
\begin_inset Formula $\boldsymbol{F}(\boldsymbol{v})$
\end_inset

 describes the time evolution of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 due to the intrinsic neuron dynamics and 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},\boldsymbol{s}(t))$
\end_inset

 models the incoming synaptic current invoked by synaptic arrivals 
\begin_inset Formula $\boldsymbol{s}(t)$
\end_inset

.
 A point neuron can be viewed as an input output-box.
 It receives excitatory and inhibitory inputs 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},s(t))$
\end_inset

 which arrive from other neurons by their associated synapses.
 These inputs are modeled either as injected currents or as a change in
 conductance.
 Current based synapses are simpler compared to conductance based models
 because they produce a current which is independent of the state of the
 neuron.
 Hence, multiple synaptic inputs can be summed linearly.
 Conductance based synapses provide a biological more realistic description
 
\begin_inset CommandInset citation
LatexCommand cite
key "Tuckwel1983"

\end_inset

 compared to Hodgkin-Huxley (H-H) type models 
\begin_inset CommandInset citation
LatexCommand cite
key "Hodgkin1952"

\end_inset

.
 They are state dependent because the synaptic current produced by a conductance
 change depends on the difference between the membrane potential and the
 reversal potential of the respective synapse which makes the summation
 of synaptic inputs nonlinear.
 If a neuron receives sufficiently strong excitatory input such that the
 membrane potential exceeds a certain threshold value, then the neuron will
 generate an action potential (spike), followed by a reset mechanism and
 a refractory period.
 The output spike is then fed back into the network and contributes to the
 input to other neurons.
 
\end_layout

\begin_layout Standard
To give an example, for a Hodgkin-Huxley (H-H) type model in standard notation
 
\begin_inset CommandInset citation
LatexCommand cite
key "Keener1998"

\end_inset

 with conductance based synapses Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

 becomes 
\begin_inset Formula 
\begin{align}
\frac{dV}{dt} & =\frac{1}{C}\left(g_{L}(V_{L}+V)+g_{n}m^{3}h(V_{N}-V)+g_{K}n^{4}(V_{K}-V)\right)+\frac{1}{C}\sum_{i=1}^{N}g_{i}(t)(V_{i}^{(s)}-V)\nonumber \\
\frac{dm}{dt} & =\frac{1}{\tau_{m}(V)}(m_{\infty}(V)-m),\nonumber \\
\frac{dh}{dt} & =\frac{1}{\tau_{h}(V)}(h_{\infty}(V)-h),\nonumber \\
\frac{dn}{dt} & =\frac{1}{\tau_{n}(V)}(n_{\infty}(V)-n).\label{eq: H-H}
\end{align}

\end_inset

The state of the neuron is determined by the set of variables 
\begin_inset Formula $\boldsymbol{v}=(V,m,h,n)$
\end_inset

, where 
\begin_inset Formula $V$
\end_inset

 is the membrane potential, 
\begin_inset Formula $m$
\end_inset

 governs the sodium activation, 
\begin_inset Formula $h$
\end_inset

 sodium inactivation, and 
\begin_inset Formula $n$
\end_inset

 the potassium activation.
 Hence, 
\begin_inset Formula $\boldsymbol{F}(\boldsymbol{v})$
\end_inset

 is four dimensional vector with 
\begin_inset Formula 
\begin{equation}
F_{1}(\boldsymbol{v})=\frac{1}{C}\left(g_{L}(V_{L}+V)+g_{n}m^{3}h(V_{N}-V)+g_{K}n^{4}(V_{K}-V)\right),
\end{equation}

\end_inset

and 
\begin_inset Formula $F_{2},F_{3}$
\end_inset

 and 
\begin_inset Formula $F_{4}$
\end_inset

 given by the last three equations in 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

.
 Note that the synaptic current 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},\boldsymbol{s}(t))$
\end_inset

 only causes changes in the membrane potential.
 Hence, the only entry in 
\begin_inset Formula $\boldsymbol{S}(\boldsymbol{v},s(t))$
\end_inset

 which is nonzero is the first one 
\begin_inset Formula $S_{1}$
\end_inset

 which we define as 
\begin_inset Formula 
\begin{equation}
I(V,s(t))=\frac{1}{C}\sum_{j=1}^{K}g_{j}^{(s)}(t)(V_{j}^{(s)}-V),\label{eq: S conductance}
\end{equation}

\end_inset

where 
\begin_inset Formula $K$
\end_inset

 is the total number afferent connections which is depicted in Fig and 
\begin_inset Formula $V_{j}^{(s)}$
\end_inset

 is the reversal potential associated with synapse 
\begin_inset Formula $j$
\end_inset

.
 For the leaky integrate-and-fire neuron model 
\begin_inset CommandInset citation
LatexCommand citep
key "Lapicque1907,Stein1967"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

 simplifies to 
\begin_inset Formula 
\begin{equation}
\frac{dV}{dt}=-\frac{g_{L}}{C}(V-V_{L})+\frac{1}{C}\sum_{j=1}^{N}g_{j}(t)(V_{j}^{(s)}-V),
\end{equation}

\end_inset

Note that we considered only a single synapse type in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: S conductance"

\end_inset

 for simplicity.
 The synaptic conductance 
\begin_inset Formula $g_{i}^{(s)}(t)$
\end_inset

 is zero in absence of synaptic arrivals and becomes only nonzero for small
 time window after a spike has arrived.
 We represent all spike arrivals at the 
\begin_inset Formula $j$
\end_inset

th synapse by a sum of delta distributions
\begin_inset Formula 
\begin{equation}
s_{j}(t)=\sum_{n}\delta(t-t_{n}^{(j)}),\label{eq: s_i(t)}
\end{equation}

\end_inset

where 
\begin_inset Formula $t_{n}^{(j)}$
\end_inset

 is the time of the 
\begin_inset Formula $n$
\end_inset

th spike arrival.
 Assuming that synaptic time scales are short compared to the membrane time
 constant, 
\begin_inset CommandInset citation
LatexCommand cite
key "Omurtag"

\end_inset

 approximate the conductance changes caused by arriving spike to be instantaneou
s 
\begin_inset Formula 
\begin{equation}
g_{j}(t)=\hat{g}_{j}\sum_{n}\delta(t-t_{n}^{(j)}).\label{eq: g_i(t)}
\end{equation}

\end_inset

This approximation is referred to as delta synapses.
 The parameter 
\begin_inset Formula $\hat{g}_{j}$
\end_inset

 represent the integrated countenance over time course of the synaptic event.
 If conductance changes are instantaneous, then the membrane potential makes
 a jump of 
\begin_inset Formula $\hat{g}_{j}(V_{s}-V(t))/C$
\end_inset

 whenever a spike arrives.
 
\end_layout

\begin_layout Standard
If we would subsitute Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: s_i(t)"

\end_inset

 into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: neuron dynamics"

\end_inset

 and integrate the r.h.s., then we obtain the deterministic time evolution
 of 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 for a given synaptic input 
\begin_inset Formula $\boldsymbol{s}(t)=\{s_{1}(t),s_{2}(t),\ldots,s_{N}(t)\}$
\end_inset

.
 However, 
\begin_inset Formula $\boldsymbol{s}(t)$
\end_inset

 is unknown unless we simulate all neurons in the network individually.
 
\end_layout

\begin_layout Standard
Since, we are dealing with a biological system which is subject to noise
 our goal is to approximate 
\begin_inset Formula $s_{j}(t)$
\end_inset

 by stochastic process.
 The membrane potential of a neuron is subject to two sources of noise:
 one intrinsic to the neuron, associated with stochastic nature of the mechanism
 controlling the release of neurotransmitter, the opening of ion channels
 and so forth.
 The other is extrinsic, arising from the apparently random arrival of individua
l spikes 
\begin_inset CommandInset citation
LatexCommand citet
key "Burkitt2006"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Mainen1995"

\end_inset

 showed in vitro, that neurons in rat cortex are able to reliably respond
 to an identical fluctuating input current injected directly into the cell
 body.
 Over several trials, neurons emitted spikes at roughly identical points
 in time with small deviations compared to the average length of interspike
 intervals.
 This suggests that intrinsic noise is insignificant compared to extrinsic
 noise associated with the stochastic synaptic input.
 
\end_layout

\begin_layout Standard
Consequently, the dominant source of randomness is assumed to be the stochastic
 arrival of spikes.
 These are usually approximated by a renewal process, i.e.
 interspike intervals (ISI) are identical and independently distributed
 
\begin_inset CommandInset citation
LatexCommand cite
key "Burkitt2006,Burkitt2006a"

\end_inset

.
 We introduce the instantaneous firing rate 
\begin_inset Formula $r_{j}(t)$
\end_inset

 which can be used to calculate the number of spikes 
\begin_inset Formula $N_{j}(t,t+\delta t)$
\end_inset

 in a small time interval 
\begin_inset Formula $[t,t+\delta t]$
\end_inset

 in the limit 
\begin_inset Formula $\delta t\rightarrow0$
\end_inset


\begin_inset Formula 
\begin{equation}
\lim_{\delta t\rightarrow0}N_{j}(t,t+\delta t)=\lim_{\delta t\rightarrow0}r_{j}(t)\delta t.
\end{equation}

\end_inset

Note that the spike trains which arrive at different synapses of a neuron
 are in general not independent 
\begin_inset CommandInset citation
LatexCommand citep
key "Poulet2008"

\end_inset

.
 Indeed, input correlations are an inevitable consequence of two neurons
 being part of the same network, and therefore likely to share some common
 synaptic input 
\begin_inset CommandInset citation
LatexCommand citep
key "Ostojic"

\end_inset

.
 However, if the network is sparsely connected, i.e.
 the number of indegrees is small compared to the network size, then the
 number of common inputs can assumed to be small.
 Furthermore, it has been shown that in recurrently connected networks inhibitio
n decorrelates neural activity 
\begin_inset CommandInset citation
LatexCommand citep
key "Tetzlaff2012,Renart2010"

\end_inset

.
 Excitation and inhibition tends to balance each other such that the membrane
 potential of individual neurons saturates below threshold.
 Threshold crossings in the balanced state are caused by random fluctuations
 in the input (noise driven regime) which lead to asynchronous irregular
 firing (AI), also referred to as spontaneous activity 
\begin_inset CommandInset citation
LatexCommand citet
key "Amit1997"

\end_inset

.
 In such a setting, assuming the input at different synapses to be independent
 can be regarded as a zeroth order approximation.
 If input correlations are assumed to be small, then network dynamics can
 be studied perturbatively 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindner2001"

\end_inset

.
 For the remainder of this report, we assume synaptic inputs to be independent.
 
\end_layout

\begin_layout Standard
For an arbitrary neuron 
\begin_inset Formula $i$
\end_inset

, the synaptic input is given by Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: S conductance"

\end_inset

 
\begin_inset Formula 
\begin{equation}
I_{i}(V,s(t))=\frac{1}{C}\sum_{j=1}^{K_{i}}g_{ij}^{(s)}(t)(V_{i}^{(s)}-V),
\end{equation}

\end_inset

where 
\begin_inset Formula $g_{ij}^{(s)}(t)$
\end_inset

 describes the time evolution of the conductance associated with the synapse
 which connects neuron 
\begin_inset Formula $j$
\end_inset

 to 
\begin_inset Formula $i$
\end_inset

 
\begin_inset Formula 
\begin{equation}
g_{ij}(t)=\hat{g}_{ij}\sum_{n}\delta(t-t_{n}^{(j)}).\label{eq: g_ij(t)}
\end{equation}

\end_inset

To arrive at a description on the population level, 
\begin_inset CommandInset citation
LatexCommand cite
key "Omurtag"

\end_inset

 make a mean-field ansatz, i.e.
 they replace all single neuron quantities by their population averages
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\hat{g}_{ij} & \rightarrow\hat{g}=\bigl\langle\hat{g}_{ij}\bigr\rangle,\nonumber \\
V_{ij}^{(s)} & \rightarrow V_{s}=\bigl\langle V_{ij}^{(s)}\bigr\rangle\nonumber \\
K_{i} & \rightarrow K=\bigl\langle K_{i}\bigr\rangle,\nonumber \\
r_{i}(t) & \rightarrow r(t)=\bigl\langle r_{i}\bigr\rangle.
\end{align}

\end_inset

This simplifies Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: g_ij(t)"

\end_inset

 to
\begin_inset Formula 
\begin{equation}
g_{i}(t)=\hat{g}\sum_{n=1}^{K}s_{i}(t).
\end{equation}

\end_inset

The sum is a superposition of independent renewal processes all having the
 same firing rate 
\begin_inset Formula $r(t)$
\end_inset

.
 It can be well approximated by a Poisson process with firing rate 
\begin_inset Formula $Kr(t)$
\end_inset

 due to the pooling property of independent renewal processes 
\begin_inset CommandInset citation
LatexCommand citep
key "Gallager2011"

\end_inset

.
 Hence, on average each neuron feels the instantaneous firing rate 
\begin_inset Formula 
\begin{equation}
\sigma(t)=\sigma_{0}(t)+Kr(t),\label{eq: input rate}
\end{equation}

\end_inset

where 
\begin_inset Formula $\sigma_{0}(t)$
\end_inset

 is the average firing rate associated with connections from the external
 surrounding of the network.
 The mean-field ansatz is motivated by the fact that 
\begin_inset CommandInset citation
LatexCommand cite
key "Omurtag"

\end_inset

 are only interested in predicting the average behavior of the entire population.
 In the limit of large networks, the population dynamics are expected to
 be only mildly affected by the neglected heterogeneity in the connectivity.
 Indeed, 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997a"

\end_inset

 simulated a network with variable numbers of indegrees and stochastic synapses
 and showed that the PDM still reliably predicts the stationary firing rates
 for the individual populations in the network.
 
\end_layout

\begin_layout Standard
Having derived Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

, 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 introduce the probability density function 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 which how many neurons in the population are expected to be found in the
 state space volume 
\begin_inset Formula $[\boldsymbol{v},\boldsymbol{v}+d\boldsymbol{v}]$
\end_inset

 at given point in time.
 How 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 changes over time in a small state space volume 
\begin_inset Formula $D$
\end_inset

 is determined by the equation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\partial}{\partial t}\int_{D}\rho\,d\boldsymbol{v}=-\int_{\partial D}\rho\,\boldsymbol{F}(\boldsymbol{v})\cdot\boldsymbol{n}-\int_{D}d\boldsymbol{v}\left(\frac{\delta\rho}{\partial t}\right)^{-}+\int_{D}d\boldsymbol{v}\left(\frac{\delta\rho}{\partial t}\right)^{+}\label{eq: integral density}
\end{equation}

\end_inset

The first term on the r.h.s.
 represents the probability flow out of the surface area of 
\begin_inset Formula $D$
\end_inset

 due to the intrinsic neuron dynamics.
 The next two terms represent changes in 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 due to synaptic arrivals.
 If 
\begin_inset Formula $D$
\end_inset

 is taken small enough that any neuron receiving a spike leaves 
\begin_inset Formula $D$
\end_inset

, then 
\begin_inset Formula 
\begin{equation}
\left(\frac{\delta\rho}{\partial t}\right)^{-}=\sigma(t)\rho(\boldsymbol{v},t).\label{eq: jump out}
\end{equation}

\end_inset

To determine the fraction of neurons which enter the volume 
\begin_inset Formula $D$
\end_inset

, we need to identify those regions in the state space 
\begin_inset Formula $D'(D)$
\end_inset

 which end up in 
\begin_inset Formula $D$
\end_inset

 after a synaptic arrival.
 Because synaptic arrivals only affect the membrane potential, we need to
 solve
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
V & =V''+h(V'-V_{s})\Leftrightarrow V'(V)=\frac{V+hV_{s}}{1+h}
\end{align}

\end_inset

where 
\begin_inset Formula $h=\hat{g}/C$
\end_inset

 is called synaptic efficacy.
 
\begin_inset Formula 
\begin{align}
\int_{D}d\boldsymbol{v}\left(\frac{\delta\rho}{\partial t}\right)^{+} & =\sigma(t)\int_{D'}d\boldsymbol{v}'\rho(\boldsymbol{v}')\nonumber \\
 & =\sigma(t)\int_{D}d\boldsymbol{v}\rho(\boldsymbol{v}'(\boldsymbol{v}))\frac{\partial\boldsymbol{v}'}{\partial\boldsymbol{v}}d\boldsymbol{v}\label{eq: jump in}
\end{align}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: jump out"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: jump in"

\end_inset

 into 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integral density"

\end_inset

, using the theorem of Gauss one arrives at 
\begin_inset Formula 
\begin{equation}
\frac{\partial}{\partial t}\int_{D}\rho\,d\boldsymbol{v}=\int d\boldsymbol{v}\left\{ \frac{\partial}{\partial\boldsymbol{v}}(\rho\,\boldsymbol{F}(\boldsymbol{v}))-\sigma(t)\left(\rho(\boldsymbol{v},t)-\rho(\boldsymbol{v}'(\boldsymbol{v}))\frac{\partial\boldsymbol{v}'}{\partial\boldsymbol{v}}\right)\right\} 
\end{equation}

\end_inset

Because 
\begin_inset Formula $D$
\end_inset

 is small but otherwise arbitrary, we arrive at the partial differential
 equation (PDE)
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho}{\partial t}=-\frac{\partial}{\partial\boldsymbol{v}}\left(F(\boldsymbol{v})\rho\right)-\sigma(t)\times\left\{ \rho(\boldsymbol{v},t)-\rho(\boldsymbol{v}'(\boldsymbol{v}),t)\frac{\partial\boldsymbol{v}'}{\partial\boldsymbol{v}}\right\} .\label{eq: PDE}
\end{equation}

\end_inset

The above equation can be written as a continuity equation
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=-\frac{\partial}{\partial\boldsymbol{v}}\boldsymbol{J}(\boldsymbol{v},t),\label{eq: continuity equation}
\end{equation}

\end_inset

where 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 is probability current which determines the flow of probability at point
 
\begin_inset Formula $\boldsymbol{v}$
\end_inset

 at a given time 
\begin_inset Formula $t$
\end_inset

.
 The probability flux has two contributions,
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}=\boldsymbol{J}_{F}+\boldsymbol{J}_{\text{s}},\label{eq: J}
\end{equation}

\end_inset

one corresponds to the intrinsic neuron dynamics
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}_{F}=\boldsymbol{F}(\boldsymbol{v})\rho(\boldsymbol{v},t),\label{eq: J_str}
\end{equation}

\end_inset

and the other corresponds the synaptic input, and therefore depends on the
 input rate 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\boldsymbol{J}_{\text{s}}=-\sigma(t)\int_{V}^{V'(V)}\boldsymbol{e}_{V}\rho(W,v_{2},\ldots)dW.\label{eq: J_imp}
\end{equation}

\end_inset

To determine the firing rate 
\begin_inset Formula $r(t)$
\end_inset

 of the population, one needs to define a threshold value 
\begin_inset Formula $V=V_{\theta}$
\end_inset

 for the the membrane potential and construct a Poincare surface at this
 value.
 The firing rate 
\begin_inset Formula $r(t)$
\end_inset

 is given by the probability flux which goes through this surface at time
 
\begin_inset Formula $t$
\end_inset

.
 Hence, the we can express 
\begin_inset Formula $r(t)$
\end_inset

 as a functional of 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

: 
\begin_inset Formula 
\begin{equation}
r(t)=R[\boldsymbol{J}(\boldsymbol{v},t)]\label{eq: r}
\end{equation}

\end_inset

To ensure conservation of probability, the probability which passes the
 threshold needs to be reinserted at the reset potential 
\begin_inset Formula $V_{r}$
\end_inset

.
 This can be modeled by a introducing an absorbing boundary at the threshold.
 The crucial point is that 
\begin_inset Formula $\boldsymbol{J}(\boldsymbol{v},t)$
\end_inset

 depends on 
\begin_inset Formula $\sigma(t)$
\end_inset

, and therefore on 
\begin_inset Formula $r(t)$
\end_inset

 due to Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: input rate"

\end_inset

.
 Replacing 
\begin_inset Formula $r(t)$
\end_inset

 by 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: r"

\end_inset

 and expressing 
\begin_inset Formula $\boldsymbol{J}$
\end_inset

 in terms of 
\begin_inset Formula $\rho(\boldsymbol{v},t$
\end_inset

) makes Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 a nonlinear integro partial differential equation.
 It can be solved numerically e.g.
 by using the method of characteristics 
\begin_inset CommandInset citation
LatexCommand citep
key "DeKamps2003,DeKamps2013"

\end_inset

, or analyzed analytically for particular simple neuron models.
 As a proof of principle, 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 compared numerical results from the theory against direct simulations of
 a population of uncoupled (no recurrent connections) LIF neurons demonstrating
 excellent agreement for a large enough population 
\begin_inset Formula $\mathcal{O}(>10^{4})$
\end_inset

.
 
\end_layout

\begin_layout Standard
The importance of the work by 
\begin_inset CommandInset citation
LatexCommand citep
key "Omurtag"

\end_inset

 comes from the fact that their method can be in principle applied to any
 type of point neuron model.
 The macroscopic Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 for the dynamics on the population level can be derived from the microscopic
 details of the neuron model without introducing any additional parameter.
 It can be generalized to networks with multiple populations each described
 by a single density function.
 Different synaptic delays can be included into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: r"

\end_inset

 to mimic a spatial arrangement of the populations within the network.
 A large drawback of the PDM is that it can not model synaptic plasticity,
 because all heterogeneity in the connectivity needs to be averaged out
 to arrive at a low dimensional description on the level of populations.
 
\end_layout

\begin_layout Standard
In theoretical neuroscience, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PDE"

\end_inset

 has been studied subsequently for more and more complex integrate-and-fire
 neurons 
\begin_inset CommandInset citation
LatexCommand cite
key "Amit1997,Brunel2000,Fourcaud2002,Fourcaud-Trocme2003,Brunel2003"

\end_inset

.
 All these studies are based on the diffusion approximation which we will
 introduce in the next section 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Diffusion-approximation"

\end_inset

.
 
\end_layout

\begin_layout Subsection
Diffusion approximation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Diffusion-approximation"

\end_inset


\end_layout

\begin_layout Standard
The diffusion approximation replaces the Poisson process represented by
 the second term in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PDE"

\end_inset

 by a diffusion advection process.
 The diffusion and drift coefficients can be derived by describing the time
 evolution of the probability density by the Chapman-Kolmogorov equation
 and expanding it in a Kramer-Moyals expansion 
\begin_inset CommandInset citation
LatexCommand citep
key "Riksen1992"

\end_inset

.
 For a Poisson process, the Kramers-Moyal expansion has infinitely many
 terms.
 Truncating it after the second order yields the diffusion approximation.
 We will illustrate how the diffusion approximation comes about for a general
 integrate-and-fire neuron model.
\end_layout

\begin_layout Standard
The state of an integrate-and-fire neuron is only described by the membrane
 potential 
\begin_inset Formula $V$
\end_inset

 which drastically simplifies the analysis if e.g.
 compared to the four dimensional H-H type model introduced in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: H-H"

\end_inset

.
 Despite their simplicity, they are still able to capture important dynamical
 features observed on a single neuron level, or in a network context.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Bernander1991"

\end_inset

.
 One of most commonly used point neuron models is leaky integrate-and-fire
 neuron 
\begin_inset CommandInset citation
LatexCommand citep
key "Lapicque1907,Stein1967"

\end_inset

 (LIF).
 It describes the subthreshold dynamics of the membrane potential which
 can be modeled by a RC circuit
\begin_inset Formula 
\begin{equation}
C\frac{dV}{dt}=-g_{L}(V-V_{L})+I_{\text{s}}(t),\label{eq: LIF}
\end{equation}

\end_inset

where 
\begin_inset Formula $I_{s}(t)$
\end_inset

 is the synaptic input current.
 The LIF neuron is not capable of modeling the generation of an action potential
 which needs to be included by introducing an artificial threshold 
\begin_inset Formula $V_{\text{th}}$
\end_inset

.
 If the membrane potential of the neuron exceeds 
\begin_inset Formula $V_{\text{th}}$
\end_inset

, a spike is emitted and the membrane potential is reset to a reset value
 
\begin_inset Formula $V_{\text{r}}$
\end_inset

.
 Other examples of integrate-and-fire models are the quadratic integrate-and-fir
e 
\begin_inset CommandInset citation
LatexCommand citep
key "Ermentrout1996"

\end_inset

 (QIF) 
\begin_inset Formula 
\begin{equation}
C\frac{dV}{dt}=\frac{g_{L}}{2\Delta_{\text{th}}}(V-V_{L})(V-V_{\text{th}})+I_{\text{s}}(t),\label{eq: QIF}
\end{equation}

\end_inset

and exponential integrate-and-fire neuron model 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 (EIF)
\begin_inset Formula 
\begin{equation}
C\frac{dV}{dt}=-g_{L}(V-V_{L})+g_{L}\Delta_{\text{th}}\exp\left(\frac{V-V_{\text{th}}}{\Delta_{\text{th}}}\right)+I_{\text{s}}(t),\label{eq: EIF}
\end{equation}

\end_inset

The QIF and the EIF model both contain nonlinear dynamics to mimic the superthre
shold transients of the membrane potential due to spike initiation.
 In case of the QIF neuron, they are quadratic, and in case of the EIF,
 they are exponential.
 The parameter 
\begin_inset Formula $\Delta_{\text{th}}$
\end_inset

 is inversely proportional to the curvature of the 
\begin_inset Formula $I$
\end_inset

-
\begin_inset Formula $V$
\end_inset

 curve at threshold, i.e.
 it measures the sharpness of spike initiation.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Fourcaud-Trocme2003"

\end_inset

 compared the response of the LIF, QIF and EIF neuron to noisy input with
 the response of more realistic H-H type models and showed that the nonlinear
 dynamics must be included to achieve a good agreement.
 We can write Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: LIF"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: QIF"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: EIF"

\end_inset

 as 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=f(V)+I_{\text{s}}(t),\label{eq: integrate-and-fire}
\end{equation}

\end_inset

where 
\begin_inset Formula $\tau_{\text{m}}=C/g_{L}$
\end_inset

 is the membrane time constant and 
\begin_inset Formula $g_{L}$
\end_inset

 has been absorbed into synaptic current which is now in the units of voltage.
 The membrane time constant is typically in the order of 
\begin_inset Formula $10$
\end_inset

-
\begin_inset Formula $20$
\end_inset

ms.
 For simplicity, we assume that the network consists of a single population
 and that neurons are connected via current based synapses.
 Hence, for an arbitrary neuron 
\begin_inset Formula $i$
\end_inset

, the total incoming synaptic current is given by 
\begin_inset Formula 
\begin{equation}
I_{\text{s},i}(t)=\tau_{\text{m}}\sum_{j=1}^{K_{i}}I_{ij}(t),
\end{equation}

\end_inset

where we used that different synaptic currents superimpose linearly for
 current based synapses.
 We assume again that the time scale of the synapses is much smaller compared
 to the membrane time constant and approximate the synaptic current to be
 instantaneous (delta-synapses) 
\begin_inset Formula 
\begin{equation}
I_{ij}(t)=J_{ij}\sum_{n=1}^{K_{i}}\delta(t-t_{n}^{(ij)}).\label{eq: delta synapse-1}
\end{equation}

\end_inset

Hence, whenever a spike arrives a synapse, the membrane potential makes
 a jump by 
\begin_inset Formula $J_{ij}$
\end_inset

 followed by an exponential decay.
 Using the mean-field ansatz introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:The-population-density"

\end_inset

, we replace all quantities in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: delta synapse-1"

\end_inset

 by their population averages 
\begin_inset Formula 
\begin{equation}
I_{\text{s}}(t)=\tau_{\text{m}}J\sum_{n}^{K}\delta(t-t_{n}^{(i)}),\label{eq: synaptic current-1}
\end{equation}

\end_inset

where 
\begin_inset Formula $K=\bigl\langle K_{i}\bigr\rangle$
\end_inset

 and 
\begin_inset Formula $J=\bigl\langle J_{ij}\bigr\rangle$
\end_inset

.
 The spike times are Poisson distributed with rate 
\begin_inset Formula $\sigma(t)=Kr(t)+r_{\text{ext}}$
\end_inset

.
 The number of indegrees a cortical neuron receives are typically in the
 order of 
\begin_inset Formula $K\sim\mathcal{O}(10^{3}$
\end_inset

-
\begin_inset Formula $10^{4})$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Braitenberg2013"

\end_inset

 and firing rates are in the order of 
\begin_inset Formula $r(t)\sim\mathcal{O}(1$
\end_inset

-
\begin_inset Formula $10^{2})$
\end_inset

Hz 
\begin_inset CommandInset citation
LatexCommand cite
key "Zador1998"

\end_inset

.
 Hence, neurons receive a large number of inputs in a time interval equal
 to the size of the membrane time constant.
 If individual inputs cause only a small changes in the membrane potential,
 i.e.
 
\begin_inset Formula $J$
\end_inset

 is small compared to the distance from the reset value 
\begin_inset Formula $V_{\text{r}}$
\end_inset

 to threshold 
\begin_inset Formula $V_{\text{th}}$
\end_inset

, then 
\begin_inset Formula $I_{\text{s}}(t)$
\end_inset

 can be approximated by Gaussian white noise 
\begin_inset CommandInset citation
LatexCommand cite
key "Amit1997"

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
I_{\text{s}}(t)\approx\mu(t)+\sqrt{\tau_{\text{m}}}\sigma(t)\xi(t),\label{eq: synaptic current diffusion}
\end{equation}

\end_inset

where 
\begin_inset Formula $\xi(t)$
\end_inset

 is Gaussian white noise with zero mean and unit variance 
\begin_inset Formula 
\begin{equation}
\left\langle \xi(t)\right\rangle =0,\quad\left\langle \xi(t)\xi(t')\right\rangle =\delta(t-t')
\end{equation}

\end_inset

The mean 
\begin_inset Formula $\mu(t)$
\end_inset

 and variance 
\begin_inset Formula $\sigma^{2}(t)$
\end_inset

 of the noise depend on the firing rate, and model parameters
\begin_inset Formula 
\begin{align}
\mu(t) & =\tau_{\text{m}}KJr(t)+\mu_{\text{ext}},\label{eq: mu}\\
\sigma^{2}(t) & =\tau_{\text{m}}KJ^{2}r(t)+\sigma_{\text{ext}}^{2}.\label{eq: sig}
\end{align}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: synaptic current diffusion"

\end_inset

 into Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integrate-and-fire"

\end_inset

 yields the Langevin equation 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=f(V)+\mu+\sqrt{\tau_{m}}\sigma^{2}\xi(t)\label{eq: integrate-and-fire diffusion approx}
\end{equation}

\end_inset

For the LIF neuron Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 describes a Ornstein-Uhlenbeck process 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=-(V-\mu)+\sqrt{\tau_{m}}\sigma^{2}\xi(t).
\end{equation}

\end_inset

Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: diffusion approximation"

\end_inset

 illustrates that the diffusion approximation is only valid for high input
 rates.
 The Langevin equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 can be equivalently by described by a Fokker-Planck equation 
\begin_inset CommandInset citation
LatexCommand cite
key "Riksen1992"

\end_inset

 which determines the time evolution of the probability density function
 
\begin_inset Formula $\rho(V,t)$
\end_inset

 in the diffusion approximation.
 By equivalently we mean that 
\begin_inset Formula $\rho(V,t)$
\end_inset

 yields the same moments 
\begin_inset Formula $\bigl\langle V^{m}\bigr\rangle$
\end_inset

 as we would obtain directly from the Langevin equation 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align left
\begin_inset Graphics
	filename figures/diffusion_approximation.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
The black curves show how the membrane potential of the LIF neuron changes
 due to synaptic arrivals.
 The incoming spike trains (blue dots) are modeled as a homogeneous Poisson
 process.
 For high enough firing rates (bottom panel), the trace of membrane potential
 resembles a Ornstein-Uhlenbeck process, randomly fluctuating around the
 mean value 
\begin_inset Formula $\mu$
\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig: diffusion approximation"

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Fokker-Planck equation
\begin_inset CommandInset label
LatexCommand label
name "subsec:Fokker-Planck-equation"

\end_inset


\end_layout

\begin_layout Standard
The Fokker-Planck equation (FPE) which corresponds to Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 reads
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{\partial\rho(V,t)}{\partial t}=-\frac{\partial}{\partial V}[f(V)+\mu(t)]\rho(V,t)+\frac{\sigma^{2}}{2}\frac{\partial^{2}}{\partial V}\rho(V,t),\label{eq: FPE}
\end{equation}

\end_inset

The FPE is a linear 2nd order partial differential equation which describes
 an advection diffusion process with time dependent drift 
\begin_inset Formula $D_{1}(V,t)$
\end_inset

 and diffusion coefficient 
\begin_inset Formula $D_{2}(v,t)$
\end_inset

 
\begin_inset Formula 
\begin{align}
D_{1}(V,t) & =-\frac{1}{\tau_{\text{m}}}[f(V)+\mu(t)],\quad D_{2}(t)=\frac{\sigma(t)^{2}}{2\tau_{\text{m}}}.
\end{align}

\end_inset

Note the that 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE"

\end_inset

 is equivalent to 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PDE"

\end_inset

, expect the second term is replaced by a diffusion process.
 The FPE can be written as 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(V,t)}{\partial t}=L\rho(V,t),\label{eq: FPE-1}
\end{equation}

\end_inset

where 
\begin_inset Formula $L$
\end_inset

 is called Fokker-Planck operator which is given by 
\begin_inset Formula 
\begin{align}
L(t) & =\frac{\partial}{\partial V}D_{1}(V,t)+D_{2}(t)\frac{\partial^{2}}{\partial V^{2}}\label{eq: FP operator}
\end{align}

\end_inset

The benefit of formulating the time evolution in terms of the FPE is that
 it allows us to incorporate the reset mechanism at the threshold value
 by appropriate boundary conditions.
 
\end_layout

\begin_layout Subsubsection
Boundary conditions
\begin_inset CommandInset label
LatexCommand label
name "subsec:Boundary-conditions"

\end_inset


\end_layout

\begin_layout Standard
A strength of formulating the problem in terms of a FPE is that the threshold
 and reset mechanism can be incorporated into the boundary conditions.
 To show this we rewrite 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE"

\end_inset

 as a continuity equation 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(V,t)}{\partial t}=-\frac{\partial}{\partial V}J(V,t),\label{eq: FPE continuity}
\end{equation}

\end_inset

where 
\begin_inset Formula 
\begin{equation}
J(V,t)=\frac{\mu+f(V)}{\tau_{\text{m}}}\rho(V,t)-\frac{\sigma^{2}}{2\tau_{\text{m}}}\frac{\partial}{\partial V}\rho(V,t).\label{eq: FPE flux}
\end{equation}

\end_inset

is the probability current through 
\begin_inset Formula $V$
\end_inset

 at time 
\begin_inset Formula $t$
\end_inset

.
 Because a spike is emitted each time 
\begin_inset Formula $V$
\end_inset

 reaches 
\begin_inset Formula $V_{\text{th}}$
\end_inset

, neurons can not reach the region 
\begin_inset Formula $V>V_{\text{th}}$
\end_inset

.
 From this follows that 
\begin_inset Formula $\rho(V>V_{\text{th}},t)=0$
\end_inset

.
 The probability flux 
\begin_inset Formula $J(V_{\text{th}},t)$
\end_inset

 yields the fraction of neuron passing through threshold at a given time
 which is equivalent to the firing rate 
\begin_inset Formula $J(V_{\text{th}},t)=r(t)$
\end_inset

.
 From 
\begin_inset Formula $\rho(V>V_{\text{th}},t)=0$
\end_inset

 follows that 
\begin_inset Formula $\rho(V_{\text{th}},t)=0$
\end_inset

 because otherwise 
\begin_inset Formula $\rho(V,t)$
\end_inset

 would be discontinuous at the threshold and its derivative infinite.
 This would result into an infinite firing rate due to 
\begin_inset Formula $J(V_{\text{th}},t)\propto\frac{\partial}{\partial V}\rho(V_{\text{th}},t)$
\end_inset

.
 Neurons are reset immediately to 
\begin_inset Formula $V_{\text{r}}$
\end_inset

 after the spike emission.
 To ensure conservation of probability, the probability flux passing the
 threshold must be reinserted at the reset value 
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0}J(V_{\text{r}}+\epsilon,t)-J(V_{\text{r}}-\epsilon,t)=J(V_{\text{th}},t).
\end{equation}

\end_inset

which is illustrated in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: reset bc "

\end_inset

.
 Finally, neurons should not enter the system from the left boundary, i.e.
 the probability current needs to vanish 
\begin_inset Formula ${\displaystyle \lim_{V\rightarrow-\infty}}J(V,t)=0$
\end_inset

 for 
\begin_inset Formula $V\rightarrow-\infty$
\end_inset

.
 To summarize, we have in total three boundary boundary conditions (BC)
 
\end_layout

\begin_layout Enumerate
Left boundary condition: 
\begin_inset Formula 
\begin{equation}
\lim_{V\rightarrow-\infty}J(V,t)=0\label{eq: left bc}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Right boundary condition: 
\begin_inset Formula 
\begin{equation}
\rho(V_{\text{th}},t)=0\label{eq: right bc}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Reset boundary condition: 
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0}J(V_{\text{r}}+\epsilon,t)-J(V_{\text{r}}-\epsilon,t)=J(V_{\text{th}},t)=r(t).\label{eq: reset bc}
\end{equation}

\end_inset


\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename figures/reset_bc.svg

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Sketch of the reset boundary condition.
\begin_inset CommandInset label
LatexCommand label
name "fig: reset bc "

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
If the rate pooled inputs is large, and the change jumps caused in the synaptic
 current is small, then the can be approximated by a Gaussian white noise.
 This is illustrated in figure [] The normalized contribution of a single
 
\begin_inset Formula $\delta$
\end_inset

-function input is called postsynaptic response function 
\begin_inset CommandInset citation
LatexCommand cite
key "Burkitt2006a"

\end_inset


\begin_inset Formula 
\[
\epsilon(t)=\frac{1}{\tau_{\text{m}}}e^{-\frac{t}{\tau_{\text{m}}}}\theta(t)
\]

\end_inset

The normalized postsynaptic response function is given by 
\begin_inset Formula 
\begin{equation}
\epsilon(t)=\frac{e^{-\frac{t}{\tau_{\text{m}}}}-e^{-\frac{t}{\tau_{\text{s}}}}}{\tau_{\text{m}}-\tau_{\text{s}}}\theta(t)
\end{equation}

\end_inset


\end_layout

\begin_layout Plain Layout
It replaces the synaptic current in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: neuron dynamics"

\end_inset

 by an average current plus an additional Gaussian white noise.
 The diffusion approximation can be understood as an approximation of the
 Poisson input in the limes of large input rates and small synaptic efficacies
 
\begin_inset Formula $h$
\end_inset

.
 By small, we mean that the post synaptic potential PSP induced by spike
 arrival is small compared to the distance from the reset to the threshold
 potential.
 
\end_layout

\begin_layout Plain Layout
The strength of the noise and the average input current depend on the rate
 of the Poisson input and the parameters of the neuron model.
 In the diffusion approximation, Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: continuity equation"

\end_inset

 reduces to a Fokker-Planck equation.
 
\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Solving the Fokker-Planck equation
\end_layout

\begin_layout Standard
Solving the time dependent FPE is a difficult task for several reasons.
 Firstly, the probability current makes a jump at the reset value due to
 reset boundary condition 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: reset bc"

\end_inset

.
 Secondly, the diffusion coefficient depends on time and the drift coefficient
 depends on the membrane potential and on time.
 The stationary solution for constant (time independent) input can be derived
 analytically for the LIF and QIF neuron and numerically for the EIF neuron
 
\begin_inset CommandInset citation
LatexCommand cite
key "Richardson2007,Richardson2008"

\end_inset

.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 used the diffusion approximation to derive the stationary firing rates
 in a recurrent randomly connected network of LIF neurons, mimicking a cortical
 column.
 The network in the study consists of an excitatory and inhibitory population
 (EI-Network).
 The populations receive additional uncorrelated stationary excitatory input
 from the external surrounding of the network.
 This external input represents the global spontaneous ongoing activity
 observed in cortex which has typically low firing rates 
\begin_inset Formula $1$
\end_inset

-
\begin_inset Formula $5$
\end_inset

 Hz.
 The purely excitatory external input is motivated by the fact that excitatory
 pyramidal neurons tend to form longer axons compared to inhibitory neurons
 which connect more locally 
\begin_inset CommandInset citation
LatexCommand citep
key "Braitenberg2013"

\end_inset

.
 The stationary solution of the Fokker-Planck equation yields the stationary
 firing rate of the excitatory and inhibitory population for a given input
 rate 
\begin_inset CommandInset citation
LatexCommand citep
key "A.1953"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 showed that the equation for the stationary firing rage has a solution
 for which the average firing rate of the excitatory population matches
 the spontaneous activity of the external surrounding.
 This is desirable because the excitatory population is the external surrounding
 from the perspective of the neighboring cortical columns.
 Finding the solution for the output firing rate of a population which reproduce
s the initial input firing rate is often referred to as self-consistent
 mean-field theory 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

.
 Spontaneous activity is hypothesized to be a ground state of the brain.
 Compared to silent networks, a spontaneous active network has the advantage
 that it places neurons close to the threshold, rather at their resting
 potential so that the network can respond faster to a stimulus.
\end_layout

\begin_layout Standard
The stability of the stationary state presented in 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 has been studied extensively in 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000,Brunel1999,Lindner2001"

\end_inset

.
 If the temporal modulations of the firing rate are small compared to its
 stationary baseline 
\begin_inset Formula 
\begin{equation}
r(t)=r+\delta r(t),
\end{equation}

\end_inset

with 
\begin_inset Formula $\bigl|\delta r(t)\bigr|\ll r$
\end_inset

, then perturbation theory can be applied 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

.
 showed that the LIF neuron behaves like a linear filter in first order
 approximation.
 The most important steps of the derivation are presented in more detail
 in Sec 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Solving-the-Fokker-Planck"

\end_inset

.
 The filter properties are characterized by the response-function 
\begin_inset Formula $T(t)$
\end_inset

 which determines how the time dependent part of the output firing rate
 
\begin_inset Formula $\delta\tilde{r}(t)$
\end_inset

 depends on the input firing rate 
\begin_inset Formula 
\begin{equation}
\delta\tilde{r}(t)=\int_{-\infty}^{t}T(t)\delta r(t).\label{eq: transfer}
\end{equation}

\end_inset

The gain (change in amplitude) of the response is related to the modulus
 
\begin_inset Formula $\left|T(f)\right|$
\end_inset

 and the phase shift to the argument 
\begin_inset Formula $\arg[T(f)]$
\end_inset

 of the Fourier transform of 
\begin_inset Formula $T(f)$
\end_inset

 also referred to as the transfer function.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 showed that the self-consistent solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: transfer"

\end_inset

 mark the points where the stationary state loses stability and network
 transitions into a regime which can sustain global oscillations.
 Depending on the strength of the external input, the balance between excitation
 and inhibition, and the time scale of the synaptic delay, the average firing
 rate of the populations can show oscillations in different frequency regimes.
 Independently of the global oscillations, the firing of individual neurons
 are still highly irregular.
 The work by 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 has been the first analytical study investigating the synchronization propertie
s of randomly connected recurrent spiking neural networks.
 
\end_layout

\begin_layout Standard
The transfer function 
\begin_inset Formula $T(\omega)$
\end_inset

 for the LIF neuron behaves like a low-pass filter decaying with 
\begin_inset Formula $1/\sqrt{f}$
\end_inset

 in the high frequency limit.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 studied the frequency response for nonlinear integrate-and-fire neurons
 and showed that EIF acts as a filter with constant gain in the low and
 intermediate frequency range followed by a 
\begin_inset Formula $1/f$
\end_inset

 drop off in high frequency limit.
 These results hold for current-based as well as conductance-based synapses,
 because the spike-generating currents dominate the neuronal dynamics and
 the synaptic input has little effect on what happens after spike initiation.
 Replacing the delta-synapses by synapses with finite synaptic time scale
 introduces temporal correlations into the input noise which decay on the
 order the synaptic time scale.
 The temporal correlations can be effectively modeled by replacing the Gaussian
 white noise in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 by colored noise 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud2002"

\end_inset

 with a auto-correlation function which decays exponentially on the same
 time scale as the synapse.
 Using numerical simulations, 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 showed that the filtering properties of the EIF are in good agreement with
 those of more realistic H-H type models used in 
\begin_inset CommandInset citation
LatexCommand cite
key "Hansel2002"

\end_inset

.
 Knowing how the filtering properties of spiking neuronal model can be used
 to map spiking neuron models to rate based models as it has been done in
 
\begin_inset CommandInset citation
LatexCommand cite
key "Aviel2006,Ostojic2011a"

\end_inset

.
\end_layout

\begin_layout Standard
The results in presented studies are all leading approximation, i.e.
 they are only applicable if the temporal modulations of input firing rate
 are small compared to its baseline.
 Since the derivation for LIF neuron are already quite involved, it seems
 to likely that extending the results to more complex neuron models and
 higher orders would require a combination of analytical and numerical methods.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Deniz2017"

\end_inset

 recently solved the stationary FPE for the LIF neuron for arbitrary input
 correlations using the method of spectral decomposition.
 They showed that their method can be related to the perturbative approach
 used in 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindner2001"

\end_inset

 which relies on the assumption that correlations are small.
 Hence, using the method spectral decomposition may allows to derive higher
 order corrections for the transfer function in a similar manner.
 
\end_layout

\begin_layout Standard
The method of spectral decomposition expands the density function in terms
 of the eigenfunctions of the differential operator which describes its
 time evolution.
 It has been first introduced in the context of PDMs by 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

.
\end_layout

\begin_layout Subsection
Spectral decomposition
\begin_inset CommandInset label
LatexCommand label
name "subsec:Spectral-decomposition"

\end_inset


\end_layout

\begin_layout Standard
In this section we follow the notation introduced in 
\begin_inset CommandInset citation
LatexCommand citep
key "Knight2000a"

\end_inset

.
 We start from equation Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PDE"

\end_inset

 and Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE"

\end_inset

 both of which can be written as 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=Q(\boldsymbol{v},r(t))\rho(\boldsymbol{v},t),\label{eq: rho operator}
\end{equation}

\end_inset

where 
\begin_inset Formula $Q$
\end_inset

 is called the dynamical operator which depends implicitly on time through
 its dependence on the input firing rate 
\begin_inset Formula $r(t)$
\end_inset

.
 In the diffusion approximation, 
\begin_inset Formula $Q$
\end_inset

 is equivalent to the Fokker-Planck operator introduced in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FP operator"

\end_inset

.
 The eigenfunctions 
\begin_inset Formula $\phi_{n}(\boldsymbol{v},t)$
\end_inset

 and eigenvalues 
\begin_inset Formula $\lambda_{n}(t)$
\end_inset

 of 
\begin_inset Formula $Q$
\end_inset

 are defined by 
\begin_inset Formula 
\begin{equation}
Q(\boldsymbol{v},r(t))\phi_{n}(\boldsymbol{v},t)=\lambda_{n}(t)\phi_{n}(\boldsymbol{v},t).\label{eq: phi_n}
\end{equation}

\end_inset

Note that both eigenfunctions and eigenvalues are time dependent because
 
\begin_inset Formula $Q$
\end_inset

 changes in time.
 Hence, we are dealing with moving basis.
 The dynamical operator 
\begin_inset Formula $Q$
\end_inset

 is not Hermitian (self-adjoint) due to the first derivative in the drift
 term in Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: PDE"

\end_inset

 and Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: FPE"

\end_inset

.
 For non Hermitian operators, eigenvalues 
\begin_inset Formula $\lambda_{n}$
\end_inset

 are in general complex and the eigenfunctions 
\begin_inset Formula $\phi_{n}(\boldsymbol{v},t)$
\end_inset

 are not orthogonal.
 Taking the complex conjugate of Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: phi_n"

\end_inset

 and using the fact that 
\begin_inset Formula $Q$
\end_inset

 is real, we find that 
\begin_inset Formula 
\begin{equation}
Q(\boldsymbol{v},t)\phi_{n}^{*}(\boldsymbol{v},t)=\lambda_{n}^{*}\phi_{n}^{*}(\boldsymbol{v},t).
\end{equation}

\end_inset

This shows that the eigenvalues and eigenfunctions of 
\begin_inset Formula $Q$
\end_inset

 come in complex conjugate pairs.
 If the set of eigenfunctions 
\begin_inset Formula $\{\phi_{n}(\boldsymbol{v})\}$
\end_inset

 are complete, then we can expand the density function in terms of eigenfunction
s
\begin_inset Formula 
\begin{equation}
\rho(\boldsymbol{v},t)=\sum_{n=-\infty}^{\infty}c_{n}(t)\phi_{n}(\boldsymbol{v},t),\label{eq: eigenfunction expansion}
\end{equation}

\end_inset

where we introduce the notation 
\begin_inset Formula $\phi_{-n}(\boldsymbol{v})=\phi_{n}^{*}(\boldsymbol{v})$
\end_inset

.
 Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: phi_n"

\end_inset

 into the firing rate is given by Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: r"

\end_inset

 and using that the functional 
\begin_inset Formula $R$
\end_inset

 is linear, we arrive at 
\begin_inset Formula 
\begin{equation}
r(t)=R[\boldsymbol{J}(\boldsymbol{v},t)]=R[C\rho(\boldsymbol{v},t)]=\sum_{n=-\infty}^{\infty}c_{n}(t)R[C\phi_{n}(\boldsymbol{v},t)].
\end{equation}

\end_inset

where 
\begin_inset Formula $C$
\end_inset

 is the linear current operator 
\begin_inset Formula 
\begin{equation}
J(\boldsymbol{v},t)=C\rho(\boldsymbol{v},t).
\end{equation}

\end_inset

The current operator 
\begin_inset Formula $C$
\end_inset

 is related to dynamical operator by 
\begin_inset Formula $Q=-KC$
\end_inset

, where 
\begin_inset Formula $K$
\end_inset

 is the familiar divergence operator of ordinary vector analysis 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

.
 The weighting coefficient 
\begin_inset Formula $c_{n}(t)$
\end_inset

 tell us how the 
\begin_inset Formula $n$
\end_inset

th mode contributes to 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 a given point in time.
 The density 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 must fulfill the boundary conditions introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Boundary-conditions"

\end_inset

, this means that each eigenfunction 
\begin_inset Formula $\phi_{n}(\boldsymbol{v},t)$
\end_inset

 must also fulfill the boundary conditions to ensure that any linear combination
 of eigenfunctions fulfills them as well.
 To determine the weighting coefficients 
\begin_inset Formula $c_{n}(t)$
\end_inset

, we need to construct a basis 
\begin_inset Formula $\left\{ \tilde{\phi}_{n}(\boldsymbol{v},t)\right\} $
\end_inset

 which is orthogonal to 
\begin_inset Formula $\{\phi_{n}(\boldsymbol{v},t)\}$
\end_inset

.
 It turns of that the desired basis 
\begin_inset Formula $\left\{ \tilde{\phi}_{n}(\boldsymbol{v},t)\right\} $
\end_inset

 is spanned by the eigenfunctions of the adjoint operator 
\begin_inset Formula $Q^{\dagger}$
\end_inset

.
 The set of eigenfunctions 
\begin_inset Formula $\left\{ \tilde{\phi}_{n}(\boldsymbol{v},t),\phi_{n}(\boldsymbol{v},t)\right\} $
\end_inset

 is referred to as a dual basis.
 The time evolution 
\begin_inset Formula $c_{n}(t)$
\end_inset

 is determined by a coupled system of linear equations.
 Details are presented in Sec 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition-1"

\end_inset

.
 
\end_layout

\begin_layout Standard
The hope is that a finite number of modes is sufficient to describe the
 dynamics of the population.
 This dimensionality reduction could provide a computational efficient tool
 to simulate Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: rho operator"

\end_inset

 on the one hand as envisioned by 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

, and provide a more intuitive understanding about the network dynamics
 in terms eigenmodes on the other hand.
 In order to achieve this it is necessary to know how the eigenvalues and
 eigenfunctions change as a function of the input rate.
 Finding an analytic expression of the eigenvalues and eigenfunctions is
 difficult and has so far only been achieved for the PIF neuron with additional
 constant leak term 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2002"

\end_inset

 and the LIF neuron 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunel2000,Lindner2001,Deniz2017"

\end_inset

 in the diffusion limit.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2002"

\end_inset

 presented a way to include changes in the input rate due to recurrent connectio
ns in a self-consistent manner.
 As a proof of principle, they showed in the subsequent work 
\begin_inset CommandInset citation
LatexCommand citep
key "Mattia2004"

\end_inset

 that the theory is capable of predicting the network dynamics of a recurrent
 connected EI-Network of PIF neurons.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Biggio2017"

\end_inset

 developed a method to study a general integrate-and-fire model with exponential
 decaying synaptic currents.
 Their method reduces the inherently two dimension problem to a one dimensional.
 Theoretical predicted averaging firing rates show excellent agreement to
 simulation of PIF neurons.
\end_layout

\begin_layout Standard
So far it is not known if eigenfunctions can be found for regimes where
 the diffusion approximation does not apply.
 Furthermore, more complex models including synaptic dynamics, adaptation
 or spike generating currents have not been studied yet.
 
\end_layout

\begin_layout Section*
Research questions
\end_layout

\begin_layout Enumerate
Is it possible to efficiently simulate large scale neuronal networks on
 the population level by describing each population by a finite set of eigenmode
s? 
\begin_inset Note Note
status collapsed

\begin_layout Enumerate
Is it possible to develop an algorithm to numerically determine eigenfunctions
 and eigenvalues for a wide class of neuron models?
\end_layout

\end_inset


\end_layout

\begin_layout Enumerate
Using the method of spectral decomposition, can we characterize the response-fun
ction of neuron for a wide class neurons models without relying on the assumptio
n that temporal input modulations are small? Can we use the response-function
 to derive a mapping between spiking neuron models and rate neurons which
 only depends on the microscopic parameter of the spiking model?
\end_layout

\begin_layout Section*
Research proposal
\end_layout

\begin_layout Standard
In computational neuroscience, the most common method to simulate neural
 circuits is by means of direct simulation.
 This approach follows the dynamics of all neurons individually taking into
 account interactions modeled by connectivity blueprint and synaptic dynamics.
 Although, direct simulations yield full information about the network state
 on the single neuron level at all times, direct simulations also have shortcomi
ngs: They demand a fast amount of computational resources, even for extremely
 simplified neuron models, large scale brain simulations need to be run
 on supercomputers 
\begin_inset CommandInset citation
LatexCommand citep
key "Schuecker2017"

\end_inset

.
 This makes it difficult to systematically investigate relationships between
 model parameters, connectivity structure and network dynamics.
 
\end_layout

\begin_layout Standard
The columnar organization hypothesis, first proposed by by 
\begin_inset CommandInset citation
LatexCommand cite
key "Mountcastle1979"

\end_inset

, states that the cortical sheet is organized in cortical columns.
 It is currently the most widely adopted hypothesis to explain the cortical
 processing of information 
\begin_inset CommandInset citation
LatexCommand cite
key "DeFelipe2013"

\end_inset

.
 Cortical columns are structured into layers, different types of neurons
 within the different layers are usually pooled into populations.
 In the simplest case, each layer is represented by an excitatory and inhibitory
 population 
\begin_inset CommandInset citation
LatexCommand cite
key "Potjans2012"

\end_inset

.
 Cortical column models are often used as a elementary building block, to
 model larger brain areas.
 It is therefore desirable to have method which can efficiently simulate
 a cortical column on different levels of detail.
 
\end_layout

\begin_layout Standard
Population density methods (PMDs) seek to make us of the redundancy observed
 cortical networks.
 PDMs use a probabilistic description on the level of populations instead
 of modeling networks on the level of individual neurons.
 The state of each population is characterized by a probability density
 function which determines the fraction of neurons which are in a given
 state space volume at given time.
 Populations interact by sending Poisson spike trains to each other.
 The firing rate of the Poisson process is given by the population average
 firing rate which can be determined from how the density function changes
 in time.
 Population density reduce the dimensionalty of the problem from the number
 of neurons to the number of populations.
 
\end_layout

\begin_layout Standard
Hence, on the first glance, one would think that this should result in a
 massive simulation speed up.
 However, even for simple neuronal models, the time evolution of the density
 is governed by a complicated integro partial differential equation (iPDE)
 
\begin_inset CommandInset citation
LatexCommand cite
key "Omurtag"

\end_inset

.
 The complexity of solving the iPDE scales drastically with the dimension
 of the neuron model.
 Using the method of characteristics, 
\begin_inset CommandInset citation
LatexCommand cite
key "DeKamps2003"

\end_inset

 developed a generic and stable method to solve the iPDE.
 It relies on representing the density function on a geometric grid which
 mimics the intrinsic neuron dynamics.
 Depending on the specifies of the neuron model, a large number of grid
 cells are needed to arrive at an accurate prediction.
 Roughly, the number of cells grows exponentially with the number of dimensions
 of the neuron model.
 For two dimensional models, simulation times are currently on the same
 time scale compared to direct simulations.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

 proposed a different method of solution which is based on the idea of expanding
 the probability density function in terms of eigenfunctions of the dynamical
 operator which describes the time evolution of the density.
 By doing so the problem can be separated into two distinct parts.
 Firstly, a finite set of eigenfunctions and eigenvalues of the dynamical
 operator need to determined for a given neuron model.
 This problem does not depend is time independent and can be done before
 the simulation.
 Secondly, the time evolution of the weighting coefficients need to determined.
 This eigenfunction decomposition reduces the PDE to a finite system of
 ordinary differential equations (ODEs) which can presumably be solved much
 faster than the iPDE.
 So far, analytic results for eigenvalues and eigenfunction are known for
 the the perfect integrate-and-fire model leaky integrate-and-fire model
 in the diffusion approximation 
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002,Brunel1999,Deniz2017"

\end_inset

.
 Hence, our first goal is to develop a generic numerical method to determine
 eigenvalues and eigenfunctions for more complex neuron models.
 Subsequently, we want to demonstrate expanding the density function in
 terms of eigenfunctions allows us to efficiently simulate the dynamics
 of populations in a cortical column.
 
\end_layout

\begin_layout Standard
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Section
Preliminary Results 
\end_layout

\begin_layout Standard
Our objective is to develop a numerical algorithm to determine the eigenvalues
 and eigenfunctions of the dynamical operator introduced in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

 for wide class of neuron models.
 In the diffusion approximation, eigenvalues and eigenfunctions of the perfect
 integrate-and-fire and the leaky integrate-and-fire neuron can be determined
 analytically.
 Hence, as a first step, we recover the results presented 
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002,Deniz2017,Brunel1999"

\end_inset

 so that we can compare the performance of our algorithm against them.
 
\end_layout

\begin_layout Subsection
Perfect integrate-and-fire 
\end_layout

\begin_layout Standard
The perfect integrate-and-fire (PIF) also referred to as the simplest integrate-
and-fire model has been introduced in 
\begin_inset CommandInset citation
LatexCommand cite
key "Fusi1999"

\end_inset

 and is described by 
\begin_inset Formula 
\begin{equation}
\frac{dv}{dt}=-\alpha+I_{\text{s}}(t)
\end{equation}

\end_inset

It can be obtained from the leaky integrate-and-fire neuron by replacing
 the leak term by a constant.
 As discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Diffusion-approximation"

\end_inset

, in the diffusion approximation, the synaptic input is replaced by a Gaussian
 white noise 
\begin_inset Formula 
\begin{align}
\frac{dv}{dt} & =-\alpha+\mu(t)+\sqrt{\sigma(t)}\xi(t)=\eta(t)+\sqrt{\sigma(t)}\xi(t)\label{eq: PIF diffusion}
\end{align}

\end_inset

where defined 
\begin_inset Formula $\eta(t)=\mu(t)-\alpha$
\end_inset

.
 As discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Fokker-Planck-equation"

\end_inset

, Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PIF diffusion"

\end_inset

 can cast into a FPE 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(v,t)}{\partial t}=L\rho(v,t),\quad L=-\eta(t)\frac{\partial}{\partial v}+\frac{\sigma^{2}(t)}{2}\frac{\partial^{2}}{\partial v},
\end{equation}

\end_inset

The eigenfunctions of the FP operator 
\begin_inset Formula $L$
\end_inset

 are determined by Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: phi_n"

\end_inset

 which can be written as 
\begin_inset Formula 
\begin{equation}
-\eta\phi'_{n}(v)+\frac{\sigma^{2}}{2}\phi_{n}''(v)=\lambda_{n}\phi_{n}(v),\label{eq: PIF phi_n}
\end{equation}

\end_inset

where we suppressed the time argument for convenience.
 Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PIF phi_n"

\end_inset

 is a ODE with constant coefficients which can be solved using an exponential
 ansatz 
\begin_inset Formula $\phi_{n}(v)=e^{\alpha v}$
\end_inset

 .
 The free coefficients of the general solution must be determined such that
 
\begin_inset Formula $\phi_{n}(v)$
\end_inset

 fulfills the BC of 
\begin_inset Formula $\rho(v,t)$
\end_inset

.
 Without going into the details of the derivation, in the end one arrives
 at an expression for the eigenfunctions 
\begin_inset Formula $\phi_{n}(v)$
\end_inset

 and the eigenfunctions of the adjoint operator 
\begin_inset Formula $\tilde{\phi}_{n}(v)$
\end_inset

 
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002"

\end_inset


\begin_inset Formula 
\begin{align*}
\phi_{0}(v,t) & =\frac{c}{\eta}\left(1-e^{\frac{-2\xi(\theta-v)}{\theta}}\right),\\
\phi_{n}(v,t) & =c_{n}\sinh\left(\zeta_{n}\frac{\theta_{n}-v}{\theta}\right)e^{\frac{\xi v}{\theta}},\quad\text{for }n\neq0,\\
\tilde{\phi}{}_{n}(v,t) & =\left[\zeta_{n}\cosh\left(\frac{\zeta_{n}v}{\theta}\right)+\xi\sinh\left(\frac{\zeta_{n}v}{\theta}\right)\right]e^{-\frac{\xi}{\theta}v},
\end{align*}

\end_inset

where 
\begin_inset Formula $\xi$
\end_inset

 and 
\begin_inset Formula $\zeta_{n}$
\end_inset

 are given by
\begin_inset Formula 
\[
\zeta_{n}=\frac{\theta}{\sigma^{2}}\sqrt{\eta^{2}+2\sigma^{2}\lambda_{n}},\quad\xi=\frac{\eta\theta}{\sigma^{2}}.
\]

\end_inset

 From the reset BC, a characteristic equation for the eigenvalues can be
 derived 
\begin_inset Formula 
\[
\zeta_{n}e^{\xi}=\zeta_{n}\cosh\left(\zeta_{n}\right)+\xi\sinh\left(\zeta_{n}\right).
\]

\end_inset

The roots of this equation determine the infinite countable set of eigenvalues
 
\begin_inset Formula $\{\lambda_{n}\}$
\end_inset

.
 Eigenvalues of the first three modes for different values of 
\begin_inset Formula $\eta$
\end_inset

 and 
\begin_inset Formula $\sigma=1$
\end_inset

 are shown in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: PIF spectrum"

\end_inset

.
 Eigenvalues are purely real for 
\begin_inset Formula $\eta<0$
\end_inset

 (noise dominated regime) and imaginary for 
\begin_inset Formula $\eta>0$
\end_inset

 (drift dominated) regime.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/PIF_spectrum.png
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Real part and imaginary part 
\begin_inset Formula $\lambda_{n}$
\end_inset

 for the first mode (blue), second mode (orange), third mode (green) for
 different values of 
\begin_inset Formula $\eta$
\end_inset

.
 The remaining model parameters are set to
\begin_inset Formula $\{\sigma=1,v_{\text{r}}=1,v_{\text{th}}=1\}$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig: PIF spectrum"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset

The first three eigenfunctions are shown as an example for two different
 values of 
\begin_inset Formula $\eta$
\end_inset

 (drift and noise dominated regime) in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: PIF eigenfunctions"

\end_inset

.
 Note that the eigenfunctions fulfill the boundary condition 
\begin_inset Formula $\phi_{n}(v_{\text{th}})=0$
\end_inset

 as desired.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/PIF_ef.png
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Real and imaginary part of the first three eigenfunctions 
\begin_inset Formula $\phi_{n}(v)$
\end_inset

 for 
\begin_inset Formula $\eta=-1$
\end_inset

 (left column) and 
\begin_inset Formula $\eta=1$
\end_inset

 (right) column.
 The remaining model parameters are set to
\begin_inset Formula $\{\sigma=1,v_{\text{r}}=0,v_{\text{th}}=1\}$
\end_inset

.
\begin_inset CommandInset label
LatexCommand label
name "fig: PIF eigenfunctions"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset

Knowing eigenfunctions and eigenvalues, we can predict the time evolution
 of the density function and the population firing rate at any times for
 a given initial condition.
 Figure shows the simulation results for a population of non-interacting
 PIF neurons which receive a constant external input.
 In the beginning of the simulation all neurons are placed at the reset
 potential, i.e.
 
\begin_inset Formula $\rho(V,0)=\delta(v_{\text{r}})$
\end_inset

.
 Hence, the initial value of the weighting coefficient of the 
\begin_inset Formula $n$
\end_inset

th mode is given by 
\begin_inset Formula 
\[
c_{n}(0)=(\tilde{\phi}_{n},\delta(v_{\text{r}}))=\tilde{\phi}_{n}(v_{\text{r}}).
\]

\end_inset

This shows us that all modes with 
\begin_inset Formula $\tilde{\phi}_{n}(v_{\text{r}})\neq0$
\end_inset

 are needed in beginning to combine to the delta-function 
\begin_inset Formula $\delta(v_{\text{r}})$
\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/PIF_rate_density.png
	scale 60

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Top panel shows the firing rate of the population over time for 
\begin_inset Formula $\{\eta=10,\sigma=1,v_{\text{th}}=1,v_{\text{r}}=0,a=\}$
\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset

.
 Theoretical result (black curve) have been calculated using the first three
 modes.
 The red dashed line shows the result from the Miind simulation.
 The green line shows the average firing rate obtained from 
\begin_inset Formula $1000$
\end_inset

 Monte Carlo simulations.
 The background colors mark different time intervals in which only a certain
 subset of modes is still active while all other have already decayed to
 zero.
 In the blue the time interval only the first mode is active, in yellow
 interval the first two modes are active and in green time interval the
 first three modes are active.
 The bottom panel shows the density function relative to the stationary
 distribution 
\begin_inset Formula $\rho_{0}$
\end_inset

 at two different time points indicated by the crosses in the top panel.
 Theoretical result (black curve) in left panel has been calculated using
 the first two modes, and only the first mode in the right panel.
 The red dashed lines show the result from the Miind simulation.
\end_layout

\end_inset


\end_layout

\end_inset

The firing starts at zero because all neurons are at the reset in the beginning.
 The peaks in the beginning can be explained the fact that the drift coefficient
 
\begin_inset Formula $\eta$
\end_inset

 is much stronger compared to the diffusion coefficient 
\begin_inset Formula $\sigma$
\end_inset

, i.e.
 the initial density function is still strongly peaked when neurons reach
 the threshold for the first time.
 However, the initial peak will diffuse eventually and both the density
 function and the firing rate converge to steady state.
 From a mathematical viewpoint, oscillations of the the firing rate occur
 because eigenvalues becoming complex for 
\begin_inset Formula $\eta>0$
\end_inset

.
 We observe that Miind and MC simulations both show a good agreement with
 the theoretical prediction.
 As expected, the first three modes suffice to describe the full time evolution
 in the colored area.
 A strength of Miind compared to MC is that it produces smooth curves because
 it solves Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: PDE"

\end_inset

 directly.
 The input in the Miind and MC simulation is modeled by a homogeneous Poisson
 process.
 
\end_layout

\begin_layout Subsubsection
Leaky integrate-and-fire 
\begin_inset CommandInset label
LatexCommand label
name "subsec: LIF"

\end_inset


\end_layout

\begin_layout Standard
The FP equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE"

\end_inset

 for LIF neuron reads 
\begin_inset Formula 
\begin{equation}
\partial_{t}\rho(V,t)=L\rho(V,t),\quad L=\partial_{V}\left(\frac{1}{\tau}\left[V-\mu(t)\right]+\frac{\sigma^{2}(t)}{2\tau}\partial_{V}\right),
\end{equation}

\end_inset

where we set reversal potential of the leak channel to 
\begin_inset Formula $V_{L}=0$
\end_inset

.
 The variable transformation 
\begin_inset Formula 
\begin{equation}
s=\frac{t}{\tau},\quad x=\frac{\sqrt{2}}{\sigma}(V-\mu),
\end{equation}

\end_inset

bring the Fokker-Planck into the simpler form 
\begin_inset Formula 
\begin{equation}
L=\partial_{x}\left(x+\partial_{x}\right),
\end{equation}

\end_inset

and eigenfunctions are determined by the linear second order ODE 
\begin_inset Formula 
\begin{equation}
\phi(x)+x\phi'(x)+\phi''(x)=\lambda\phi(x).
\end{equation}

\end_inset

Note that coefficient in front of the first derivative is not constant which
 complicates the derivation tremendously compare to PIF neuron.
 Here, we present only the end results for refer Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec: ef LIF"

\end_inset

 for a detailed derivation.
 In, end one finds 
\begin_inset Formula 
\begin{align}
\phi_{n}(x)=e^{-\frac{1}{4}x^{2}} & \begin{cases}
c_{n}U(z_{n},-x) & x<x_{\text{r}}\\
a_{n}V(z_{n},-x)+b_{n}U(z_{n},-x) & x_{\text{r}}\leq x<x_{\theta}
\end{cases},\label{eq: LIF phi_n}
\end{align}

\end_inset

where 
\begin_inset Formula $z_{n}=\lambda_{n}-1/2$
\end_inset

.
 The functions 
\begin_inset Formula $U(z,x)$
\end_inset

 and 
\begin_inset Formula $V(z,x)$
\end_inset

 are called parabolic cylinder functions 
\begin_inset CommandInset citation
LatexCommand cite
key "Abramowitz1965"

\end_inset

.
 Eigenfunctions are unique up to a arbitrary normalization constant which
 we set to be 
\begin_inset Formula 
\begin{equation}
\partial_{x}\phi(x_{\theta})=e^{-\frac{1}{4}x_{\theta}}\partial_{x}\varphi(x_{\theta})=\sqrt{\frac{2}{\pi}}.\label{eq: LIF normalization}
\end{equation}

\end_inset

The coefficients 
\begin_inset Formula $a_{n},b_{n}$
\end_inset

 and 
\begin_inset Formula $c_{n}$
\end_inset

 are chosen such that 
\begin_inset Formula $\phi_{n}(x)$
\end_inset

 fulfills the BC.
 For the specific normalization 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF normalization"

\end_inset

, they are given by 
\begin_inset Formula 
\begin{align}
a_{n} & =\frac{U(z_{n},y_{\theta})}{f(y_{\theta})},\nonumber \\
b_{n} & =-\frac{V(z_{n},y_{\theta})}{f(y_{\theta})},\nonumber \\
c_{n} & =\frac{V(z_{n},y_{\text{r}})}{f(y_{\text{r}})}-\frac{V(z_{n},y_{\theta})}{f(y_{\theta})}.
\end{align}

\end_inset

The eigenfunction of the adjoint operator is given by 
\begin_inset Formula 
\begin{equation}
\tilde{\phi}_{n}(x)=d_{n}e^{\frac{1}{4}x^{2}}U(z_{n},-x)
\end{equation}

\end_inset

where 
\begin_inset Formula $d_{n}$
\end_inset

 defined as 
\begin_inset Formula 
\begin{equation}
d_{n}=(e^{\frac{1}{4}x^{2}}U(z_{n},-x),\phi_{n}(x)),
\end{equation}

\end_inset

to ensure that 
\begin_inset Formula $(\tilde{\phi}_{n},\phi_{n})=1$
\end_inset

.
 The BC yield a characteristic equation for the eigenvalues 
\begin_inset Formula 
\begin{equation}
e^{-\frac{1}{4}x_{\text{r}}^{2}}U(z_{n},y_{\theta})-e^{-\frac{1}{4}x_{\theta}^{2}}U(z_{n},y_{\text{r}})=0\label{eq: characteristic equation}
\end{equation}

\end_inset

The solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 yield the infinite countable set of eigenvalues 
\begin_inset Formula $\{\lambda_{n}\}$
\end_inset

.
 Finding solutions 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 is not easy because the real and imaginary part of the parabolic cylinder
 functions undergo rapid oscillations in the complex plane.
 A preliminary attempt to solve Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 is illustrated in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: LIF Spectrum "

\end_inset

.
 Panel A shows the zero crossings of the real part and imaginary part Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 in the complex plane.
 We expect that solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 can be found at points where the blue line crosses the real axis and at
 points where the blue and yellow line cross each other.
 Using this points as a initial guess, we can solve Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 numerically using a bisection method on the real axis and newtons method
 in the complex plane.
 Panel B shows a exemplary spectrum.
 We find that the spectrum of the LIF neuron has complex and purely real
 eigenvalues which is different compared to the spectrum of PIF neuron which
 ha either purely real eigenvalues or complex eigenvalues but not both.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/LIF_spectrum.png
	scale 55

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Exemplary spectrum for 
\begin_inset Formula $\{\mu=1.2,\sigma=0.2,v_{\text{r}}=0,v_{\text{th}}=1,\tau_{\text{m}}=10\text{ms}\}$
\end_inset

.
 Panel A shows the zero crossings of the real part (blue )and imaginary
 part (yellow ) Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 in the complex plane.
 Panel B shows numerical solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig: LIF Spectrum "

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

 speculated that eigenvalues should approximately given by 
\begin_inset Formula 
\begin{equation}
\lambda_{n}\approx-\Gamma(r)n^{2}+in\omega_{0},
\end{equation}

\end_inset

where 
\begin_inset Formula $\Gamma(r)$
\end_inset

 is some unknown function which depends on the input rate and 
\begin_inset Formula $\omega_{0}$
\end_inset

 is called fundamental frequency.
 The fundamental frequency is given by 
\begin_inset Formula 
\begin{equation}
\omega_{0}=2\pi/T_{0},
\end{equation}

\end_inset

where 
\begin_inset Formula $T_{0}$
\end_inset

 is period which the membrane potential needs to go from the reset value
 to threshold, assuming that neuron receives the mean input 
\begin_inset Formula $\mu$
\end_inset

 neglecting fluctuations.
 In transformed coordinates, it is given by 
\begin_inset Formula 
\begin{equation}
T_{0}=\tau_{\text{m}}\ln\left(\frac{\mu}{\mu-V_{\text{th}}}\right)
\end{equation}

\end_inset

Note 
\begin_inset Formula $T_{0}$
\end_inset

 is only defined if 
\begin_inset Formula $\mu>V_{\text{th}}$
\end_inset

 which is referred to as mean driven regime.
 Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: LIF spectrum 2"

\end_inset

 panel A shows the imaginary part and real part of the complex eigenvalues
 shown in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: LIF Spectrum "

\end_inset


\series bold
 
\series default
panel B as a function of 
\begin_inset Formula $n$
\end_inset

 for 
\begin_inset Formula $\mu=1.2$
\end_inset

 and 
\begin_inset Formula $\sigma=0.2$
\end_inset

.
 We confirm that the real part shows quadratic, and the imaginary part a
 linear dependence on 
\begin_inset Formula $n$
\end_inset

.
 However, the slope of the fit does not match the fundamental frequency.
 Furthermore, eigenvalues are still complex if 
\begin_inset Formula $\mu<V_{\text{th}}$
\end_inset

 as can been in panel 
\series bold
B
\series default
.
 Interestingly, the real part of the eigenvalues seems to be only mildly
 affected by changing 
\begin_inset Formula $\mu$
\end_inset

 while the imaginary part changes linearly.
 This implies that oscillations with higher frequencies can occur for higher
 baseline input.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/LIF_spectrum_2.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Panel 
\series bold
A 
\series default
shows the real and imaginary part over of the complex eigenvalues plotted
 over 
\begin_inset Formula $n$
\end_inset

 for 
\begin_inset Formula $\{\mu=1.2,\sigma=0.2,V_{\text{th}}=1,V_{\text{r}}=1\}$
\end_inset


\begin_inset CommandInset label
LatexCommand label
name "fig: LIF spectrum 2"

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Redo figure 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Fig shows the eigenfunctions for the first three eigenvalues (Panel 
\series bold
A
\series default
) and purely real eigenvalues (Panel 
\series bold
B
\series default
).
 We confirm that 
\begin_inset Formula $\phi_{n}(V)$
\end_inset

 fulfills the right BC 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: right bc"

\end_inset

 
\begin_inset Formula $\phi_{n}(V_{\text{th}}=1)$
\end_inset

.
 Note that 
\begin_inset Formula $\phi_{n}(V)$
\end_inset

 has as kink at the reset potential 
\begin_inset Formula $V_{\text{r}}=0$
\end_inset

 where the first derivative makes a jump.
 The size of the jump is 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF normalization"

\end_inset

 equivalent to value of the derivative at threshold potential which we constrain
t to be 
\begin_inset Formula $\sqrt{2/\pi}\approx0.8$
\end_inset

.
 Hence, we conclude that 
\begin_inset Formula $\phi_{n}(V)$
\end_inset

 the reset BC 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: reset bc"

\end_inset

.
 The third eigenfunction (green) in panel 
\series bold
B 
\series default
is not correctly displayed.
 We assume that the error comes from the fact that parabolic cylinder functions
 
\begin_inset Formula $U(z_{n},x)$
\end_inset

 and 
\begin_inset Formula $V(z_{n},x)$
\end_inset

 undergo rapid changes from extremely high to extremely low values in the
 complex plane.
 In the interval 
\begin_inset Formula $V>V_{\text{r}}$
\end_inset

, the solution 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF phi_n"

\end_inset

 for 
\begin_inset Formula $\phi_{n}(V)$
\end_inset

 is given by a weighted of 
\begin_inset Formula $U(z_{n},x)$
\end_inset

 and 
\begin_inset Formula $V(z_{n},x)$
\end_inset

, i.e.
 we are possibly adding extremely large and extremely low floats which is
 prone to numerical errors.
 We need to investigate this further to arrive at numerical stable implementatio
n.
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/LIF_eigenfunctions.png
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout

\series bold
A
\series default
: Eigenfunctions and 1st derivative for the first three purely real eigenvalues.
 
\series bold
B
\series default
: Eigenfunctions and 1st derivative of the first three complex eigenvalues.
 Parameters 
\begin_inset Formula $\{\mu=1.2,\sigma=0.2,V_{\text{th}}=1,V_{\text{r}}=1\}$
\end_inset

.
 
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Higher order corrections to the transfer function 
\end_layout

\begin_layout Standard
We discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Solving-the-Fokker-Planck"

\end_inset

 the response of neuron to a time modulated input rate can be characterized
 in leading order by the transfer function 
\begin_inset Formula $T(t)$
\end_inset

.
 Here, we want to investigate if we can obtain higher order corrections,
 i.e.
 in a regime where the amplitude of input modulations is not small compared
 to the stationary baseline, by expanding the probability density function
 
\begin_inset Formula $\rho(V,t)$
\end_inset

 in terms of eigenfunctions.
 We follow 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 and start from Eq.
 Our objective is to solve the Fokker-Planck equation if the neuron population
 receives time dependent input rate
\begin_inset Formula 
\begin{equation}
r(t)=r_{0}+\delta r(t).
\end{equation}

\end_inset

We assume that the time dependent input modulation 
\begin_inset Formula $\left|\delta r(t)\right|$
\end_inset

 is small compared to the baseline 
\begin_inset Formula $r_{0}$
\end_inset

.
 The diffusion approximation, Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire"

\end_inset

 becomes 
\begin_inset Formula 
\begin{equation}
\tau_{\text{m}}\frac{dV}{dt}=f(V)+\mu(t)+\sqrt{\tau_{m}}\sigma^{2}(t)\xi(t),
\end{equation}

\end_inset

where 
\begin_inset Formula $\mu(t)$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}(t)$
\end_inset

 can be written as 
\begin_inset Formula 
\begin{align}
\mu & =\mu_{0}+\delta u(t)=\tau_{\text{m}}h(r_{0}+\delta r(t)),\nonumber \\
\sigma^{2} & =\sigma_{0}^{2}+\delta\sigma^{2}(t)=\tau_{\text{m}}h(r_{0}+h\delta r(t))
\end{align}

\end_inset

We introduce the expansion parameter 
\begin_inset Formula $\epsilon(t)=\delta r(t)/r_{0}$
\end_inset

 so that 
\begin_inset Formula $\delta\mu(t)$
\end_inset

 and 
\begin_inset Formula $\delta\sigma^{2}(t)$
\end_inset

 can be written as
\begin_inset Formula 
\begin{align}
\delta\mu(t) & =\epsilon(t)\frac{\tau h}{r_{0}},\nonumber \\
\delta\sigma^{2}(t) & =\epsilon(t)\frac{\tau h^{2}}{r_{0}}.
\end{align}

\end_inset

The Fokker-Planck operator 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FP operator"

\end_inset

 is given by
\begin_inset Formula 
\[
L(t)=-\frac{1}{\tau_{\text{m}}}\frac{\partial}{\partial V}[f(V)+\mu(t)]+\frac{\sigma(t)^{2}}{2\tau_{\text{m}}}\frac{\partial^{2}}{\partial V^{2}}.
\]

\end_inset

We split the FP operator into a constant and time dependent part 
\begin_inset Formula 
\begin{align}
L_{0} & =\partial_{V}\left(\frac{1}{\tau}\left[V-\mu_{0}\right]-\frac{1}{C}\psi(V)\right)+\frac{\sigma^{2}}{2\tau}\partial_{V}^{2},\\
\epsilon(t)L_{1} & =\epsilon(t)\left(-G\partial_{V}+H\partial_{V}^{2}\right),\label{eq: L1}
\end{align}

\end_inset

where we defined the constants 
\begin_inset Formula $G$
\end_inset

 and 
\begin_inset Formula $H$
\end_inset


\begin_inset Formula 
\begin{equation}
G=-\frac{h}{r_{0}},\quad H=\frac{h^{2}}{2r_{0}}.
\end{equation}

\end_inset

The FPE can be written as 
\begin_inset Formula 
\begin{equation}
\partial_{t}\rho(V,t)=L_{0}\rho(V,t)+\epsilon(t)L_{1}\rho(V,t)\label{eq: FPE-2}
\end{equation}

\end_inset

Expanding 
\begin_inset Formula $\rho(V,t)$
\end_inset

 in terms of the eigenfunctions of the constant operator 
\begin_inset Formula $L_{0}$
\end_inset


\begin_inset Formula 
\begin{equation}
\rho(V,t)=\sum_{n}c_{n}(t)\phi_{n}(V).
\end{equation}

\end_inset

and substituting the expansion into Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE-2"

\end_inset

 yields 
\begin_inset Formula 
\begin{equation}
\sum_{n}\dot{c}_{n}(t)\phi_{n}(V)=\sum_{n}c_{n}(t)L_{0}\phi_{n}(V)+\epsilon(t)\sum_{n}c_{n}(t)L_{1}\phi_{n}(V)
\end{equation}

\end_inset

Multiplying from left with 
\begin_inset Formula $\tilde{\phi}_{m}$
\end_inset

 eigenfunction of the adjoint operator and taking the inner product over
 
\begin_inset Formula $V$
\end_inset

 yields 
\begin_inset Formula 
\begin{align}
\dot{c}_{m}(t) & =\lambda_{m}c_{m}(t)+\epsilon(t)\sum_{n}c_{n}(t)(\tilde{\phi}_{m},L_{1}\phi_{n})
\end{align}

\end_inset

Using Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: L1"

\end_inset

, the inner product 
\begin_inset Formula $(\tilde{\phi}_{m},L_{1}\phi_{n}(V))$
\end_inset

 can be written as
\begin_inset Formula 
\begin{equation}
(\tilde{\phi}_{m},L_{1}\phi_{n}(V))=-G(\tilde{\phi}_{m},\phi_{n}')+H(\tilde{\phi}_{m},\phi''_{n}).
\end{equation}

\end_inset

We define the matrices 
\begin_inset Formula $\boldsymbol{G}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

 as 
\begin_inset Formula 
\begin{align}
G_{mn} & =G(\tilde{\phi}_{m},\phi_{n}'),\nonumber \\
H_{nm} & =H\left(\tilde{\phi}_{m},\phi''_{n}\right),\label{eq: G and H}
\end{align}

\end_inset

and arrive at a linear system of equations for the weighting coefficients
 
\begin_inset Formula $c_{n}(t)$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\frac{\partial\boldsymbol{c}(t)}{\partial t}=\boldsymbol{\Lambda}\boldsymbol{c}(t)+\epsilon(t)(-\boldsymbol{G}+\boldsymbol{H})\boldsymbol{c}(t),
\end{equation}

\end_inset

where 
\begin_inset Formula $\Lambda_{nm}=\lambda_{n}\delta_{nm}$
\end_inset

.
 The formal solution to this systems of equations is given by a matrix exponenti
al
\begin_inset Formula 
\begin{equation}
\boldsymbol{c}(t)=c_{0}\exp\left[(\boldsymbol{\Lambda}+\epsilon(t)\boldsymbol{A})t\right],
\end{equation}

\end_inset

where we defined the matrix 
\begin_inset Formula $\boldsymbol{A}$
\end_inset

 as
\begin_inset Formula 
\begin{equation}
\boldsymbol{A}=(-\boldsymbol{G}+\boldsymbol{H}).
\end{equation}

\end_inset

 Expanding the matrix exponential to arrive at expression for the weighting
 coefficients 
\begin_inset Formula $c(t)$
\end_inset

 which can be systematically expanded in orders of 
\begin_inset Formula $\epsilon(t)$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
c(t)=c_{0}\sum_{n=0}^{\infty}\frac{(\boldsymbol{\Lambda}t+\epsilon(t)\boldsymbol{A}t)^{n}}{n!}t^{n}=c_{0}\sum_{n=0}^{\infty}\frac{\boldsymbol{A}^{n}}{n!}t^{n}.
\end{equation}

\end_inset

To evaluate the matrix powers 
\begin_inset Formula $\boldsymbol{A}^{n}$
\end_inset

, we need to know 
\begin_inset Formula $\lambda_{n},\phi_{n}$
\end_inset

 and 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 so that we can compute matrix elements 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: G and H"

\end_inset

 of matrix 
\begin_inset Formula $\boldsymbol{G}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{H}$
\end_inset

.
\end_layout

\begin_layout Subsection
Finding eigenvalues and eigenfunctions numerically 
\end_layout

\begin_layout Standard
Our goal is to develop an algorithm which is capable of fining a sufficient
 number of eigenfunctions and eigenvalues of the dynamical operator introduced
 for a large class of integrate-and-fire neuron models.
 The algorithm should not require to much fine tuning for individual models.
 The latter part is important if we want to have any hope that it may be
 used by other researchers.
 We consider the following naive approach: First, solve the PDE 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: rho operator"

\end_inset

 numerically using Miind.
 We discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

 that the probability density function 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 can be decomposed into the contributions from individual modes.
 Hence.
 our goal is to reverse engineer the eigenfunctions and eigenvalues from
 the given solution for 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

.
 To do this we make use of the fact that the higher modes relax back to
 equilibrium on different time scales.
 If we order them from large to small time scales, i.e.
 from modes which decay slowly to modes which decay fast, then it may be
 possible to identify the first mode by looking at time window in which
 the system has almost relaxed back to equilibrium.
 In other words, we want to look at an time window in which only the zero
 and the first mode are active and all other modes are inactive.
 This would allow us to obtain an approximation for the first eigenfunction
 and the corresponding eigenvalue.
 After we know the first eigenvalue and eigenfunction, we can move on to
 the second eigenvalue and eigenfunction and so forth.
 Hence, it may be possible to find a sufficient number of eigenfunctions.
 Eigenvalues with larger imaginary part are associated with higher frequencies,
 i.e.
 if one is interested to track non-equilibrium dynamics on fast time scales,
 then it will presumably necessarily to include modes up to a high order
 in the expansion.
 
\end_layout

\begin_layout Standard
As a proof on principle, we want to test our proposed algorithm on the PIF
 and LIF neuron.
 Because the eigenfunctions and eigenvalues are known analytically for these
 models.
 Fig.
 shows the reconstruction of the first eigenfunction for PIF neuron and
 compares it the to theoretical prediction.
 Although, we can successfully approximate the first eigenfunction, we identifie
d difficulties with the proposed method.
 
\end_layout

\begin_layout Enumerate
The Fokker-Planck operator depends implicitly on time if the input is time
 dependent.
 This means that eigenfunctions and eigenvalues change with time.
 To use the method for time dependent input, we need to know how the eigenfuncti
ons change as a function of the input.
 A possible solution to this problem would be to determine the eigenfunctions
 and eigenvalues for a set of stationary inputs in a given range of interest.
 If we discretize the input range into a fine enough grid, then we may be
 able to approximate the derivative of the eigenfunctions with respect to
 the input using neighboring grid points.
 As soon as we know the solution for a specific input, could use the solution
 as an initial guess to find the eigenfunction for input not far away from
 the initial one.
 
\end_layout

\begin_layout Enumerate
It is not sufficient to know the eigenfunctions of the Fokker-Planck operator,
 but also the eigenfunctions of the adjoint operator.
 The adjoint eigenfunctions determine the initial values of the weighting
 coefficients in the spectral decomposition and they also appear in the
 solution for time dependent input.
 One possibility would be to run the simulation for a fixed input, but different
 initial conditions for the density.
 If the initial condition corresponds to a delta-distribution at a point
 in the state space of the neuron model, then the initial value of an arbitrary
 weighting coefficient is given by the value of the corresponding adjoint
 eigenfunction at this particular point.
 Suppose we would run a multitude of simulations.
 For each simulation the input is the same, but the initial value for density
 is given by a delta-distribution at different point in state space.
 If this set of points covers the entire state space, then it may be possible
 to obtain the adjoint eigenfunction.
 Note that this approach requires presumably a lot compute time if the state
 space of the neuron model is multidimensional.
 Note that spectra of an operator and its adjoint operator are identical.
 
\end_layout

\begin_layout Enumerate
Another problem is that the characteristic time scales on which neighboring
 modes decay become less and less distinguishable with increasing mode number.
 Hence, it will become increasingly harder to identify time windows in which
 only one of the active modes is unknown.
 
\end_layout

\begin_layout Standard
The above concerns motivate us to explore alternative methods for determining
 eigenfunctions and eigenvalues.
 In the diffusion approximation, the dynamical operator simplifies to a
 2nd order linear differential operator.
 There exists a lot of literature on how to numerically find eigenvalues
 and eigenfunctions for differential operators subject to BC.
 Finite difference methods and finite element methods 
\begin_inset CommandInset citation
LatexCommand cite
key "Li2017"

\end_inset

 approximate eigenvalue problems as a matrix equation in a discretized represent
ation of the state space.
 For an eigenvalue problem, BC usually incorporated into the subset of matrix
 elements which represent the boundaries of the state space.
 For our problem, one difficulty arises from the fact that the reset BC
 is quite exotic, and is therefore not treated in the standard literature.
 
\end_layout

\begin_layout Section
Outline 
\end_layout

\begin_layout Subsection
Short term objectives 
\end_layout

\begin_layout Subsubsection
Numerical stable implementation of the analytical results for the LIF neuron
 
\end_layout

\begin_layout Standard
We discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec: LIF"

\end_inset

 that numerical instabilities complicate finding solutions of the characteristic
 equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation"

\end_inset

 and implementing the eigenfunctions.
 Hence, we need to investigate the causes of the numerical problems and
 if they can be resolved.
 We are confident that a numerically stable implementation can be found
 since it has been demonstrated in 
\begin_inset CommandInset citation
LatexCommand cite
key "Deniz2017"

\end_inset

.
 If the problem is inherent to the behavior of the parabolic cylinder functions
 in the complex plane, then we can alternatively try to expand the eigenfunction
s in a basis spanned by linear combinations of confluent hypergeometric
 functions as it has been done in 
\begin_inset CommandInset citation
LatexCommand cite
key "Deniz2017"

\end_inset

.
\end_layout

\begin_layout Subsubsection
Transfer-function of the LIF neuron
\end_layout

\begin_layout Standard
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection
Eigenfunctions and eigenvalues of integrate-and-fire neurons
\end_layout

\begin_layout Standard
All the subsequent objectives depend on whether we are able to develop a
 numerical method which is capable of determining a sufficient set of eigenvalue
s and eigenfunctions of the dynamical operator 
\begin_inset Formula $Q$
\end_inset

 introduced in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

 with a satisfactory accuracy.
 Hence, this must be our main objective.
 
\end_layout

\begin_layout Standard
As already discussed, finite difference and finite element methods approximate
 eigenvalue problems by matrix equations in a discretized representation
 of the state space.
 Mixed finite element methods treat the density and probability current
 as two separated entities.
 This formulation seems to be especially suitable for incorporating the
 reset BC which is expressed in terms of probability currents 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: reset bc"

\end_inset

.
 Hence, as a starting point, we will try to recover a finite set of eigenvalues
 and eigenfunctions of the PIF and LIF neuron using a mixed finite element
 method.
 The results should converge to the analytical results in the limit of vanishing
 grid spacing.
 
\end_layout

\begin_layout Standard
If it turns out that finite element methods are not applicable to our problem,
 then we will examine the numerical method developed in 
\begin_inset CommandInset citation
LatexCommand cite
key "Richardson2007,Richardson2008"

\end_inset

 which can be used determine the stationary solution of Fokker-Planck equation
 numerically.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Ostojic2011"

\end_inset

 used the method to determine the eigenfunctions of the EIF neuron without
 reset mechanism.
 Although, we are interested in solving the problem including the reset
 mechanism, the initial method appears nevertheless promising.
 
\end_layout

\begin_layout Subsubsection
One dimensional neuron models
\end_layout

\begin_layout Standard
Assuming that we recovered the eigenfunctions of the PIF and LIF neuron,
 we want to apply our method to neuron models for which analytical results
 are lacking.
 It makes sense to first study the EIF and QIF neuron before moving to more
 complicated higher dimensional models.
 Hence, analytical expressions for eigenvalues and eigenfunctions are not
 known for these models, we need to find an alternative way validate our
 results.
 As discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

, expanding the density function in a finite set of eigenmodes allows us
 to solve the time dependent FP equation for arbitrary time dependent inputs
 from which we obtain the time dependent output firing rate of the neuron.
 The firing rate can be compared against the firing rate obtained from Miind
 and MC simulations which gives us a method of validation.
 
\end_layout

\begin_layout Subsubsection
Higher dimensional neuron models
\end_layout

\begin_layout Standard
If we want to use the method of spectral decomposition to efficiently model
 neuronal networks on the population level, then it is of utter importance
 to show that it is possible to determine eigenvalues and eigenfunctions
 of higher dimensional neuron models.
 For example, to model a recurrently connected EI-Network including finite
 synaptic timescales for the excitatory and inhibitory synapses three dimensions
 are needed to represent each population, namely the membrane potential,
 the excitatory synaptic current and the inhibitory synaptic current.
 
\end_layout

\begin_layout Standard
As an intermediate step, we start with two dimensional models.
 We started a collaboration with Maurizio Mattia to study the dynamical
 properties of adaptive neuron models.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Brette2005"

\end_inset

 demonstrated that the adaptive exponential integrate-and-fire neuron can
 accurately predict the spike trains of a detailed regular spiking neuron
 model driven by realistic conductance based synaptic inputs.
 As already discussed, 
\begin_inset CommandInset citation
LatexCommand cite
key "Biggio2017"

\end_inset

 presented a method to effectively reduce the dimensionality of the FP equation
 by expanding the solution in terms of eigenfunctions associated with the
 membrane potential while treating the second dynamic variable as a constant.
 Integrating the solutions over the different values for the second variable
 allows them to approximate the dynamical behavior of the inherently two
 dimensional problem.
 Although, this approach seems to be very promising, so far it is unclear
 under which conditions it is applicable.
 We believe that we can contribute to answering this question in two ways.
 Firstly, we can simulate two dimensional models with Miind and study the
 time evolution of the two dimensional density function and firing rates
 in full detail.
 Secondly, by providing a numerical approximation of the eigenvalues and
 eigenfunctions of the two dimensional system.
 
\end_layout

\begin_layout Subsubsection
Network implementation 
\end_layout

\begin_layout Standard
Assuming that the eigenvalues and eigenfunctions for We want to show that
 we can use it to efficiently simulate the population dynamics for a simple
 EI-Network as it has been studied e.g.
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Brunel2000"

\end_inset

.
 For a dynamical system, firing rates change in time which makes the dynamical
 operator 
\begin_inset Formula $Q$
\end_inset

 time dependent.
 We discussed in Sec.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Spectral-decomposition"

\end_inset

 that recurrent connections can be incorporated expressing the output firing
 rate of the populations in terms of eigenmodes.
 This equation needs to be solved together with system of equations for
 the weighting coefficients in a self consistent manner.
 Since 
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2004"

\end_inset

 simulated a EI-network of PIF neurons using the method of spectral decompositio
n, we are confident that network simulations are possible.
 However, weather they are more efficient is still a open question.
 
\end_layout

\begin_layout Subsection
Long term objectives 
\end_layout

\begin_layout Standard
There are two long term objective.
 Firstly, we want to show that expanding the neuron dynamics in terms of
 eigenmodes can facilitate efficient simulations of large scale neuronal
 networks on the population level.
 Secondly, we want to use the modal expansion to better understand dynamical
 properties of wide class of neuron models.
\end_layout

\begin_layout Subsubsection
Implementation eigenfunctions decomposition in Miind 
\end_layout

\begin_layout Standard
If it can be shown that simple networks can efficiently simulated in terms
 of eigenmodes for wide class of neuron models, then it makes sense to implement
 the method into the Miind simulator which is designed to model neuronal
 networks in terms of interacting populations.
 Starting with an EI-Network as an elementary building block, we could construct
 a simple model of a cortical column as it has been e.g.
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Potjans2012"

\end_inset

 where each cortical layer is represent by a EI-Network.
 Connecting multiple cortical columns Large brain areas can modeled by has
 been used to e.g.
 in 
\begin_inset CommandInset citation
LatexCommand cite
key "Schuecker2017"

\end_inset

 who modeled the visual cortex of macaque monkey.
 
\end_layout

\begin_layout Subsubsection
Establish mapping between spiking 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/gantt_chart.svg
	scale 50

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Gantt Chart: #1 Collaboration with  Maurizio Mattia on spectral theory of
 aEIF neurons, #2 Prepare Miind tutorial for Computational Neuroscience
 Meeting (CNS), #3 Implement finite element method, #4 Stabilize analytic
 implementation for LIF neuron, #5 Study spectral decomposition QIF and
 EIF , #6 Study spectral decomposition of two dimensional models, #7 Implement
 simple network simulation, #7 Implement method into Miind, #8 Implement
 large scale network
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Risk assessment
\end_layout

\begin_layout Section
Appendix
\end_layout

\begin_layout Subsection
Current-based synapses 
\end_layout

\begin_layout Standard
Current-based synapses are state do not depend on the state of the neuron,
 i.e.
 contributions from individual synapses superimpose linearly so that 
\begin_inset Formula $I_{\text{s}}(t)$
\end_inset

 can be written as 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
I_{\text{s}}(t)=\tau_{\text{m}}\sum_{j=1}^{K}I_{j}(t),\label{eq: synaptic current}
\end{equation}

\end_inset

where 
\begin_inset Formula $I_{j}(t)$
\end_inset

 is the synaptic current associated with the 
\begin_inset Formula $j$
\end_inset

th synapse.
 Synaptic currents have due to a spike arrival have typically a fast raise
 time followed by slower the decay time Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: current-based synapse"

\end_inset

.
 The time scale of the decay time depends on the receptor type of the synapse.
 Common receptors are 
\end_layout

\begin_layout Enumerate
AMPA receptors which have decay time constants of the order of 
\begin_inset Formula $2$
\end_inset

ms 
\begin_inset CommandInset citation
LatexCommand cite
key "Angulo1999"

\end_inset


\end_layout

\begin_layout Enumerate
GABA
\begin_inset Formula $_{\text{A}}$
\end_inset

 receptors which have decay time constants typically 
\begin_inset Formula $5$
\end_inset

-
\begin_inset Formula $10$
\end_inset

ms 
\begin_inset CommandInset citation
LatexCommand cite
key "Xiang1998"

\end_inset


\end_layout

\begin_layout Enumerate
NMDA which have time decay constants about 
\begin_inset Formula $100$
\end_inset

ms 
\begin_inset CommandInset citation
LatexCommand cite
key "Sah1990"

\end_inset


\end_layout

\begin_layout Standard
If the synaptic time constant is much smaller as the membrane time constant,
 then the simplest approximation is to assume that synaptic currents are
 instantaneous (delta-synapses)
\begin_inset Formula 
\begin{equation}
I_{j}(t)=\tau_{\text{m}}J_{j}\sum_{n}\delta(t-t_{n}^{(j)}),\label{eq: delta synapse}
\end{equation}

\end_inset

where 
\begin_inset Formula $J_{i}$
\end_inset

 is the synaptic efficacy of the respective synapse in mV.
 For delta-synapses, the membrane potential makes a jump by 
\begin_inset Formula $J_{i}$
\end_inset

 at each spike arrival followed by an exponential decay.
 If the raise time of the synapse is much faster compared to its decay time,
 then the synaptic current can be approximated as a jump exponential decay
 
\begin_inset Formula 
\begin{equation}
\tau_{\text{s}}\frac{d}{dt}I_{j}(t)=-I_{j}(t)+\tau_{\text{m}}J_{j}\sum_{n}\delta(t-t_{n}^{()}),\label{eq: exponential synapse}
\end{equation}

\end_inset

where 
\begin_inset Formula $\tau_{\text{s}}$
\end_inset

 synaptic time constant.
 At each spike arrival, 
\begin_inset Formula $I_{i}(t)$
\end_inset

 makes a jump by 
\begin_inset Formula $J_{i}$
\end_inset

 followed by an exponential decay back to zero which is illustrated by the
 blue curve in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: current-based synapse"

\end_inset

.
 A synaptic raise time can be included by modeling 
\begin_inset Formula $I_{i}(t)$
\end_inset

 by the set of equations 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud2002"

\end_inset


\begin_inset Formula 
\begin{align}
\tau_{\text{s}}\frac{dI_{\text{s}}}{dt} & =-I_{\text{s}}(t)+I_{\text{r}}(t)\nonumber \\
\tau_{\text{r}}\frac{dI_{\text{r}}}{dt} & =-I_{\text{r}}(t)+\tau_{\text{m}}J_{i}\sum_{n}\delta(t-t_{n}^{(i)}).\label{eq: synaptic current raise}
\end{align}

\end_inset

The synaptic value for different ratios 
\begin_inset Formula $\tau_{\text{r}}$
\end_inset

 is shown in Fig.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig: current-based synapse"

\end_inset

.
 
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename figures/current_based_synapse.png

\end_inset


\begin_inset Caption Standard

\begin_layout Plain Layout
Synaptic current (Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: synaptic current raise"

\end_inset

) caused by single spike arrival for 
\begin_inset Formula $\tau_{\text{s}}=2.0$
\end_inset

 ms and different values for 
\begin_inset Formula $\tau_{\text{r}}=[0,\,0.5,\,1.0,\,2.0]$
\end_inset

.
 Note that for 
\begin_inset Formula $\tau_{\text{r}}=0$
\end_inset

, we recover Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: exponential synapse"

\end_inset

.
 
\begin_inset CommandInset label
LatexCommand label
name "fig: current-based synapse"

\end_inset

 
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
\begin_inset CommandInset bibtex
LatexCommand bibtex
bibfiles "transfer_report"
options "plain"

\end_inset


\end_layout

\begin_layout Subsection
Solving the Fokker-Planck equation 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Solving-the-Fokker-Planck"

\end_inset


\end_layout

\begin_layout Subsubsection
Stationary case 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Stationary-case"

\end_inset


\end_layout

\begin_layout Standard
To determine points of stationary activity 
\begin_inset Formula $r(t)=r_{0}$
\end_inset

, one needs to find the stationary solution of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE continuity"

\end_inset


\begin_inset Formula 
\begin{equation}
0=-\frac{\partial}{\partial V}J(V,t).
\end{equation}

\end_inset

The above equation tells us that the flux must be constant.
 From left BC follows 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: left bc"

\end_inset

 that 
\begin_inset Formula $J(V,t)$
\end_inset

 must be zero for 
\begin_inset Formula $V\rightarrow-\infty$
\end_inset

.
 From 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: reset bc"

\end_inset

 that the flux must be equivalent to the rate 
\begin_inset Formula $r_{0}$
\end_inset

 at threshold.
 Hence, 
\begin_inset Formula $J(V,t)$
\end_inset

 is 
\begin_inset Formula $0$
\end_inset

 from 
\begin_inset Formula $V<V_{r}$
\end_inset

 and makes a jump to 
\begin_inset Formula $r$
\end_inset

 at the reset the 
\begin_inset Formula $V_{r}$
\end_inset

 which we can write as
\begin_inset Formula 
\[
J(V,t)=r\Theta(V-V_{\text{th}})\Theta(V-V_{\text{r}}).
\]

\end_inset

Substituting 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE flux"

\end_inset

 into yields the stationary density 
\begin_inset Formula $\rho_{0}(V)$
\end_inset

 from which the stationary firing rate as it has been in 
\begin_inset CommandInset citation
LatexCommand cite
key "Amit1997"

\end_inset


\begin_inset Formula 
\begin{align}
r & =\Phi(\mu,\sigma^{2})\label{eq: rate}
\end{align}

\end_inset

where 
\begin_inset Formula $\Phi(\mu,\sigma^{2})$
\end_inset

 given by
\begin_inset Formula 
\begin{equation}
\Phi(\mu,\sigma^{2})=\frac{1}{\tau_{\text{m}}\sqrt{\pi}}\int_{\frac{V_{\text{r}}-\mu}{\sigma}}^{\frac{V_{\text{th}}-\mu}{\sigma}}(1+\text{erf}(x))e^{x^{2}}dx.
\end{equation}

\end_inset

It is crucial to notice that 
\begin_inset Formula $\mu$
\end_inset

 and 
\begin_inset Formula $\sigma^{2}$
\end_inset

 both depend on the firing themselves.
 Hence, we need to find self-consistent solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: rate"

\end_inset

.
 So far we only considered a single population network.
 In network with multiple populations 
\begin_inset Formula $\boldsymbol{\alpha}=\{1,2,\ldots,M\}$
\end_inset

, mean an variance are given by 
\begin_inset Formula 
\begin{align}
\mu_{\alpha}(\boldsymbol{r}) & =\tau_{\text{m}}\sum_{\beta}K_{\alpha\beta}J_{\alpha\beta}r_{\beta}+\mu_{\text{ext}},\label{eq: mu multi}\\
\sigma_{a}^{2}(\boldsymbol{r}) & =\tau_{\text{m}}\sum_{\beta}K_{\alpha\beta}J_{\alpha\beta}r_{\beta}+\sigma_{\text{ext}}^{2},\label{eq: sigma multi}
\end{align}

\end_inset

where 
\begin_inset Formula $\boldsymbol{r}=(r_{1},\ldots,r_{M})$
\end_inset

.
 The firing rate of population 
\begin_inset Formula $\alpha$
\end_inset

 is given by 
\begin_inset Formula 
\[
r_{\alpha}(\boldsymbol{r})=\Phi(\mu_{\alpha}(\boldsymbol{r}),\sigma_{\alpha}^{2}(\boldsymbol{r}))=\frac{1}{\tau_{\text{m}}\sqrt{\pi}}\int_{\frac{V_{\text{r}}-\mu_{\alpha}}{\sigma_{\alpha}}}^{\frac{V_{\text{th}}-\mu_{\alpha}}{\sigma_{\alpha}}}(1+\text{erf}(x))e^{x^{2}}dx,
\]

\end_inset

where 
\begin_inset Formula $\mu_{\alpha}$
\end_inset

 and 
\begin_inset Formula $\sigma_{\alpha}$
\end_inset

 depend on 
\begin_inset Formula $\boldsymbol{r}=\{r_{1},r_{2},\ldots,r_{M})$
\end_inset

 which can be seen from Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: mu multi"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: sigma multi"

\end_inset

.
 To find stationary states of the network, we need to find values for the
 vector 
\begin_inset Formula $\boldsymbol{r}$
\end_inset

 which solve the set of 
\begin_inset Formula $M$
\end_inset

 equations in a self-consistent manner.
 
\end_layout

\begin_layout Standard
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 used the diffusion approximation to derive the stationary average rates
 in a recurrently randomly connected network of LIF neurons, mimicking a
 cortical column.
 The network in the study consists of an excitatory and inhibitory population
 (EI-Network).
 The populations receive additional uncorrelated stationary excitatory input
 from the external surrounding of the network.
 This external input represents the global spontaneous ongoing activity
 observed in cortex which has typically low firing rates 
\begin_inset Formula $1$
\end_inset

-
\begin_inset Formula $5$
\end_inset

 Hz.
 The purely excitatory external input is motivated by the fact that excitatory
 pyramidal neurons tend to form longer axons compared to inhibitory neurons
 which connect more locally 
\begin_inset CommandInset citation
LatexCommand citep
key "Braitenberg2013"

\end_inset

.
 The stationary solution of the Fokker-Planck equation yields the stationary
 firing rate of the excitatory and inhibitory population for a given input
 rate 
\begin_inset CommandInset citation
LatexCommand citep
key "A.1953"

\end_inset

.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 showed that the equation for the stationary firing rage has a solution
 for which the average firing rate of the excitatory population matches
 the spontaneous activity of the external surrounding.
 This is desirable because the excitatory population is the external surrounding
 from the perspective of the neighboring cortical columns.
 Finding the solution for the output firing rate of a population which reproduce
s the initial input firing rate is often referred to as self-consistent
 mean-field theory 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

.
 Spontaneous activity is hypothesized to be a ground state of the brain.
 Compared to silent networks, a spontaneous active network has the advantage
 that it places neurons close to the threshold, rather at their resting
 potential so that the network can respond faster to a stimulus.
\end_layout

\begin_layout Subsubsection
Time dependent case 
\end_layout

\begin_layout Standard
Solving the time dependent Fokker-Planck equation is a difficult task.
 The stability of the stationary state presented in 
\begin_inset CommandInset citation
LatexCommand citep
key "Amit1997"

\end_inset

 has been studied extensively in 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000,Brunel1999,Lindner2001"

\end_inset

.
 If the temporal modulation of the firing rate is small compare to its stationar
y baseline 
\begin_inset Formula 
\begin{equation}
r(t)=r+\delta r(t),
\end{equation}

\end_inset

with 
\begin_inset Formula $\bigl|\delta r(t)\bigr|\ll r$
\end_inset

, then perturbation theory 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 applicable.
 The mean 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: mu"

\end_inset

 and variance 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: sig"

\end_inset

 of the Gaussian white noise can be split into a constant and time dependent
 part 
\begin_inset Formula 
\begin{align}
\mu(t) & =\mu+\delta\mu(t)\\
\sigma^{2}(t) & =\sigma^{2}+\delta\sigma^{2}(t)
\end{align}

\end_inset

and Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE continuity"

\end_inset

 becomes
\begin_inset Formula 
\begin{align}
\frac{\partial\rho(V,t)}{\partial t} & =\left(-\frac{\partial}{\partial V}\frac{\mu+f(V)}{\tau_{\text{m}}}+\frac{\sigma^{2}}{2\tau_{\text{m}}}\frac{\partial^{2}}{\partial V^{2}}\right)\rho(V,t)+\left(-\delta\mu(t)\frac{\partial}{\partial V}+\frac{\delta\sigma^{2}(t)}{2}\frac{\partial^{2}}{\partial V^{2}}\right)\rho(V,t)\label{eq: FPE time dependent-3}
\end{align}

\end_inset

Note that 
\begin_inset Formula $\delta\mu(t)$
\end_inset

 and 
\begin_inset Formula $\delta\sigma(t)$
\end_inset

 both depend implicitly one time through 
\begin_inset Formula $\delta r(t)$
\end_inset

.
 We define the relative rate modulation 
\begin_inset Formula $\epsilon(t)=\delta r(t)/r$
\end_inset

 as a small parameter Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE time dependent-3"

\end_inset

 can be written
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(V,t)}{\partial t}=L_{0}\rho(V,t)+\epsilon(t)L_{1}\rho(V,t)\label{eq: FPE time dependent}
\end{equation}

\end_inset

The above equations has been be solved to first order in 
\begin_inset Formula $\epsilon(t)$
\end_inset

 in 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 using the following steps.
 Expand the 
\begin_inset Formula $\rho(V,t)$
\end_inset

 around the stationary solution derived in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Stationary-case"

\end_inset

 
\begin_inset Formula 
\begin{equation}
\rho(V,t)=\rho_{0}(V)+\rho_{1}(V,t)+\rho_{2}(V,t)+\ldots
\end{equation}

\end_inset

with 
\begin_inset Formula $\rho_{n}(V,t)\sim\mathcal{O}(\epsilon(t)^{n})$
\end_inset

.
 Substituting into Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE time dependent"

\end_inset

 and keeping only those terms up to first order in 
\begin_inset Formula $\epsilon(t)$
\end_inset

 yields 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho_{1}(V,t)}{\partial t}=L_{0}\rho_{1}(V,t)+\epsilon(t)L_{1}\rho_{0}(V)+\mathcal{O}(\epsilon)\label{eq: FPE time dependent-1}
\end{equation}

\end_inset

where we used that 
\begin_inset Formula $\rho_{0}(V)$
\end_inset

 is time independent and 
\begin_inset Formula $L_{0}\rho(V)=0$
\end_inset

.
 The above equation is a first order inhomogeneous partial differential
 equation for 
\begin_inset Formula $\rho_{1}(V,t)$
\end_inset

.
 It is sufficient to consider only sinusoidal modulations, because we can
 Fourier transform 
\begin_inset Formula $\epsilon(t)$
\end_inset


\begin_inset Formula 
\[
\epsilon(t)=\frac{1}{2\pi}\int_{-\infty}^{\infty}d\omega\,\epsilon(\omega)e^{i\omega t}
\]

\end_inset

and solve each frequency component separately due to the linearity of the
 problem.
 Hence, we make a complex ansatz 
\begin_inset Formula 
\[
\epsilon(t)=\epsilon(\omega)e^{i\omega t}
\]

\end_inset

 Substituting into 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE time dependent-1"

\end_inset

 and using separation of variables 
\begin_inset Formula $\rho_{1}(V,t)=\rho_{1}(V)e^{i\omega t}$
\end_inset

 yields a inhomogeneous linear ordinary differential equation for 
\begin_inset Formula $\rho_{1}(V)$
\end_inset


\begin_inset Formula 
\begin{equation}
\left(i\omega-L_{0}\right)\rho_{1}(V,t)=L_{1}\rho_{0}(V).\label{eq: FPE time dependent-2}
\end{equation}

\end_inset

The solution of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: FPE time dependent-2"

\end_inset

 is given by the homogeneous solution plus the particular solution which
 reproduces the inhomogeneity on the r.h.s.
 The free coefficients in the homogeneous solution need to be determined
 such that the sum of the homogeneous and the particular solution fulfill
 the boundary conditions which we discussed in 
\begin_inset CommandInset ref
LatexCommand ref
reference "subsec:Boundary-conditions"

\end_inset

.
 Skipping the details of calculation, 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 derived the transfer function 
\begin_inset Formula $T(\omega)$
\end_inset

 which determines how a frequency component 
\begin_inset Formula $\epsilon(\omega)$
\end_inset

 on the input side is changed on the output side 
\begin_inset Formula $\overline{\epsilon}(\omega)$
\end_inset

 
\begin_inset Formula 
\begin{equation}
\overline{\epsilon}(\omega)=T(\omega)\epsilon(\omega).\label{eq: transfer function}
\end{equation}

\end_inset

Taking the Fourier back transform of the above equation shows that the neurons
 acts as a linear filter in first order approximation 
\begin_inset Formula 
\begin{equation}
\overline{r}(t)=\Phi(r)+r\int_{-\infty}^{t}T(t)\epsilon(t),
\end{equation}

\end_inset

where the kernel 
\begin_inset Formula $T(t)$
\end_inset

 is Fourier back transform of transfer function 
\begin_inset Formula $T(\omega)$
\end_inset

.
 The gain of response is related to the modulus 
\begin_inset Formula $\left|T(\omega)\right|$
\end_inset

 and the phase shift to the argument 
\begin_inset Formula $\arg[T(\omega)]$
\end_inset

 .
 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 showed that the self-consistent solutions of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: transfer function"

\end_inset

  mark that the points where the stationary state loses stability and network
 network transitions into a regime which can sustain global oscillations.
 Depending on the strength of the external input, the balance between excitation
 and inhibition, and the time scale of the synaptic delay, the average firing
 rate of the populations can show oscillations in different frequency regimes.
 Independently of the global oscillations, the firing of individual neurons
 are still highly irregular.
 The work by 
\begin_inset CommandInset citation
LatexCommand citep
key "Brunel2000"

\end_inset

 has been the first analytical study investigating the synchronization propertie
s of randomly connected recurrent spiking neural networks.
 
\end_layout

\begin_layout Standard
The transfer function 
\begin_inset Formula $T(\omega)$
\end_inset

 for LIF neuron behaves like a low-pass filter dropping of with 
\begin_inset Formula $1/\sqrt{\omega}$
\end_inset

 in the high frequency limit.
 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 studied the frequency response for nonlinear integrate-and-fire neurons
 and showed that EIF acts as a filter with constant gain in the low and
 intermediate frequency range followed by a 
\begin_inset Formula $1/\omega$
\end_inset

 drop off in high frequency limit.
 These results hold for current-based as well as conductance-based synapses,
 because the spike-generating currents dominate the neuronal dynamics and
 the synaptic input has little effect on what happens after spike initiation.
 Replacing the delta-synapses by synapses with finite synaptic time scale
 introduces temporal correlations into the input noise which decay on the
 order the synaptic time scale.
 The temporal correlations can be effectively modeled by replacing the Gaussian
 white noise in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: integrate-and-fire diffusion approx"

\end_inset

 by colored noise 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud2002"

\end_inset

 with a auto-correlation function which decays exponentially on the same
 time scale as the synapse.
 Using numerical simulations, 
\begin_inset CommandInset citation
LatexCommand cite
key "Fourcaud-Trocme2003"

\end_inset

 showed that the filtering properties of the EIF are in good agreement with
 those of more realistic H-H type models used in 
\begin_inset CommandInset citation
LatexCommand cite
key "Hansel2002"

\end_inset

.
 
\end_layout

\begin_layout Standard
Knowing how the filtering properties of spiking neuronal model can be used
 to map spiking neuron models to rate based models as it has been done in
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
TODO
\end_layout

\end_inset

.
 All the presented studies are only leading order results which are only
 valid if the temporal modulation are small.
 Since the derivation for LIF neuron are already quite involved, it seems
 to likely that extending the results to more complex neuron models and
 higher orders requires a combination of analytical and numerical tools.
 
\begin_inset CommandInset citation
LatexCommand citep
key "Deniz2017"

\end_inset

 recently solved the stationary FPE for the LIF neuron for arbitrary input
 correlations using the method of spectral decomposition.
 They showed that their method can be related to arbitrary orders of the
 perturbative approach used in 
\begin_inset CommandInset citation
LatexCommand citep
key "Lindner2001"

\end_inset

 who assumed small small correlations.
 The method of spectral decomposition expands the density function in terms
 of the eigenfunctions of the differential operator which describes its
 time evolution.
 It has been first introduced in the context of PDM by 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

.
\end_layout

\begin_layout Subsection
Spectral decomposition 
\begin_inset CommandInset label
LatexCommand label
name "subsec:Spectral-decomposition-1"

\end_inset


\end_layout

\begin_layout Standard
We equip the state space with an inner product given by the bilinear integral
 
\begin_inset Formula 
\begin{equation}
(\tilde{\phi},\phi)=\int d\boldsymbol{v}\,\tilde{\phi}(\boldsymbol{v})\phi(\boldsymbol{v}).\label{eq: inner product}
\end{equation}

\end_inset

For a given inner product, the adjoint operator 
\begin_inset Formula $Q^{\dagger}$
\end_inset

 of 
\begin_inset Formula $Q$
\end_inset

 is defined by the equation 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
(\tilde{\phi},Q\phi)=(Q^{\dagger}\tilde{\phi},\phi).\label{eq: Q adjoint}
\end{equation}

\end_inset

The eigenfunctions 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 of the adjoint operator 
\begin_inset Formula $O^{\dagger}$
\end_inset

 are given by 
\begin_inset Formula 
\begin{equation}
Q^{\dagger}\tilde{\phi}_{n}(\boldsymbol{v})=\tilde{\lambda}_{n}\tilde{\phi}_{n}(\boldsymbol{v}).
\end{equation}

\end_inset

The boundary conditions for eigenfunctions 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 must be chosen such the surface terms in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: Q adjoint"

\end_inset

 vanish.
 We use that eigenvalues of an operator and its adjoint operator are equivalent
 
\begin_inset Formula $\tilde{\lambda}_{n}=\lambda_{n}$
\end_inset

 and write 
\begin_inset Formula 
\[
\lambda_{n}(\tilde{\phi}_{m},\tilde{\phi}_{n})=(\tilde{\phi}_{m},Q\tilde{\phi}_{n})=(Q^{\dagger}\tilde{\phi}_{m},\tilde{\phi}_{n})=\lambda_{m}(\tilde{\phi}_{m},\tilde{\phi}_{n}),
\]

\end_inset

where we used Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: Q adjoint"

\end_inset

 in the third step.
 Subtracting the r.h.s.
 from the from the l.h.s.
 yields 
\begin_inset Formula 
\[
(\lambda_{n}-\lambda_{m})(\tilde{\phi}_{m},\tilde{\phi}_{n})=0
\]

\end_inset

Since one or the other factor must vanish, we find that set the eigenfunctions
 of 
\begin_inset Formula $Q$
\end_inset

 and 
\begin_inset Formula $Q^{\dagger}$
\end_inset

 are orthogonal for 
\begin_inset Formula $n\neq m$
\end_inset

.
 Using proper normalization, we can write 
\begin_inset Formula 
\begin{equation}
(\tilde{\phi}_{m},\phi_{n})=\delta_{nm}\label{eq: orthogonality}
\end{equation}

\end_inset

Hence, the set of eigenfunctions 
\begin_inset Formula $\{\tilde{\phi}_{n}(\boldsymbol{v}),\phi_{n}(\boldsymbol{v})\}$
\end_inset

 form a biorthonormal set.
 Some remarks on the properties of spectrum of 
\begin_inset Formula $Q$
\end_inset

 derived in 
\begin_inset CommandInset citation
LatexCommand cite
key "Knight2000a"

\end_inset

: 
\end_layout

\begin_layout Enumerate
The real part of all eigenvalues is negative 
\begin_inset Formula $\text{Re}(\lambda_{n})\leq0$
\end_inset

 
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\lambda_{0}=0$
\end_inset

 is a eigenvalue of 
\begin_inset Formula $Q$
\end_inset

 and the associated eigenfunction 
\begin_inset Formula $\phi_{0}(\boldsymbol{v})$
\end_inset

 is the stationary solution 
\begin_inset Formula $Q(\boldsymbol{v},r)\rho_{0}(\boldsymbol{v})=0$
\end_inset


\end_layout

\begin_layout Enumerate
The corresponding eigenfunction 
\begin_inset Formula $\tilde{\phi}_{0}(\boldsymbol{v})$
\end_inset

 is constant which can be set to 
\begin_inset Formula $1$
\end_inset

 such that 
\begin_inset Formula $(\tilde{\phi}_{0}(\boldsymbol{v}),\phi_{0}(\boldsymbol{v}))=\int d\boldsymbol{v}\,\rho_{0}(\boldsymbol{v})=1$
\end_inset

 
\end_layout

\begin_layout Enumerate
From 
\begin_inset Formula $(\tilde{\phi}_{0}(\boldsymbol{v}),\phi_{n}(\boldsymbol{v}))=0$
\end_inset

 follows 
\begin_inset Formula $0=\int d\boldsymbol{v}\phi_{n}(\boldsymbol{v})$
\end_inset

, i.e.
 all probability is contained in the zero mode 
\begin_inset Formula $\phi_{0}(\boldsymbol{v})=\rho_{0}(\boldsymbol{v})$
\end_inset

 
\end_layout

\begin_layout Standard
We are now ready, to determine the time evolution of the weighting coefficients
 for a given initial condition 
\begin_inset Formula $\rho(\boldsymbol{v},0)=f(\boldsymbol{v})$
\end_inset

.
 We start with simplest example, a population of non-interacting neurons.
 
\end_layout

\begin_layout Subsubsection
Non-interacting neurons stationary input rate 
\end_layout

\begin_layout Standard
By non-interacting, we mean that all recurrent connections cut and all neurons
 receive the same constant external input 
\begin_inset Formula $r_{\text{ext}}=r$
\end_inset

.
 We start from Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: rho operator"

\end_inset


\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=Q(\boldsymbol{v},r)\rho(\boldsymbol{v},t).
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: eigenfunction expansion"

\end_inset

 for 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 on both sides yields 
\begin_inset Formula 
\begin{equation}
\sum_{m=-\infty}^{\infty}\left(\frac{\partial}{\partial t}c_{m}(t)\right)\phi_{m}(\boldsymbol{v})=\sum_{m=-\infty}^{\infty}c_{m}(t)\lambda_{m}\phi_{m}(\boldsymbol{v})
\end{equation}

\end_inset

Note that eigenvalues and eigenfunctions are both time independent because
 
\begin_inset Formula $r$
\end_inset

 is constant.
 Multiplying with 
\begin_inset Formula $\tilde{\phi}_{n}(\boldsymbol{v})$
\end_inset

 from the l.h.s.
 and integrating over the state space yields 
\begin_inset Formula 
\begin{align}
\sum_{m=-\infty}^{\infty}\left(\frac{\partial}{\partial t}c_{m}(t)\right)(\tilde{\phi}_{n},\phi_{m}) & =\sum_{m=-\infty}^{\infty}\lambda_{m}(\phi_{n},\tilde{\phi}_{m})
\end{align}

\end_inset

Using orthogonality 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: orthogonality"

\end_inset

, we arrive at 
\begin_inset Formula 
\begin{equation}
\frac{\partial}{\partial t}c_{n}(t)=\lambda_{m}.
\end{equation}

\end_inset

Hence, we find that 
\begin_inset Formula $c_{n}(t)$
\end_inset

 is given by 
\begin_inset Formula 
\begin{equation}
c_{n}(t)=c_{n}(0)e^{\lambda_{n}t}\label{eq: c_n(t)}
\end{equation}

\end_inset

The initial value 
\begin_inset Formula $c_{n}(0)$
\end_inset

 can be determined from initial condition 
\begin_inset Formula $\rho(\boldsymbol{v},0)=f(\boldsymbol{v})$
\end_inset

 
\begin_inset Formula 
\begin{equation}
c_{n}(0)=(\tilde{\phi},f(\boldsymbol{v})).
\end{equation}

\end_inset

From 
\begin_inset Formula $\text{Re}(\lambda_{n})<0$
\end_inset

 follows that all 
\begin_inset Formula ${\displaystyle \lim_{t\rightarrow\infty}}c_{n}(t)=0$
\end_inset

 expect for 
\begin_inset Formula $c_{0}(t)=1$
\end_inset

.
 Hence, all modes, except for zero mode, die out over time and 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 converges to 
\begin_inset Formula $\phi_{0}(\boldsymbol{v})=\rho_{0}(\boldsymbol{v}).$
\end_inset

 The the time of the exponential decay 
\begin_inset Formula $\tau_{n}$
\end_inset

 is given by 
\begin_inset Formula $\tau_{n}=1/\left|\text{Re}(\lambda_{1})\right|$
\end_inset

.
 Hence, it males sense to order the modes according to the magnitude of
 the real part of their associated eigenvalues 
\begin_inset Formula 
\[
0\leq\left|\text{Re}(\lambda_{1})\right|\leq\left|\text{Re}(\lambda_{2})\right|\leq\left|\text{Re}(\lambda_{3})\right|\leq\ldots
\]

\end_inset

The natural next step is consider a population of non-interacting neurons
 which receives a time dependent external input.
\end_layout

\begin_layout Subsubsection
Non-interacting neurons with time dependent input 
\end_layout

\begin_layout Standard
If the external rate is time dependent 
\begin_inset Formula $r_{\text{ext}}(t)=r(t)$
\end_inset

, then eigenvalues and eigenvectors will be time dependent.
 We start again from Eq.
 
\begin_inset Formula 
\begin{equation}
\frac{\partial\rho(\boldsymbol{v},t)}{\partial t}=Q(\boldsymbol{v},r(t))\rho(\boldsymbol{v},t)
\end{equation}

\end_inset

Substituting 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: eigenfunction expansion"

\end_inset

 for 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 yields 
\begin_inset Formula 
\begin{align*}
\sum_{m}\frac{\partial}{\partial t}\left(c_{m}(t)\phi_{m}(\boldsymbol{v},t)\right) & =\sum_{m}\lambda_{m}c_{m}(t)\phi_{m}(\boldsymbol{v},t),\\
\sum_{m}\left\{ \frac{\partial c_{m}(t)}{\partial t}\phi_{m}(\boldsymbol{v},t)+c_{m}(t)\frac{\partial\phi_{m}(\boldsymbol{v},t)}{\partial r}\frac{\partial r(t)}{\partial t}\right\}  & =\sum_{m}\lambda_{m}c_{m}(t)\phi_{m}(\boldsymbol{v},t),
\end{align*}

\end_inset

where we used the chain rule for second term on the l.h.s.
 Multiplying from the left with 
\begin_inset Formula $\tilde{\phi}_{n}(\boldsymbol{v},t)$
\end_inset

 and integrating over the state space yields 
\begin_inset Formula 
\begin{align*}
\sum_{m}\left\{ \frac{\partial c_{m}(t)}{\partial t}(\tilde{\phi}_{n},\phi_{m})+c_{m}(t)\frac{\partial r(t)}{\partial t}(\tilde{\phi}_{n},\frac{\partial\phi_{m}}{\partial r})\right\}  & =\sum_{m}\lambda_{m}(\tilde{\phi}_{n}(\boldsymbol{v},t),\phi_{m}(\boldsymbol{v},t))\\
\frac{\partial c_{m}(t)}{\partial t}+\frac{\partial r(t)}{\partial t}(\tilde{\phi}_{n},\frac{\partial\phi_{m}}{\partial r})c_{m}(t) & =\lambda_{m}c_{m}(t)
\end{align*}

\end_inset

Following 
\begin_inset CommandInset citation
LatexCommand cite
key "Mattia2002"

\end_inset

, defining the matrix 
\begin_inset Formula $A_{mn}=(\tilde{\phi}_{n},\frac{\partial\phi_{m}}{\partial r})$
\end_inset

, the above equation can be written as matrix equation 
\begin_inset Formula 
\[
\frac{\partial\boldsymbol{c}}{\partial t}=\left(\boldsymbol{\Lambda}-\frac{\partial r(t)}{\partial t}\boldsymbol{A}_{mn}\right)\boldsymbol{c}
\]

\end_inset

Note that matrix 
\begin_inset Formula $\boldsymbol{A}_{nm}$
\end_inset

 and 
\begin_inset Formula $\boldsymbol{\Lambda}$
\end_inset

 both depend on time.
 
\end_layout

\begin_layout Subsubsection
Interacting-neurons with time dependent input 
\end_layout

\begin_layout Standard
To include the interaction, we need to incoporate the firing rate 
\begin_inset Formula 
\[
r(t)=R[\boldsymbol{J}(\boldsymbol{v},t)]
\]

\end_inset

where is given by a linear operator 
\begin_inset Formula 
\[
J(\boldsymbol{v},t)=C\rho(\boldsymbol{v},t)
\]

\end_inset

Expanding 
\begin_inset Formula $\rho(\boldsymbol{v},t)$
\end_inset

 in terms of the eigenfunctions expresses 
\begin_inset Formula $r(t)$
\end_inset

 in terms of the eigenfunctions, and therefore in terms of the weighting
 coefficients 
\begin_inset Formula $\boldsymbol{c}$
\end_inset

.
 Hence, the set of equations need to be solved self-consistently 
\begin_inset Formula 
\begin{align*}
\frac{\partial\boldsymbol{c}}{\partial t} & =\left(\boldsymbol{\Lambda}-\frac{\partial r(t)}{\partial t}\boldsymbol{A}\right)\boldsymbol{c}\\
r(t) & =\sum_{n}R\left[C\left(c_{n}(t)\phi_{n}(\boldsymbol{v},t)\right)\right]
\end{align*}

\end_inset

For a general leaky integrate-and-fire model in diffusion approximation,
 the rate equation simplifies to 
\begin_inset Formula 
\[
r(t)=-\frac{1}{2}\sum_{n}\sigma^{2}(t)c_{n}(t)\left.\partial_{V}\phi_{n}(V,t)\right|_{V=\theta}.
\]

\end_inset

which can be written as 
\begin_inset Formula 
\[
r(t)=\boldsymbol{f}\boldsymbol{c}
\]

\end_inset

with 
\begin_inset Formula $f_{n}=-\frac{1}{2}\sigma^{2}(t)c_{n}(t)$
\end_inset

.
 
\end_layout

\begin_layout Subsection
Spectrum and eigenfunctions of the leaky integrate-and-fire neuron 
\begin_inset CommandInset label
LatexCommand label
name "subsec: ef LIF"

\end_inset


\end_layout

\begin_layout Standard
Starting from Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: Fokker-Planck"

\end_inset

 and setting 
\begin_inset Formula $\psi(V)=0$
\end_inset

 in Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: Fokker-Planck operator"

\end_inset

, we obtain the Fokker-Planck equation for the LIF neuron 
\begin_inset Formula 
\begin{equation}
\partial_{t}\rho(V,t)=L\rho(V,t),\quad L=\partial_{V}\left(\frac{1}{\tau}\left(V-\mu\right)+\frac{\sigma^{2}}{2\tau}\partial_{V}\right)\label{eq: LIF Fokker-Planck}
\end{equation}

\end_inset

If a neuron reaches the threshold value 
\begin_inset Formula $V_{\text{th}}$
\end_inset

 it gets reset to the reset potential 
\begin_inset Formula $V_{\text{r}}$
\end_inset

.
 The Fokker-Planck operator can be brought into a more simpler form by making
 the variable transformation
\begin_inset Formula 
\begin{equation}
s=\frac{t}{\tau},\quad x=\frac{\sqrt{2}}{\sigma}(V-\mu).
\end{equation}

\end_inset

We use
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\partial_{t}\rho & =\frac{1}{\tau}\rho_{s}\nonumber \\
\partial_{V}\rho & =\frac{\sqrt{2}}{\sigma}\partial_{x}\rho\nonumber \\
\partial_{V}^{2}\rho & =\frac{2}{\sigma^{2}}\partial_{x}^{2}\rho,
\end{align}

\end_inset

and Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF Fokker-Planck"

\end_inset

 becomes
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
\partial_{s}\rho(x,s)=L\rho(x,s),\quad L=\partial_{x}\left(x+\partial_{x}\right).\label{eq: LIF Fokker-Planck x}
\end{equation}

\end_inset

We rewrite Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF Fokker-Planck x"

\end_inset

 as a continuity equation 
\begin_inset Formula 
\begin{equation}
\partial_{s}\rho(x,s)=-\partial_{x}J(x,s).
\end{equation}

\end_inset

The probability current 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: Probability current"

\end_inset

 in the new coordinates reads
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
J(x,s)=-\left(x+\partial_{x}\right)\rho(x,s)
\end{equation}

\end_inset

The reset mechanism we described before gives rise to boundary conditions
 for 
\begin_inset Formula $\rho(x,s)$
\end_inset

.
 
\end_layout

\begin_layout Enumerate
Left boundary condition: We introduce a reflecting barrier at 
\begin_inset Formula $V_{\text{min}}$
\end_inset

, i.e the membrane potential 
\begin_inset Formula $V$
\end_inset

 can not take values smaller than 
\begin_inset Formula $V_{\text{min}}$
\end_inset

.
 Hence, neurons can not enter the system from left side of 
\begin_inset Formula $V_{\text{min}}$
\end_inset

, and therefore the probability current 
\begin_inset Formula $J(x,s)$
\end_inset

 must be zero at 
\begin_inset Formula $x_{\text{min}}=\sqrt{2}(V_{\text{min}}-\mu)/\sigma$
\end_inset


\begin_inset Formula 
\begin{equation}
0=J(x_{\text{min}},s)=\left.-\left(x+\partial_{x}\right)\rho(x,s)\right|_{x=x_{\text{min}}}\label{eq: left bc-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Right boundary condition: We introduce an absorbing boundary at 
\begin_inset Formula $V_{\text{max}}$
\end_inset

, i.e.
 neurons which go over threshold vanish, i.e.
 the density function 
\begin_inset Formula $\rho(x,t)$
\end_inset

 must be zero for values 
\begin_inset Formula $x\geq x_{\theta}=\sqrt{2}(V_{\text{th}}-\mu)/\sigma$
\end_inset


\begin_inset Formula 
\begin{equation}
\rho(x_{\theta},t)=0\label{eq: right bc-1}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Reset boundary condition: To ensure conversation of probability, neurons
 who vanish at the absorbing boundary at 
\begin_inset Formula $V_{\text{th}}$
\end_inset

 must be reinserted at the reset value 
\begin_inset Formula $V_{\text{r}}$
\end_inset

.
 Hence, the probability current on the right of the reset 
\begin_inset Formula $V_{\text{r}}+\epsilon$
\end_inset

 must be equal to the current from the left of the reset 
\begin_inset Formula $V_{\text{r}}-\epsilon$
\end_inset

 plus the probability current at the threshold 
\begin_inset Formula 
\begin{equation}
J(x_{\theta},t)=\lim_{\epsilon\rightarrow0^{+}}\left[J(x_{\text{r}}+\epsilon,t)-J(x_{\text{r}}-\epsilon,t)\right]\label{eq: reset bc-1}
\end{equation}

\end_inset

with 
\begin_inset Formula $x_{\text{r}}=\sqrt{2}(V_{\text{r}}-\mu)/\sigma$
\end_inset

 
\end_layout

\begin_layout Standard
In the new coordinates, the equation determining the eigenfunction 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: eigenfunction"

\end_inset

 reads 
\begin_inset Formula 
\begin{equation}
L\phi(x)=\partial_{x}\left(x+\partial_{x}\right)\phi(x)=\lambda\phi(x).\label{eq: eigenfunction x}
\end{equation}

\end_inset

Here, we drop the subscript 
\begin_inset Formula $n$
\end_inset

 for convenience.
 Note that the Fokker-Planck operator contains a single derivative, i.e.
 it is not self-adjoint.
 However, Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: eigenfunction x"

\end_inset

 can be transformed into a Schroedinger type equation 
\begin_inset Formula 
\[
\left(\partial_{x}^{2}\varphi(x)+V(x)\right)\varphi(x)=\lambda\varphi(x)
\]

\end_inset

with help of a similarity transformation 
\begin_inset Formula 
\begin{equation}
\varphi(x)=f^{-1}(x)\phi(x).\label{eq: phi2}
\end{equation}

\end_inset

We want need to find a 
\begin_inset Formula $f(x)$
\end_inset

 such that 
\begin_inset Formula 
\begin{equation}
f(x)^{-1}Lf(x)=\partial_{x}^{2}+V(x).\label{eq: L transformed}
\end{equation}

\end_inset

It turns out that if 
\begin_inset Formula $f(x)=e^{-\frac{x^{2}}{4}}$
\end_inset

 all first derivatives terms canel and we identify 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
We start from the equation 
\begin_inset Formula 
\[
L\phi=\lambda\phi
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Multiply from the left with 
\begin_inset Formula $f^{-1}$
\end_inset


\begin_inset Formula 
\[
f^{-1}Lf\phi=\lambda f^{-1}\phi
\]

\end_inset


\end_layout

\begin_layout Plain Layout
The r.h.s.
 evaluates to 
\begin_inset Formula 
\begin{align*}
f^{-1}Lf\phi & =f^{-1}\partial_{x}\left(x+\partial_{x}\right)f\phi\\
 & =f^{-1}\left(f\phi+xf'\phi+xf\phi'+f''\phi+2f'\phi'+f\phi''\right)\\
 & =\left(1+f^{-1}xf'+f^{-1}f''\right)\phi+\left(xf+2f'\right)\phi'+\phi''
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Choose 
\begin_inset Formula $f$
\end_inset

 such that the term in front of the first derivative vanishes 
\begin_inset Formula 
\[
xf+2f'=0
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Separation of variables yields
\begin_inset Formula 
\begin{align*}
xf+2\frac{df}{dx} & =0\\
\frac{1}{f}df & =-\frac{1}{2}x\\
f & =e^{-\frac{1}{4}x^{2}}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
The potential is given by 
\begin_inset Formula 
\begin{align*}
V(x) & =1+f^{-1}xf'+f^{-1}f''
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
First derivative and second derivative 
\begin_inset Formula 
\begin{align*}
f' & =-\frac{1}{2}xf\\
f'' & =-\frac{1}{2}f+\frac{1}{4}x^{2}f
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Hence, we find 
\begin_inset Formula 
\begin{align*}
V(x) & =1-\frac{1}{2}x^{2}-\frac{1}{2}+\frac{1}{4}x^{2}\\
 & =\frac{1}{2}-\frac{1}{4}x^{2}
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Formula 
\begin{align}
V(x) & =-\frac{1}{4}x^{2}+\frac{1}{2}.\label{eq: LIF potential}
\end{align}

\end_inset

The perform the similarity transformatin, we multiply Eq.
 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: eigenfunction"

\end_inset

 from the left with 
\begin_inset Formula $f^{-1}$
\end_inset

 and inserting a one 
\begin_inset Formula $1=f\cdot f^{-1}$
\end_inset

 on the r.h.s of the Fokker-Planck operator
\begin_inset Formula 
\begin{equation}
f^{-1}Lf\cdot f^{-1}\phi=\lambda f^{-1}\phi.
\end{equation}

\end_inset

We now use 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: phi2"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand eqref
reference "eq: L transformed"

\end_inset

, to arrive at
\begin_inset Formula 
\begin{equation}
\left(\partial_{x}^{2}+V(x)\right)\varphi=\lambda\varphi.
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF potential"

\end_inset

 into above the equation yields 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{align}
\left(\partial_{x}^{2}-\frac{1}{4}x^{2}+\frac{1}{2}\right)\varphi & =\lambda\varphi,
\end{align}

\end_inset

which can be written as 
\begin_inset Formula 
\begin{equation}
\partial_{x}^{2}\varphi-\left(\frac{1}{4}x^{2}+z\right)\varphi=0\label{eq: LIF eingefunction transformed}
\end{equation}

\end_inset

with 
\begin_inset Formula $z=\lambda-\frac{1}{2}$
\end_inset

.
 A numerical stable independent pair of solutions for the above equation
 are the parabolic cylinder functions 
\begin_inset Formula $U(z,x)$
\end_inset

 and 
\begin_inset Formula $V(z,x)$
\end_inset

 when 
\begin_inset Formula $x$
\end_inset

 is positive and 
\begin_inset Formula $U(z,-x)$
\end_inset

 and 
\begin_inset Formula $V(z,-x)$
\end_inset

 when 
\begin_inset Formula $x$
\end_inset

 is negative [DLMF].
 Hence, we can represent 
\begin_inset Formula $\varphi(x)$
\end_inset

 as a linear combination of both independent solutions 
\begin_inset Formula 
\[
\varphi(x)=aV(z,\pm x)+bU(z,\pm x)
\]

\end_inset

Note that 
\begin_inset Formula $x\in[-\infty,\,x_{\theta}]$
\end_inset

 with 
\begin_inset Formula $x_{\theta}=\sqrt{2}(V_{\text{th}}-\mu)/\sigma$
\end_inset

 which is positive if 
\begin_inset Formula $V_{\text{th}}>\mu$
\end_inset

 and negative if 
\begin_inset Formula $V_{\text{th}}<\mu$
\end_inset

.
 In the following, we set reflecting boundary to be located at 
\begin_inset Formula $x_{\text{min}}=-\infty$
\end_inset

.
 From Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: left bc-1"

\end_inset

 follows that 
\begin_inset Formula 
\begin{equation}
\lim_{x\rightarrow-\infty}x\phi(x)=\lim_{x\rightarrow-\infty}xf(x)\varphi(x)=0\label{eq: LIF left bc}
\end{equation}

\end_inset

to ensure that 
\begin_inset Formula $\rho(x,s)$
\end_inset

 is normalizable.
 The asymptotic behavior of 
\begin_inset Formula $U(z,-x)$
\end_inset

 and 
\begin_inset Formula $V(z,-x)$
\end_inset

 for 
\begin_inset Formula $x\rightarrow-\infty$
\end_inset

 is
\begin_inset Formula 
\begin{align*}
\lim_{x\rightarrow-\infty}U(z,-x) & \sim e^{-\frac{1}{4}x^{2}}x^{-z-\frac{1}{2}}\\
\lim_{x\rightarrow-\infty}V(z,-x) & \sim e^{\frac{1}{4}x^{2}}x^{z-\frac{1}{2}}
\end{align*}

\end_inset

Therefore, to determine the asymptotic behavior of 
\begin_inset Formula $\phi(x)=xf(x)\varphi(x)$
\end_inset

 we need to consider 
\begin_inset Formula 
\begin{align*}
\lim_{x\rightarrow-\infty}xf(x)U(z,-x) & \sim e^{-\frac{1}{2}x^{2}}x^{-z+\frac{1}{2}}\\
\lim_{x\rightarrow-\infty}xf(x)V(z,-x) & \sim x^{z+\frac{1}{2}}
\end{align*}

\end_inset

Note that the second term does not vanish if 
\begin_inset Formula $\lambda=0$
\end_inset

 and 
\begin_inset Formula $z=-\frac{1}{2}$
\end_inset

 which corresponds to stationary solution 
\begin_inset Formula $\phi_{0}(x)$
\end_inset

.
 Figure shows the 
\begin_inset Formula $U(z,x)$
\end_inset

 and 
\begin_inset Formula $V(z,x)$
\end_inset

 for different values of 
\begin_inset Formula $z$
\end_inset

 Hence, we need to construct a piece-wise solution in which 
\begin_inset Formula $V(z,-x)$
\end_inset

 does not contribute to the left branch 
\begin_inset Formula 
\begin{equation}
\varphi(x)=\begin{cases}
cU(z,-x) & x<x_{\text{r}}\\
aV(z,-x)+bU(z,-x) & x_{\text{r}}\leq x<x_{\theta}
\end{cases}\label{eq: LIF piecewise solution}
\end{equation}

\end_inset

to ensure that 
\begin_inset Formula $J_{0}(x)=-(x+\partial_{x})\phi_{0}(x)$
\end_inset

 goes to zero for 
\begin_inset Formula $x\rightarrow-\infty$
\end_inset

.
 Note that we separated the two branches of 
\begin_inset Formula $\varphi(x)$
\end_inset

 at the reset potential 
\begin_inset Formula $x_{r}$
\end_inset

 which will simplify the derivation going forward.
 The coefficients 
\begin_inset Formula $a,b$
\end_inset

 and 
\begin_inset Formula $c$
\end_inset

 need to be determined for each eigenfunction anew because the value of
 
\begin_inset Formula $z=\lambda-\frac{1}{2}$
\end_inset

 depends on 
\begin_inset Formula $\lambda$
\end_inset

.
 For each 
\begin_inset Formula $\lambda$
\end_inset

, the coefficients need be chosen such that 
\begin_inset Formula $\phi(x)=f(x)\varphi(x)$
\end_inset

 fulfills the boundary conditions previously defined for
\begin_inset Formula $\rho(x,s)$
\end_inset

.
 Furthermore, we constrain 
\begin_inset Formula $\varphi(x)$
\end_inset

 to be continuous at the reset value 
\begin_inset Formula $x_{\text{r}}$
\end_inset

.
 Using this additional constrain, the right boundary Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: right bc-1"

\end_inset

 and the reset boundary condition 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: reset bc-1"

\end_inset

, we arrive at the following set of constraints 
\end_layout

\begin_layout Enumerate
Right boundary conditions:
\begin_inset Formula 
\begin{equation}
\phi(x_{\theta})=f(x)\varphi(x_{\theta})=0\Rightarrow\varphi(x_{\theta})=0\label{eq: LIF right bc}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Continuity at reset:
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0^{+}}\left\{ \phi(x_{r}-\epsilon)=\phi(x_{\text{r}}+\epsilon)\Rightarrow\varphi(x_{\text{r}}-\epsilon)=\varphi(x_{\text{r}}+\epsilon)\right\} \label{eq: LIF continuous}
\end{equation}

\end_inset


\end_layout

\begin_layout Enumerate
Reset boundary condition: 
\begin_inset Formula 
\begin{equation}
\lim_{\epsilon\rightarrow0^{+}}\left\{ \partial_{x}\phi(x_{\text{r}}+\epsilon)-\partial_{x}\phi(x_{\text{r}}-\epsilon)\right\} =\partial_{x}\phi(x_{\theta})\Rightarrow f(x_{\theta})\partial_{x}\varphi_{n}(x_{\theta})=f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left\{ \partial_{x}\varphi_{n}(x_{\text{r}}+\epsilon)-\partial_{x}\varphi_{n}(x_{\text{r}}-\epsilon)\right\} \label{eq: LIF reset bc}
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Start from 
\begin_inset Formula 
\[
J_{n}(x_{\theta})=\lim_{\epsilon\rightarrow0^{+}}\left[J_{n}(x_{\text{r}}+\epsilon)-J_{n}(x_{\text{r}}-\epsilon)\right]
\]

\end_inset

with 
\begin_inset Formula $J_{n}(x)=-\left(x+\partial_{x}\right)\phi_{n}(v)=-(x+\partial_{x})f(x)\varphi(x)$
\end_inset

.
 We have
\begin_inset Formula 
\[
J_{n}(x_{\theta})=-x_{\theta}f(x_{\theta})\varphi(x_{\theta})-f(x_{\theta})\varphi'(x_{\theta})-f'(x_{\theta})\varphi(x_{\theta})
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Using 
\begin_inset Formula $\varphi(x_{\theta})=0$
\end_inset

, we find 
\begin_inset Formula 
\[
J_{n}(x_{\theta})=-f(x_{\theta})\varphi'(x_{\theta})
\]

\end_inset


\end_layout

\begin_layout Plain Layout
We have 
\begin_inset Formula 
\begin{align*}
 & \lim_{\epsilon\rightarrow0^{+}}\left[J_{n}(x_{\text{r}}+\epsilon)-J_{n}(x_{\text{r}}-\epsilon)\right]\\
= & \lim_{\epsilon\rightarrow0^{+}}\{-(x_{\text{r}}+\epsilon)f(x_{\text{r}}+\epsilon)\varphi(x_{\text{r}}+\epsilon)-f(x_{\text{r}}+\epsilon)\varphi'(x_{\text{r}}+\epsilon)-f'(x_{\text{r}}+\epsilon)\varphi(x_{\text{r}}+\epsilon)\\
 & +(x_{\text{r}}-\epsilon)f(x_{\text{r}}-\epsilon)\varphi(x_{\text{r}}-\epsilon)+f(x_{\text{r}}-\epsilon)\varphi'(x_{\text{r}}-\epsilon)+f'(x_{\text{r}}-\epsilon)\varphi(x_{\text{r}}-\epsilon)\}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
We use that all functions are continuous at 
\begin_inset Formula $x_{\text{r}}$
\end_inset

 except for the first derivative of 
\begin_inset Formula $\varphi'(x)$
\end_inset

 at 
\begin_inset Formula $x_{\text{r}}$
\end_inset


\begin_inset Formula 
\begin{align*}
\lim_{\epsilon\rightarrow0^{+}}\left[J_{n}(x_{\text{r}}+\epsilon)-J_{n}(x_{\text{r}}-\epsilon)\right]= & -x_{\text{r}}f(x_{\text{r}})\varphi(x_{\text{r}})-f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\varphi'(x_{\text{r}}+\epsilon)-f'(x_{\text{r}})\varphi(x_{\text{r}})\\
 & +(x_{\text{r}})f(x_{\text{r}})\varphi(x_{\text{r}})+f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\varphi'(x_{\text{r}}-\epsilon)-f'(x_{\text{r}})\varphi(x_{\text{r}})\}\\
= & f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left(\varphi'(x_{\text{r}}-\epsilon)-\varphi'(x_{\text{r}}+\epsilon)\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Hence, we find 
\begin_inset Formula 
\begin{align*}
\varphi'(x_{\theta}) & =f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left(\varphi'(x_{\text{r}}-\epsilon)-\varphi'(x_{\text{r}}+\epsilon)\right)\\
f(x_{\theta})\varphi'(x_{\theta}) & =f(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left(\varphi'(x_{\text{r}}+\epsilon)-\varphi'(x_{\text{r}}-\epsilon)\right)
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
For the reset boundary condition, we used that 
\begin_inset Formula $\phi(x_{\theta})=0$
\end_inset

 and that 
\begin_inset Formula $\phi(x)$
\end_inset

 is continuous at reset 
\begin_inset Formula $x_{\text{r}}$
\end_inset

 so that only the first derivative terms remain.
 We make the variable transformation 
\begin_inset Formula $x=-y$
\end_inset

 such that 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF piecewise solution"

\end_inset

 becomes 
\begin_inset Formula 
\[
\varphi(y)=\begin{cases}
aV(z,y)+bU(z,y) & y_{\theta}<y<y_{\text{r}}\\
cU(z,y) & y>y_{\text{r}}
\end{cases}
\]

\end_inset

with 
\begin_inset Formula $y_{\theta}=-x_{\theta}$
\end_inset

 and 
\begin_inset Formula $y_{\text{r}}=-x_{\text{r}}$
\end_inset

.
 The constraints 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF right bc"

\end_inset

, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF continuous"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF reset bc"

\end_inset

 yield a system of equations for the coefficients 
\begin_inset Formula $a_{n},b_{n}$
\end_inset

 and 
\begin_inset Formula $c_{n}$
\end_inset


\begin_inset Formula 
\begin{align}
a_{n}V(z_{n},y_{\theta})+b_{n}U(z_{n},y_{\theta}) & =0\nonumber \\
a_{n}V(z_{n},y_{\text{r}})+b_{n}U(z_{n},y_{\text{r}})-c_{n}U(z_{n},y_{\text{r}}) & =0\nonumber \\
a_{n}\left\{ f(y_{\theta})V'(z_{n},y_{\theta})-f(x_{\text{r}})V'(z_{n},x_{\text{r}})\right\} +b_{n}\left\{ f(y_{\theta})U'(z_{n},x_{\theta})-f(y_{\text{r}})U'(z_{n},y_{\text{r}})\right\} +c_{n}f(x_{\text{r}})U'(z_{n},y_{r}) & =0
\end{align}

\end_inset

where we used 
\begin_inset Formula $\partial_{x}V(z,-x)=-V'(z,y)$
\end_inset

 and that 
\begin_inset Formula $f(-y)=f(y)$
\end_inset

.
 In matrix notation, the system of equation can be written as 
\begin_inset Formula 
\begin{equation}
A_{n}\begin{pmatrix}a_{n}\\
b_{n}\\
c_{n}
\end{pmatrix}=\begin{pmatrix}V(z_{n},y_{\theta}) & U(z_{n},y_{\theta}) & 0\\
V(z_{n},y_{\text{r}}) & U(z_{n},y_{\text{r}}) & -U(z_{n},y_{\text{r}})\\
f(y_{\theta})V'(z_{n},y_{\theta})-f(x_{\text{r}})V'(z_{n},y_{\text{r}}) & f(y_{\theta})U'(z_{n},y_{\theta})-f(y_{\text{r}})U'(z_{n},y_{\text{r}}) & f(y_{\text{r}})U'(z_{n},y_{\text{r}})
\end{pmatrix}\begin{pmatrix}a_{n}\\
b_{n}\\
c_{n}
\end{pmatrix}=0
\end{equation}

\end_inset

This is homogeneous linear system of equations.
 If the matrix 
\begin_inset Formula $A_{n}$
\end_inset

 is invertible, the only solution to the system of equations is the trivial
 solution 
\begin_inset Formula 
\begin{equation}
A_{n}^{-1}A_{n}\begin{pmatrix}a_{n}\\
b_{n}\\
c_{n}
\end{pmatrix}=0\Leftrightarrow\begin{pmatrix}a_{n}\\
b_{n}\\
c_{n}
\end{pmatrix}=0.
\end{equation}

\end_inset

Hence, to obtain a non-trivial solution, we need to find those eigenvalues
 
\begin_inset Formula $\{\lambda_{n}\}$
\end_inset

 for which 
\begin_inset Formula $A_{n}$
\end_inset

 is singular (non invertible), i.e.
 
\begin_inset Formula 
\begin{equation}
\text{det}(A_{n})=0\label{eq: characteristic equation-1}
\end{equation}

\end_inset

 We find
\begin_inset Formula 
\begin{equation}
\text{det}\left(A_{n}\right)=\sqrt{\frac{2}{\pi}}\left[f(y_{\text{r}})U(z,y_{\theta})-f(y_{\theta})U(z,y_{\text{r}})\right],
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Using Leibniz formula for determinants, we find 
\begin_inset Formula 
\begin{align*}
 & \begin{vmatrix}V(z_{n},x_{\theta}) & U(z_{n},x_{\theta}) & 0\\
V(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
f(x_{\theta})V'(z_{n},x_{\theta})-f(x_{\text{r}})V'(z_{n},x_{\text{r}}) & U'(z_{n},x_{\theta})f(x_{\theta})-f(x_{\text{r}})U'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}\\
= & V(z_{n},x_{\theta})\begin{vmatrix}U(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
U'(z_{n},x_{\theta})f(x_{\theta})-f(x_{\text{r}})U'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}-U(z_{n},x_{\theta})\begin{vmatrix}V(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
f(x_{\theta})V'(z_{n},x_{\theta})-f(x_{\text{r}})V'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Making the calculation
\end_layout

\begin_layout Plain Layout
\begin_inset Formula 
\begin{align*}
 & V(z_{n},x_{\theta})\begin{vmatrix}U(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
U'(z_{n},x_{\theta})f(x_{\theta})-f(x_{\text{r}})U'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}-U(z_{n},x_{\theta})\begin{vmatrix}V(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
f(x_{\theta})V'(z_{n},x_{\theta})-f(x_{\text{r}})V'(z_{n},x_{\text{r}}) & f(x_{\text{r}})U'(z_{n},x_{\text{r}})
\end{vmatrix}\\
 & =V(z_{n},x_{\theta})\left\{ f(x_{\text{r}})U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+U(z_{n},x_{\text{r}})\left(U'(z_{n},x_{\theta})f(x_{\theta})-f(x_{\text{r}})U'(z_{n},x_{\text{r}})\right)\right\} \\
 & -U(z_{n},x_{\theta})\left\{ f(x_{\text{r}})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+U(z_{n},x_{\text{r}})\left(f(x_{\theta})V'(z_{n},x_{\theta})-f(x_{\text{r}})V'(z_{n},x_{\text{r}})\right)\right\} \\
 & =f(x_{\text{r}})V(z_{n},x_{\theta})U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+V(z_{n},x_{\theta})U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})f(x_{\theta})-V(z_{n},x_{\theta})U(z_{n},x_{\text{r}})f(x_{\text{r}})U'(z_{n},x_{\text{r}})\\
 & -f(x_{\text{r}})U(z_{n},x_{\theta})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})f(x_{\theta})V'(z_{n},x_{\theta})+U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})f(x_{\text{r}})V'(z_{n},x_{\text{r}})\\
 & =f(x_{\theta})\left(V(z_{n},x_{\theta})U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})-U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\right)+f(x_{r})\left(-U(z_{n},x_{\theta})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})\right)\\
 & =U(z_{n},x_{\text{r}})f(x_{\theta})\left(-U(z_{n},x_{\theta})V'(z_{n},x_{\theta})+V(z_{n},x_{\theta})U'(z_{n},x_{\theta})\right)+f(x_{\text{r}})U(z_{n},x_{\theta})\left(-V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})+U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})\right)\\
 & =\sqrt{\frac{2}{\pi}}\left(f(x_{\text{r}})U(z_{n},x_{\theta})-U(z_{n},x_{\text{r}})f(x_{\theta})\right)
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
In the last line we used that the Wronskian 
\begin_inset Formula 
\[
\text{Wr}(U,V)=U(z,x)V'(z,x)-V(z,x)U(z,x)=\sqrt{\frac{2}{\pi}}
\]

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 which leads to the following characteristic equation 
\begin_inset Formula 
\begin{equation}
\frac{U(z_{n},y_{\theta})}{f(y_{\theta})}-\frac{U(z_{n},y_{\text{r}})}{f(y_{\text{r}})}=0\label{eq: LIF characteristic equation}
\end{equation}

\end_inset

which determines the eigenvalues of our problem.
 The solutions to the above equation yield a set of countably many isolated
 eigenvalues.
\end_layout

\begin_layout Standard
A singular matrix has always at least two dependent vectors.
 Indeed one can show that if Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF characteristic equation"

\end_inset

 is fulfilled, then 
\begin_inset Formula $A_{n}$
\end_inset

 has two dependent rows.
 From this follows that the row echelon form 
\begin_inset Formula $A_{n}$
\end_inset

 has one zero row.
 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
\begin_inset Formula 
\[
A=\begin{pmatrix}V(z_{n},x_{\theta}) & U(z_{n},x_{\theta}) & 0\\
V(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}}) & -U(z_{n},x_{\text{r}})\\
V'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}V'(z_{n},x_{\theta}) & U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U'(z_{n},x_{\theta}) & -U'(z_{n},x_{\text{r}})
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Swap the first and third column and the first and third row
\begin_inset Formula 
\[
\begin{pmatrix}0 & U(z_{n},x_{\theta}) & V(z_{n},x_{\theta})\\
-U(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}}) & V(z_{n},x_{\text{r}})\\
-U'(z_{n},x_{\text{r}}) & U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U'(z_{n},x_{\theta}) & V'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}V'(z_{n},x_{\theta})
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Multiply the second row by 
\begin_inset Formula $-U'(z_{n},x_{\text{r}})$
\end_inset

 and the third row by 
\begin_inset Formula $U(z_{n},x_{\text{r}})$
\end_inset

 and add second and third row 
\begin_inset Formula 
\[
\begin{pmatrix}0 & U(z_{n},x_{\theta}) & V(z_{n},x_{\theta})\\
0 & -\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta}) & U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\\
-U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta}) & U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Multiply the second row with 
\begin_inset Formula $U(z_{n},x_{\theta})$
\end_inset

 and the first row with 
\begin_inset Formula $\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})$
\end_inset

 and sum the first and second row
\begin_inset Formula 
\[
\begin{pmatrix}0 & 0 & \frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})V(z_{n},x_{\theta})+U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-U(z_{n},x_{\theta})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\\
0 & -\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})U(z_{n},x_{\theta}) & U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\\
-U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}}) & U(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta}) & U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})
\end{pmatrix}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Show that 
\begin_inset Formula 
\begin{align*}
0 & =\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})U'(z_{n},x_{\theta})V(z_{n},x_{\theta})+U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-U(z_{n},x_{\theta})V(z_{n},x_{\text{r}})U'(z_{n},x_{\text{r}})-\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\theta})U(z_{n},x_{\text{r}})V'(z_{n},x_{\theta})\\
0 & =\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})\left(U'(z_{n},x_{\theta})V(z_{n},x_{\theta})-U(z_{n},x_{\theta})V'(z_{n},x_{\theta})\right)+U(z_{n},x_{\theta})\left(U(z_{n},x_{\text{r}})V'(z_{n},x_{\text{r}})-U'(z_{n},x_{\text{r}})V(z_{n},x_{\text{r}})\right)\\
0 & =\frac{f(x_{\theta})}{f(x_{\text{r}})}U(z_{n},x_{\text{r}})\text{Wr}(x_{\theta})-U(z_{n},x_{\theta})\text{Wr}(x_{\text{r}})
\end{align*}

\end_inset

Dividing the above equation by 
\begin_inset Formula $\text{Wr}(x_{\theta})\text{Wr}(x_{\text{r}})f(x_{\theta})$
\end_inset

 yields 
\begin_inset Formula 
\[
0=\frac{U(z_{n},x_{\text{r}})}{f(x_{\text{r}})\text{Wr}(x_{\text{r}})}-\frac{U(z_{n},x_{\theta})}{f(x_{\theta})\text{Wr}(x_{\theta})}
\]

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 Hence, the system of equations is not fully determinant, but instead we
 can construct infinite number of solutions by choosing an arbitrary value
 for one of the coefficients.
 This degree of freedom can be understood from the fact that eigenfunctions
 are only unique up to some ubiquitous normalization condition.
 Going on, we first determine the coefficients 
\begin_inset Formula $a_{n}$
\end_inset

 and 
\begin_inset Formula $b_{n}$
\end_inset

 as functions of the coefficients 
\begin_inset Formula $c_{n}$
\end_inset

.
 After that, we determine 
\begin_inset Formula $c_{n}$
\end_inset

 by a suitable normalization condition which than also fixes the values
 for 
\begin_inset Formula $a_{n}$
\end_inset

 and 
\begin_inset Formula $b_{n}$
\end_inset

.
 We introduce the abbreviations 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\begin{equation}
0=\begin{pmatrix}V(z_{n},y_{\theta}) & U(z_{n},y_{\theta}) & 0\\
V(z_{n},y_{\text{r}}) & U(z_{n},y_{\text{r}}) & -U(z_{n},y_{\text{r}})\\
f(y_{\theta})V'(z_{n},y_{\theta})-f(y_{\text{r}})V'(z_{n},y_{\text{r}}) & U'(z_{n},y_{\theta})f(y_{\theta})-f(y_{\text{r}})U'(z_{n},y_{\text{r}}) & f(x_{\text{r}})U'(z_{n},y_{\text{r}})
\end{pmatrix}\begin{pmatrix}a_{n}\\
b_{n}\\
c_{n}
\end{pmatrix}=\begin{pmatrix}V_{\theta} & U_{\theta} & 0\\
V_{r} & U_{r} & -U_{r}\\
f_{\theta}V_{\theta}'-f_{r}V_{r}' & f_{\theta}U_{\theta}'-f_{r}U_{r}' & f_{r}U_{r}'
\end{pmatrix}\begin{pmatrix}a\\
b\\
c
\end{pmatrix}
\end{equation}

\end_inset

From the first two row follows 
\begin_inset Formula 
\begin{align}
a & =\frac{U_{\theta}/f_{\theta}}{V_{r}/f_{r}-V_{\theta}/f_{\theta}}c\label{eq: LIF a}\\
b & =-\frac{V_{\theta}/f\theta}{V_{r}/f_{r}-V_{\theta}/f_{\theta}}c\label{eq: LIF b}
\end{align}

\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
From the first row follows
\begin_inset Formula 
\[
V_{\theta}a=-U_{\theta}b
\]

\end_inset


\end_layout

\begin_layout Plain Layout
From the second row follows
\begin_inset Formula 
\begin{align*}
V_{r}a+U_{r}b-U_{r}c & =0\\
U_{r}b & =U_{r}c-V_{r}a\\
b & =\frac{U_{r}c-V_{r}a}{U_{r}}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Substituting into the first equation yields 
\begin_inset Formula 
\begin{align*}
V_{\theta}a & =-U_{\theta}\frac{U_{r}c-V_{r}a}{U_{r}}\\
V_{\theta}a & =\frac{U_{\theta}V_{r}a-U_{\theta}U_{r}c}{U_{r}}\\
\left(\frac{V_{\theta}U_{r}-U_{\theta}V_{r}}{U_{r}}\right)a & =-U_{\theta}c\\
a & =\frac{-U_{r}U_{\theta}}{V_{\theta}U_{r}-U_{\theta}V_{r}}c\\
a & =\frac{U_{r}U_{\theta}}{U_{\theta}V_{r}-V_{\theta}U_{r}}c
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Substituting into the equation for 
\begin_inset Formula $b$
\end_inset


\begin_inset Formula 
\begin{align*}
b & =\frac{U_{r}c-V_{r}\frac{U_{r}U_{\theta}}{U_{\theta}V_{r}-V_{\theta}U_{r}}c}{U_{r}}\\
 & =\frac{U_{r}(U_{\theta}V_{r}-V_{\theta}U_{r})-V_{r}U_{r}U_{\theta}}{U_{r}(U_{\theta}V_{r}-V_{\theta}U_{r})}c\\
 & =\frac{U_{r}U_{\theta}V_{r}-U_{r}V_{\theta}U_{r}-V_{r}U_{r}U_{\theta}}{U_{r}(U_{\theta}V_{r}-V_{\theta}U_{r})}c\\
 & =\frac{-U_{r}V_{\theta}U_{r}}{U_{r}(U_{\theta}V_{r}-V_{\theta}U_{r})}c\\
 & =\frac{V_{\theta}U_{r}}{V_{\theta}U_{r}-U_{\theta}V_{r}}c
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

.
 We determine the coefficient 
\begin_inset Formula $c$
\end_inset

 by choosing the normalization 
\begin_inset Formula 
\begin{equation}
\partial_{x}\phi(x_{\theta})=f_{\theta}\partial_{x}\varphi(x_{\theta})=-\sqrt{\frac{2}{\pi}}\label{eq: LIF normalization-1}
\end{equation}

\end_inset

from which follows 
\begin_inset Formula 
\begin{equation}
aV'_{\theta}+bU'_{\theta}=\sqrt{\frac{2}{\pi}}f_{\theta}^{-1}
\end{equation}

\end_inset

Substituting Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF a"

\end_inset

 and 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF b"

\end_inset

 into the above equation yields 
\begin_inset Formula 
\begin{equation}
c=V_{r}/f_{r}-V_{\theta}/f_{\theta}
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
We need to solve 
\begin_inset Formula 
\begin{align*}
\frac{\frac{1}{f_{\theta}}\left(U_{\theta}V'_{\theta}-V_{\theta}U'_{\theta}\right)}{V_{r}/f_{r}-V_{\theta}/f_{\theta}}c & =\sqrt{\frac{2}{\pi}}f_{\theta}^{-1}\\
\frac{U_{\theta}V'_{\theta}-V_{\theta}U'_{\theta}}{V_{r}/f_{r}-V_{\theta}/f_{\theta}} & c=\sqrt{\frac{2}{\pi}}
\end{align*}

\end_inset

Using 
\begin_inset Formula $U_{\theta}V'_{\theta}-V_{\theta}U'_{\theta}=$
\end_inset


\begin_inset Formula $\sqrt{2/\pi}$
\end_inset

, we find 
\begin_inset Formula 
\begin{align*}
\frac{1}{V_{r}/f_{r}-V_{\theta}/f_{\theta}}c & =1\\
c & =V_{r}/f_{r}-V_{\theta}/f_{\theta}
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 Hence, we arrive at 
\begin_inset Formula 
\begin{align}
a_{n} & =\frac{U(z_{n},y_{\theta})}{f(y_{\theta})}\nonumber \\
b_{n} & =-\frac{V(z_{n},y_{\theta})}{f(y_{\theta})}\nonumber \\
c_{n} & =\frac{V(z_{n},y_{\text{r}})}{f(y_{\text{r}})}-\frac{V(z_{n},y_{\theta})}{f(y_{\theta})}\label{eq: LIF coefficients}
\end{align}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Check 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
First equation
\begin_inset Formula 
\begin{align*}
V_{\theta}a+U_{\theta}b & =0\\
\frac{V_{\theta}U_{\theta}}{f_{\theta}}-\frac{V_{\theta}U_{\theta}}{f_{\theta}} & =0\\
0 & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Second equation 
\begin_inset Formula 
\begin{align*}
V_{r}a+bU_{r}-cU_{r} & =0\\
V_{r}\frac{U_{\theta}}{f_{\theta}}-\frac{V_{\theta}}{f_{\theta}}U_{r}-\left(\frac{V_{r}}{f_{r}}-\frac{V_{\theta}}{f_{\theta}}\right)U_{r} & =0\\
\frac{V_{r}U_{\theta}}{f_{\theta}}-\frac{V_{r}U_{r}}{f_{r}} & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Using 
\begin_inset Formula $\frac{U_{\theta}}{f_{\theta}}=\frac{U_{r}}{f_{r}}$
\end_inset


\begin_inset Formula 
\[
\frac{V_{r}U_{\theta}}{f_{\theta}}-\frac{V_{r}U_{\theta}}{f_{\theta}}=0
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Third equation 
\begin_inset Formula 
\begin{align*}
(f_{\theta}V_{\theta}'-f_{r}V'_{r})a+('f_{\theta}U_{\theta}'-f_{r}U_{r}')b+f_{r}U_{r}'c & =0\\
(f_{\theta}V_{\theta}'-f_{r}V'_{r})\frac{U_{\theta}}{f_{\theta}}-(f_{\theta}U_{\theta}'-f_{r}U_{r}')\frac{V_{\theta}}{f_{\theta}}+f_{r}U_{r}'\left(\frac{V_{r}}{f_{r}}-\frac{V_{\theta}}{f_{\theta}}\right) & =0\\
V_{\theta}'U_{\theta}-\frac{f_{r}V'_{r}U_{\theta}}{f_{\theta}}-U_{\theta}'V_{\theta}+\frac{f_{r}U_{r}'V_{\theta}}{f_{\theta}}+U_{r}'V_{r}-\frac{V_{\theta}f_{r}U_{r}'}{f_{\theta}} & =0\\
U_{\theta}V_{\theta}'-U_{\theta}'V_{\theta}+\frac{f_{r}}{f_{\theta}}\left(-V'_{r}U_{\theta}+U_{r}'V_{\theta}-V_{\theta}U_{r}'\right)+U_{r}'V_{r} & =0\\
U_{\theta}V_{\theta}'-U_{\theta}'V_{\theta}-\frac{f_{r}}{f_{\theta}}V'_{r}U_{\theta}+U_{r}'V_{r} & =0\\
U_{\theta}V_{\theta}'-U_{\theta}'V_{\theta}-(U_{r}V'_{r}-U_{r}'V_{r}) & =0\\
\sqrt{\frac{2}{\pi}}-\sqrt{\frac{2}{\pi}} & =0
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Continuity at reset 
\begin_inset Formula 
\begin{align*}
cU_{r} & =aV_{r}+bU_{r}\\
(c-b)U_{r} & =aV_{r}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Inserting coefficients yields 
\begin_inset Formula 
\begin{align*}
\left(\frac{V_{r}}{f_{r}}-\frac{V_{\theta}}{f_{\theta}}+\frac{V_{\theta}}{f_{\theta}}\right)U_{r} & =\frac{U_{\theta}}{f_{\theta}}V_{r}\\
\frac{V_{r}}{f_{r}}U_{r} & =\frac{U_{\theta}}{f_{\theta}}V_{r}\\
\frac{f_{\theta}}{f_{r}} & =\frac{U_{\theta}}{U_{r}}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
which this zero due to characteristic equation.
 
\end_layout

\end_inset


\end_layout

\end_inset

 Hence, we arrive at 
\begin_inset Formula 
\[
\phi_{n}(x)=f(x)\begin{cases}
c_{n}U(z_{n},-x) & x<x_{\text{r}}\\
a_{n}V(z_{n},-x)+b_{n}U(z_{n},-x) & x_{\text{r}}\leq x<x_{\theta}
\end{cases}
\]

\end_inset

where 
\begin_inset Formula $a_{n},b_{n}$
\end_inset

 and 
\begin_inset Formula $c_{n}$
\end_inset

 are given by Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF coefficients"

\end_inset

, 
\begin_inset Formula $f(x)=e^{-\frac{1}{4}x^{2}}$
\end_inset

and 
\begin_inset Formula $z_{n}=\lambda_{n}-1/2$
\end_inset

.
 The characteristic equation 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation-1"

\end_inset

 needs to be solved numerically.
 The next figures show how Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation-1"

\end_inset

 changes on the real and the zero crossings of the real and imaginary part
 of the r.h.s.
 of 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation-1"

\end_inset

 in the complex plane.
 Surprisingly, we do not seem to find solutions to Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: characteristic equation-1"

\end_inset

 in the complex plane.
 However, [Denzik (2017)] showed a figure of spectrum which contained complex
 eigenvalues.
 
\end_layout

\begin_layout Standard
Once we found an eigenvalue 
\begin_inset Formula $\lambda_{n}$
\end_inset

, we can determine the values for the corresponding coefficients 
\begin_inset Formula $a_{n},b_{n}$
\end_inset

 and 
\begin_inset Formula $c_{n}$
\end_inset

 via Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF coefficients"

\end_inset

.
 The next figure shows the eigenfunctions for the first three eigenvalues
 we found on the real line.
 
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Graphics
	filename /usr/not-backed-up/Git Projects/PhD/PhD/transfer_report/LIF_summary/LIF_eigenfunctions.png

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
\begin_inset Formula $\phi_{n}(x)$
\end_inset

 and 
\begin_inset Formula $\phi_{n}'(x)$
\end_inset

 for 
\begin_inset Formula $(\mu=1.2$
\end_inset

, 
\begin_inset Formula $\sigma=0.3$
\end_inset

, 
\begin_inset Formula $V_{\text{th}}=1$
\end_inset

, 
\begin_inset Formula $V_{\text{r}}=0)$
\end_inset

.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Note that the eigenfunctions have a kink at 
\begin_inset Formula $V_{r}=0$
\end_inset

, where the first derivative makes a jump of height 
\begin_inset Formula $\phi(x_{\text{th}})=\sqrt{2/\pi}\approx0.78$
\end_inset

 as enforced by the normalization condition 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF normalization-1"

\end_inset

.
 
\end_layout

\begin_layout Standard
As already mentioned, the Fokker-Planck operator 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF Fokker-Planck"

\end_inset

 is not self-adjoint.
 Hence, in order to build a biorthogonal basis, we need to determine eigenfuncti
ons 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 of the adjoint operator 
\begin_inset Formula $L^{\dagger}$
\end_inset

 with 
\begin_inset Formula 
\begin{equation}
L^{\dagger}\tilde{\phi}_{n}=\tilde{\lambda}_{n}\tilde{\phi}_{n}\label{eq: LIF adjoint eigenfunction}
\end{equation}

\end_inset

 The adjoint operator is defined by the equation 
\begin_inset Formula 
\begin{equation}
\bigl\langle\tilde{\phi},L\phi\bigr\rangle=\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle\label{eq: adjoint operator}
\end{equation}

\end_inset

Using that an operator and it adjoint have the same eigenvalues 
\begin_inset Formula $\tilde{\lambda}_{n}=\lambda_{n}$
\end_inset

, it can been shown that the eigenfunctions 
\begin_inset Formula $\phi_{n}$
\end_inset

 and 
\begin_inset Formula $\tilde{\phi}_{n}$
\end_inset

 are orthogonal 
\begin_inset Formula $\bigl\langle\tilde{\phi}_{m},\phi_{n}\bigr\rangle=\delta_{nm}$
\end_inset

.
 We start from
\begin_inset Formula 
\begin{equation}
\lambda_{n}\bigl\langle\tilde{\phi}_{m},\phi_{n}\bigr\rangle=\bigl\langle\tilde{\phi}_{m},L\phi_{n}\bigr\rangle,\label{eq: dual basis proof}
\end{equation}

\end_inset

and use Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: adjoint operator"

\end_inset


\begin_inset Formula 
\begin{equation}
\bigl\langle\tilde{\phi}_{m},L\phi_{n}\bigr\rangle=\bigl\langle L^{\dagger}\tilde{\phi}_{m},\phi_{n}\bigr\rangle=\lambda_{m}\bigl\langle\tilde{\phi}_{m},\phi_{n}\bigr\rangle.
\end{equation}

\end_inset

Subtracting the r.h.s.
 of the above equation from the l.h.s.
 of Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: dual basis proof"

\end_inset

, we find 
\begin_inset Formula 
\begin{equation}
(\lambda_{n}-\lambda_{m})\bigl\langle\tilde{\phi}_{m},\phi_{n}\bigr\rangle=0,
\end{equation}

\end_inset

Hence, 
\begin_inset Formula $\bigl\langle\tilde{\phi}_{m},\phi_{n}\bigr\rangle$
\end_inset

 must be zero if 
\begin_inset Formula $n\neq m$
\end_inset

.
 The adjoint operator and the boundary condition for its eigenfunctions
 need to determined from Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: adjoint operator"

\end_inset

.
 We find 
\begin_inset Formula 
\begin{equation}
L^{\dagger}=-x\partial_{x}+\partial_{x}^{2}
\end{equation}

\end_inset

and 
\begin_inset Formula $\tilde{\phi}(x_{\text{\ensuremath{\theta}}})=\tilde{\phi}(x_{\text{r}})$
\end_inset

 
\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
We start from 
\begin_inset Formula 
\[
\bigl\langle\tilde{\phi},L\phi\bigr\rangle=\int_{-\infty}^{x_{t}}dx\tilde{\phi}L\phi=\int_{-\infty}^{x_{t}}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Split integral into two parts 
\begin_inset Formula 
\[
\int_{-\infty}^{x_{t}}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi=\lim_{\epsilon\rightarrow0^{+}}\left\{ \int_{-\infty}^{x_{r}-\epsilon}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi+\int_{x_{r}+\epsilon}^{\infty}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi\right\} 
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Our goal is to move the derivatives over to 
\begin_inset Formula $\tilde{\phi}_{m}$
\end_inset

 by partial integration 
\begin_inset Formula 
\begin{align*}
\int_{a}^{b}dx\tilde{\phi}\left(\partial_{x}x+\partial_{x}^{2}\right)\phi & =\left.\tilde{\phi}\left(x+\partial_{x}\right)\phi\right|_{a}^{b}-\int_{a}^{b}dx\left(\partial_{x}\tilde{\phi}\right)\left(x+\frac{\partial}{\partial x}\right)\phi\\
 & =\left.\tilde{\phi}\left(x+\partial_{x}\right)\phi\right|_{a}^{b}-\int_{a}^{b}dx\,\left\{ x\phi\partial_{x}\tilde{\phi}+\left(\partial_{x}\tilde{\phi}\right)\left(\frac{\partial}{\partial x}\phi\right)\right\} \\
 & =\left.\tilde{\phi}\left(x+\partial_{x}\right)\phi\right|_{a}^{b}-\int_{a}^{b}dx\,x\phi\partial_{x}\tilde{\phi}-\left.\left(\partial_{x}\tilde{\phi}\right)\phi\right|_{a}^{b}+\int_{a}^{b}dx\,\phi\partial_{x}^{2}\tilde{\phi}\\
 & =\left.\tilde{\phi}\left(x+\partial_{x}\right)\phi\right|_{a}^{b}-\left.\left(\partial_{x}\tilde{\phi}\right)\phi\right|_{a}^{b}+\int_{a}^{b}dx\,\left\{ -x\phi\partial_{x}\tilde{\phi}+\phi\partial_{x}^{2}\tilde{\phi}\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
The last term shows us that 
\begin_inset Formula 
\[
L^{\dagger}=-x\partial_{x}+\partial_{x}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
The boundary conditions of 
\begin_inset Formula $\tilde{\phi}$
\end_inset

 need to be chosen such that the surface terms vanish.
 We use 
\begin_inset Formula $J(x)=-\left(x+\partial_{x}\right)\phi$
\end_inset

 so that 
\begin_inset Formula 
\begin{align*}
\bigl\langle\tilde{\phi},L\phi\bigr\rangle & =\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle-\lim_{\epsilon\rightarrow0^{+}}\left\{ \left.\tilde{\phi}J+\right|_{-\infty}^{x_{r}-\epsilon}+\left.\left(\partial_{x}\tilde{\phi}\right)\phi\right|_{-\infty}^{x_{r}-\epsilon}+\left.\tilde{\phi}J\right|_{x_{r}+\epsilon}^{x_{\theta}}+\left.\left(\partial_{x}\tilde{\phi}\right)\phi_{n}\right|_{x_{r}+\epsilon}^{x_{\theta}}\right\} \\
 & =\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle-\lim_{\epsilon\rightarrow0^{+}}\left\{ \tilde{\phi}(x_{\text{r}}-\epsilon)J(x_{\text{r}}-\epsilon)+\tilde{\phi}'(x_{\text{r}}-\epsilon)\phi(x_{\text{r}}-\epsilon)+\tilde{\phi}(x_{\text{\ensuremath{\theta}}})J(x_{\theta})-\tilde{\phi}(x_{\text{r}}+\epsilon)J(x_{\text{r}}+\epsilon)-\tilde{\phi}'(x_{\text{r}}+\epsilon)\phi(x_{\text{r}}+\epsilon)\right\} \\
 & =\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle-\lim_{\epsilon\rightarrow0^{+}}\left\{ \tilde{\phi}(x_{\text{\ensuremath{\theta}}})J(x_{\theta})+\tilde{\phi}(x_{\text{r}}-\epsilon)J(x_{\text{r}}-\epsilon)-\tilde{\phi}(x_{\text{r}}+\epsilon)J(x_{\text{r}}+\epsilon)+\tilde{\phi}'(x_{\text{r}}-\epsilon)\phi(x_{\text{r}}-\epsilon)-\tilde{\phi}'(x_{\text{r}}+\epsilon)\phi(x_{\text{r}}+\epsilon)\right\} 
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Note that many of the terms vanish due to the boundary conditions 
\begin_inset Formula $\phi(x)$
\end_inset

.
 If 
\begin_inset Formula $\phi'(x)$
\end_inset

 is continuous at 
\begin_inset Formula $x_{\text{r}}$
\end_inset

, then the last term in the above equation vanishes and we are left with
\begin_inset Formula 
\[
\bigl\langle\tilde{\phi},L\phi\bigr\rangle=\bigl\langle L^{\dagger}\tilde{\phi},\phi\bigr\rangle-\lim_{\epsilon\rightarrow0^{+}}\left\{ \tilde{\phi}(x_{\text{\ensuremath{\theta}}})J(x_{\theta})+\tilde{\phi}(x_{\text{r}}-\epsilon)J(x_{\text{r}}-\epsilon)-\tilde{\phi}(x_{\text{r}}+\epsilon)J(x_{\text{r}}+\epsilon)\right\} 
\]

\end_inset


\end_layout

\begin_layout Plain Layout
If 
\begin_inset Formula $\tilde{\phi}(x_{\text{\ensuremath{\theta}}})=\tilde{\phi}(x_{\text{r}})$
\end_inset

, then 
\begin_inset Formula 
\[
\lim_{\epsilon\rightarrow0^{+}}\left\{ \tilde{\phi}(x_{\text{\ensuremath{\theta}}})J(x_{\theta})+\tilde{\phi}(x_{\text{r}}-\epsilon)J(x_{\text{r}}-\epsilon)-\tilde{\phi}(x_{\text{r}}+\epsilon)J(x_{\text{r}}+\epsilon)\right\} =\tilde{\phi}(x_{\text{r}})\lim_{\epsilon\rightarrow0^{+}}\left\{ J(x_{\theta})-\left[J(x_{\text{r}}+\epsilon)-J(x_{\text{r}}-\epsilon)\right]\right\} =0
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Hence, we arrive at 
\begin_inset Formula 
\[
L^{\dagger}=-x\partial_{x}+\partial_{x}^{2}
\]

\end_inset

and 
\begin_inset Formula 
\[
\tilde{\phi}(x_{\text{\ensuremath{\theta}}})=\tilde{\phi}(x_{\text{r}})
\]

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

.
 We transform Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF adjoint eigenfunction"

\end_inset

 into a Schroedinger type equation 
\begin_inset Formula 
\begin{equation}
g^{-1}L^{\dagger}g=\partial_{x}^{2}+V(x)
\end{equation}

\end_inset

using the similarity transformation 
\begin_inset Formula 
\begin{equation}
\tilde{\varphi}(x)=g^{-1}(x)\tilde{\phi}(x).
\end{equation}

\end_inset

Note that we dropped the subscript 
\begin_inset Formula $n$
\end_inset

 for convenience.
 Choosing 
\begin_inset Formula $g(x)=e^{\frac{1}{4}x^{2}}$
\end_inset

, yields 
\begin_inset Formula 
\begin{equation}
V(x)=-\frac{1}{4}x^{2}+\frac{1}{2}
\end{equation}

\end_inset


\begin_inset Note Note
status open

\begin_layout Plain Layout
Proof 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
Start from 
\begin_inset Formula 
\begin{align*}
g^{-1}\left(-x\partial_{x}+\partial_{x}^{2}\right)g\tilde{\varphi} & =g^{-1}\left(-xg'\tilde{\varphi}-xg\tilde{\varphi}'+g''\tilde{\varphi}+2g'\varphi'+g\varphi''\right)\\
 & =\left(-g^{-1}xg'+g^{-1}g''\right)\tilde{\varphi}+\left(-xg+2g'\right)\tilde{\varphi}'+\varphi''
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Choose 
\begin_inset Formula $g$
\end_inset

 such that 
\begin_inset Formula 
\[
-xg+2g'=0
\]

\end_inset


\end_layout

\begin_layout Plain Layout
Separation of variables yields 
\begin_inset Formula 
\begin{align*}
-xg+2\frac{dg}{dx} & =0\\
\frac{1}{g}dg & =\frac{1}{2}x\,dx
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
We find
\begin_inset Formula 
\[
g(x)=e^{\frac{1}{4}x^{2}}
\]

\end_inset


\end_layout

\begin_layout Plain Layout
First and second derivative 
\begin_inset Formula 
\begin{align*}
g' & =\frac{1}{2}xg\\
g'' & =\frac{1}{2}g+\frac{1}{4}x^{2}g
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Hence, we arrive at 
\begin_inset Formula 
\begin{align*}
V(x) & =\left(-g^{-1}x\frac{1}{2}xg+g^{-1}\left(\frac{1}{2}g+\frac{1}{4}x^{2}g\right)\right)\\
 & =\left(-\frac{1}{2}x^{2}+\frac{1}{2}+\frac{1}{4}x^{2}\right)\\
 & =-\frac{1}{4}x^{2}+\frac{1}{2}
\end{align*}

\end_inset


\end_layout

\begin_layout Plain Layout
Check 
\begin_inset Formula 
\begin{align*}
 & g^{-1}\left(-x\partial_{x}+\partial_{x}^{2}\right)g\\
= & g^{-1}\left(-\frac{1}{2}x^{2}g+\frac{1}{2}g+\frac{1}{4}x^{2}g\right)\\
= & -\frac{1}{4}x^{2}+\frac{1}{2}
\end{align*}

\end_inset


\end_layout

\end_inset


\end_layout

\end_inset

 which is interestingly identical to Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF potential"

\end_inset

.
 Hence, 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF adjoint eigenfunction"

\end_inset

 transforms into 
\begin_inset Formula 
\begin{equation}
\left(\partial_{x}^{2}-\frac{1}{4}x^{2}+\frac{1}{2}\right)\tilde{\varphi}=\lambda\tilde{\varphi}.
\end{equation}

\end_inset

We define 
\begin_inset Formula $z=\lambda-\frac{1}{2}$
\end_inset

 and write 
\begin_inset Formula 
\begin{equation}
\partial_{x}^{2}-\left(\frac{1}{4}x^{2}+z\right)\tilde{\varphi}=0,
\end{equation}

\end_inset

which is equivalent to 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF left bc"

\end_inset

.
 Hence, the general solution is 
\begin_inset Formula 
\begin{equation}
\tilde{\varphi}(x)=aV(z,y)+bU(z,y).
\end{equation}

\end_inset

with 
\begin_inset Formula $y=-x$
\end_inset

.
 The back transform yields 
\begin_inset Formula 
\[
\tilde{\phi}=g(y)\tilde{\varphi}(y)
\]

\end_inset

The determine asymptotic behavior of 
\begin_inset Formula $\phi(x)=g(x)\tilde{\varphi}(x)$
\end_inset

 for 
\begin_inset Formula $y\rightarrow\infty$
\end_inset

 is determined by 
\begin_inset Formula 
\begin{align*}
\lim_{y\rightarrow\infty}g(y)U(z,y) & \sim x^{-z-\frac{1}{2}}\\
\lim_{y\rightarrow\infty}g(y)V(z,y) & \sim e^{\frac{1}{4}x^{2}}x^{z-\frac{1}{2}}
\end{align*}

\end_inset

which shows that both 
\begin_inset Formula $V(z,y)$
\end_inset

 divergence.
 Hence, me make the ansatz
\begin_inset Formula 
\[
\tilde{\phi}(y)=bg(y)U(z,y)
\]

\end_inset

 Note that this solution fulfills the boundary condition 
\begin_inset Formula $\tilde{\phi}(y_{\text{\ensuremath{\theta}}})=\tilde{\phi}(y_{\text{r}})$
\end_inset

 
\begin_inset Formula 
\begin{align}
b\left(g(y_{\theta})U(z,y_{\theta})-g(y_{\text{r}})U(z,y_{\text{r}})\right) & =0
\end{align}

\end_inset

independently of 
\begin_inset Formula $b$
\end_inset

 because the term
\begin_inset Formula 
\[
g(y_{\theta})U(z,y_{\theta})-g(y_{\text{r}})U(z,y_{\text{r}})=0
\]

\end_inset

is equivalent to Eq.
 
\begin_inset CommandInset ref
LatexCommand ref
reference "eq: LIF characteristic equation"

\end_inset

.
 The remaining coefficient 
\begin_inset Formula $b$
\end_inset

 needs to determined from the normalization condition 
\begin_inset Formula $\bigl\langle\tilde{\phi},\phi\bigr\rangle=1$
\end_inset


\begin_inset Formula 
\begin{equation}
b=\frac{1}{\bigl\langle g(x)U(z,-x),\phi(x)\bigr\rangle}.
\end{equation}

\end_inset

The inner product can be written as 
\begin_inset Formula 
\[
\bigl\langle g(x)U(z,-x),\phi(x)\bigr\rangle=c_{n}\int_{-\infty}^{x_{\text{\text{r}}}}U(z,-x)U(z_{n},-x)+\int_{x_{\text{r}}}^{x_{\theta}}U(z,-x)\left(a_{n}V(z_{n},-x)+b_{n}U(z_{n},-x)\right)
\]

\end_inset

We arrive at 
\begin_inset Formula 
\begin{equation}
\tilde{\phi}(x)=bg(x)U(z,-x)
\end{equation}

\end_inset


\end_layout

\end_body
\end_document
