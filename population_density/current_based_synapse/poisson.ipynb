{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson process\n",
    "\n",
    "Here, we look at the Poisson process and its statistics in a neuroscientific context. We assume that the spike times recorded from a single cell or population can be approximatively modeled by a Poisson process. \n",
    "\n",
    "First, we consider the homogeneous Poisson process with a stationary firing rate $\\lambda$. \n",
    "\n",
    "## Interspike intervals\n",
    "\n",
    "The waiting time $t$ between two spikes called interspike intervals (ISI). For Poisson process, they are exponentially distributed \n",
    "\n",
    "$$p(t)=\\lambda e^{-\\lambda t}$$. \n",
    "\n",
    "The expectation value of the exponential distribution is inverse proportional to the firing rate\n",
    "\n",
    "$$\\text{E}[p(t)]=\\frac{1}{\\lambda}$$.\n",
    "\n",
    "This mean if we increase/decrease the firing rate we will wait on average a shorter/longer amount of time until the arrival of the next spike. The variance is inverse proportional to the squared firing rate  \n",
    "\n",
    "$$\\text{Var}[p(t)]=\\frac{1}{\\lambda^{2}}$$. \n",
    "\n",
    "Thus, the ratio between expectation value and standard deviation is constant \n",
    "\n",
    "$$\\frac{\\text{E}[p(t)]}{\\sqrt{\\text{Var}[p(t)]}}=1$$. \n",
    "\n",
    "This means that standard deviation and mean decrease identically with the firing rate. If we express $t$ in units of expectation value $\\text{E}[p(t)]$ then the mean and variance will be both one, i.e. independent of $\\lambda$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of interspike intervals drawn from exponential distribution  \n",
    "\n",
    "def exp_distribution_stats(t, lam):\n",
    "    '''Calculate expactation value and standard deviation of exponential distribution'''\n",
    "    \n",
    "    avg_t = np.mean(t) # ISI trial average\n",
    "    std_t = np.std(t) # ISI trial std\n",
    "\n",
    "    exp_t = 1./lam # expected ISI assuming a Poisson process\n",
    "    var_t = 1./lam**2 # variance ISI assuming a Poisson process\n",
    "    exp_std_t = np.sqrt(var_t)\n",
    "\n",
    "    return avg_t, std_t, exp_t, exp_std_t \n",
    "\n",
    "lam = 0.1 # rate\n",
    "N = 10000 # sample size\n",
    "\n",
    "t = np.random.exponential(1./lam, N) # draw N ISI's\n",
    "\n",
    "avg_t, std_t, exp_t, exp_std_t = exp_distribution_stats(t, lam)    \n",
    "\n",
    "print 'rate %.1f' % lam \n",
    "print 'ISI trial average: %.3f' % avg_t\n",
    "print 'ISI expactation value: %.3f' % exp_t\n",
    "print 'Relative deviation: %.3f' % (np.abs(avg_t - exp_t)/exp_t)\n",
    "print \n",
    "print 'ISI trial std: %.3f' % std_t\n",
    "print 'ISI expected std: %.3f' % exp_std_t\n",
    "print 'Relative deviation: %.3f' % (np.abs(std_t - exp_std_t)/exp_std_t)\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "h, _, _ = plt.hist(t, bins = 100, density = True, facecolor = 'b', edgecolor = 'b')\n",
    "plt.vlines([exp_t, ], 0, np.max(h), linestyles = ['-', '--', '--'], label = 'exp')\n",
    "plt.vlines([exp_t - exp_std_t, exp_t + exp_std_t], 0, np.max(h), linestyles = ['--', '--'], label = 'std')\n",
    "plt.xlabel('$t$', fontsize = 18)\n",
    "plt.ylabel('density', fontsize = 18)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot mean and standard deviation over firing rate  \n",
    "N = 1000\n",
    "\n",
    "lam_arr = np.linspace(0.1, 5, 10000)\n",
    "\n",
    "avg_t_arr = np.zeros_like(lam_arr)\n",
    "std_t_arr = np.zeros_like(lam_arr)\n",
    "\n",
    "for i, lam in enumerate(lam_arr):\n",
    "    \n",
    "    t = np.random.exponential(1./lam, N) # draw N ISI's\n",
    "\n",
    "    avg_t, std_t, _, _ = exp_distribution_stats(t, lam)  \n",
    "    avg_t_arr[i] = avg_t\n",
    "    std_t_arr[i] = std_t\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "        \n",
    "gs = plt.GridSpec(2, 1)    \n",
    "\n",
    "ax0 = plt.subplot(gs[0]) \n",
    "ax0.plot(lam_arr, avg_t_arr,  'o', color = 'blue', markersize = 0.5, label =  'Avg')\n",
    "ax0.plot(lam_arr, 1./lam_arr, '-', color = 'black', label =  'Exp')\n",
    "plt.legend()    \n",
    "\n",
    "ax1 = plt.subplot(gs[1])\n",
    "ax1.plot(lam_arr, std_t_arr, 'o', color = 'red', markersize = 0.5, label =  'Trial std')\n",
    "plt.plot(lam_arr, 1./lam_arr, '-', color = 'black', label =  'Std')\n",
    "\n",
    "plt.xlabel('$\\lambda$', fontsize = 18)           \n",
    "plt.legend()    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What can we learn from that?\n",
    "\n",
    "-  Expectation and standard deviation are inverse proportional to the rate, i.e. both measures will saturate for large rates close to zero\n",
    "-  The ratio between expectation value and standard deviation is constant, i.e. increasing the rate does not result in a more synchronous activity  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike counts\n",
    "\n",
    "The number of spikes $n$ observed in a time window of length $T$ are Poisson distributed \n",
    "\n",
    "$$p(n)=\\frac{(\\lambda T)^{n}}{n!}e^{-\\lambda T}$$.\n",
    "\n",
    "\n",
    "As we already mentioned, the spike counts in a time window of length $T$ will be Poisson distributed\n",
    "\n",
    "$$p(n)=\\frac{(\\lambda T)^{n}}{n!}e^{-\\lambda T}$$.\n",
    "\n",
    "The expectation value of the Poisson distribution is given by the product of the firing rate and the recording time \n",
    "\n",
    "$$\\text{E}[p(n)]=\\lambda T$$.\n",
    "\n",
    "Thus, for a fixed recording time $T$, the expected number of spikes increases proportional with the firing rate $\\lambda$. One interesting property of the Poisson distributed that the variance is equivalent to the expectation value \n",
    "\n",
    "$$\\text{E}[p(n)]=\\lambda T$$.\n",
    "\n",
    "We see that the standard deviation increases only with $sqrt{\\lambda}$. Thus, the ratio between expectation value and standard deviation  \n",
    "\n",
    "$$\\frac{\\text{E}[p(n)]}{\\sqrt{\\text{Var}[p(n)]}}=\\frac{1}{\\sqrt{\\lambda T}}$$,\n",
    "\n",
    "gets smaller with increasing $\\lambda$. Thus, we expect a narrower distribution if we express the spike count in units of the expectation value. \n",
    "\n",
    "For a Poisson process, the occurrence of an event is completely independent of the previous events. This is called the independence property. From this follows that it is equally likely to find a spike at any time point during the recording. This is still if other spikes have been already recorded. Thus, we can simply draw the number of spikes $n$ from a Poisson distribution and distribute them uniformly within the time window of the recording to obtain the spike times. We now show that this approach yields the expected distribution for the ISI's.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lam = 0.1 \n",
    "T = 100000 # choose larger recording time to match sample size in first figure\n",
    "\n",
    "n = np.random.poisson(lam*T) # spike count\n",
    "\n",
    "spike_times = np.sort(np.random.uniform(0, T, n))\n",
    "\n",
    "t = np.diff(spike_times)\n",
    "\n",
    "print\n",
    "print 'Uniformly distributed spike times'\n",
    "print 'ISI trial average: %.3f' % avg_t\n",
    "print 'ISI expactation value: %.3f' % exp_t\n",
    "print 'Relative deviation: %.3f' % (np.abs(avg_t - exp_t)/exp_t)\n",
    "print \n",
    "print 'ISI trial std: %.3f' % std_t\n",
    "print 'ISI expected std: %.3f' % exp_std_t\n",
    "print 'Relative deviation: %.3f' % (np.abs(std_t - exp_std_t)/exp_std_t)\n",
    "\n",
    "avg_t = np.mean(t) # ISI trial average\n",
    "std_t = np.std(t) # ISI trial std\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "\n",
    "h, _, _ = plt.hist(t, bins = 100, density = True, facecolor = 'b', edgecolor = 'b')\n",
    "plt.vlines([exp_t, exp_t - exp_std_t, exp_t + exp_std_t], 0, np.max(h), linestyles = ['-', '--', '--'], label = ['exp', 'avg'])\n",
    "plt.xlabel('$t$', fontsize = 18)\n",
    "plt.ylabel('$density$', fontsize = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now look at the spike trains for an ensemble of realizations (trials) of the same Poisson process and the distribution of the spike counts pooled over all trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spike_trains(lam, T, N):\n",
    "    \n",
    "    trials = []\n",
    "    spike_counts = np.zeros(N)\n",
    "    \n",
    "    for i in xrange(N):\n",
    "\n",
    "        n = np.random.poisson(lam*T) # draw number of spikes\n",
    "        spike_counts[i] = n\n",
    "        spike_times = np.random.uniform(0, T, n) # generate spike times\n",
    "        trials.append(spike_times)\n",
    "        \n",
    "    return trials, spike_counts\n",
    "\n",
    "N = 1000 # number of trials\n",
    "T = 100 # recording time  \n",
    "lam = 0.1 # rate\n",
    "\n",
    "# generate spike times for N trials \n",
    "trials, spike_counts = generate_spike_trains(lam, T, N)\n",
    "\n",
    "# plot spike trains\n",
    "fig = plt.figure(figsize = (16, 6))\n",
    "gs = plt.GridSpec(1,3)\n",
    "ax0 = plt.subplot(gs[0])  \n",
    "\n",
    "for i, trial in enumerate(trials):\n",
    " \n",
    "    ax0.plot(trial, i*np.ones_like(trial), 'o', color = 'b', markersize = 0.1)\n",
    "    spike_counts[i] = len(trial) # spike count\n",
    "\n",
    "avg_n = np.mean(spike_counts) # spike count trial average\n",
    "std_n = np.std(spike_counts) # spike count trial std\n",
    "\n",
    "exp_n = T*lam # expected number of spikes\n",
    "exp_std_n = np.sqrt(T*lam) # expected number of spikes\n",
    "\n",
    "print 'Spike count trial average: %.3f' % avg_n\n",
    "print 'Spike count expactation value: %.3f' % exp_n\n",
    "print 'Relative deviation: %.3f' % (np.abs(avg_n - exp_n)/exp_n)\n",
    "print \n",
    "print 'Spike count std: %.3f' % std_n\n",
    "print 'Spike count expected std: %.3f' % exp_std_n\n",
    "print 'Relative deviation: %.3f' % (np.abs(std_n - exp_std_n)/exp_std_n)\n",
    "\n",
    "ax0.set_xlabel('t', fontsize = 18)\n",
    "ax0.set_ylabel('trial', fontsize = 18)\n",
    " \n",
    "ax1 = plt.subplot(gs[1]) \n",
    "ax1.fill_betweenx(np.arange(N), 0, spike_counts, color = 'b')\n",
    "ax1.set_xlabel('count', fontsize = 18)\n",
    " \n",
    "#------------------------------------------------------------------------------ \n",
    "# Plot distribution of counts \n",
    "\n",
    "ax2 = plt.subplot(gs[2])  \n",
    "\n",
    "h, _, _ = ax2.hist(spike_counts, bins = 50, density = True)\n",
    "ax2.vlines(exp_n, 0, np.max(h), linestyles = ['-', '--', '--'], label = ['exp'])\n",
    "ax2.vlines([exp_n - exp_std_n, exp_n + exp_std_n], 0, np.max(h), linestyles = ['--', '--'], label = ['std'])\n",
    "\n",
    "plt.xlabel('count', fontsize = 18)\n",
    "plt.ylabel('density', fontsize = 18)\n",
    "plt.legend()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now check if the distribution of spike counts gets narrower in units of expectation value for increasing $\\lambda$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000 # number of trials\n",
    "T = 1000 # recording time  \n",
    "\n",
    "lam0 = 0.1 # rate\n",
    "lam1 = 1. # rate\n",
    "lam2 = 10. # rate\n",
    "\n",
    "# expectation value\n",
    "exp_n0 = lam0*T\n",
    "exp_n1 = lam1*T\n",
    "exp_n2 = lam2*T\n",
    "\n",
    "#expected std\n",
    "std_n0 = np.sqrt(exp_n0)\n",
    "std_n1 = np.sqrt(exp_n1)\n",
    "std_n2 = np.sqrt(exp_n2)\n",
    "\n",
    "# generate spike times for N trials \n",
    "_, spike_counts0 = generate_spike_trains(lam0, T, N)\n",
    "_, spike_counts1 = generate_spike_trains(lam1, T, N)\n",
    "_, spike_counts2 = generate_spike_trains(lam2, T, N)\n",
    "\n",
    "# plot spike count distribution\n",
    "fig = plt.figure(figsize = (16, 6))\n",
    "gs = plt.GridSpec(1,3)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])  \n",
    "ax0.hist(spike_counts0/exp_n0, bins = 50, density = True)\n",
    "plt.ylabel('density', fontsize = 18)\n",
    "plt.xlabel('count/Exp', fontsize = 18)\n",
    "\n",
    "x_min, x_max = ax0.get_xlim()\n",
    "\n",
    "ax1 = plt.subplot(gs[1])  \n",
    "ax1.hist(spike_counts1/exp_n1, bins = 50, density = True)\n",
    "ax1.set_xlim(x_min, x_max)\n",
    "\n",
    "plt.xlabel('count/Exp', fontsize = 18)\n",
    "\n",
    "ax2 = plt.subplot(gs[2])  \n",
    "ax2.hist(spike_counts2/exp_n2, bins = 50, density = True)\n",
    "ax2.set_xlim(x_min, x_max)\n",
    "\n",
    "plt.xlabel('count/Exp', fontsize = 18)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we learn from that? \n",
    "-  For infinite recording time $T\\rightarrow\\infty$, the ratio between expectation value and standard deviation vanishes\n",
    "-  The ratio between expectation value and standard deviation decreases with higher firing rate \n",
    "-  Spike counts in different trials become more similar if measured in units of the expectation value \n",
    "- If I would want to encode something in the spike count, ideally I would choose a high rate and a long recording time  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nonhomogeneous Poisson process\n",
    "\n",
    "For a nonhomogeneous Poisson process, the firing rate $\\lambda(t)$ is a function of time. It is defined as a continuous counting process ${N(t); t>0}$ which has the independent increment property. It is defined by the probability to observe $\\tilde{N}(t, t+\\delta)$ events in the infinitisemal time interval $[t,t+\\delta]$ \n",
    "\n",
    "\\begin{align}\n",
    "\\text{Pr}\\{\\tilde{N}(t,t+\\delta\\}=0\\} &= 1-\\delta\\lambda(t)+\\mathcal{O}(\\delta^{2}) \\\\\n",
    "\\text{Pr}\\{\\tilde{N}(t,t+\\delta\\}=1\\} &= \\delta\\lambda(t)+\\mathcal{O}(\\delta^{2}) \\\\\n",
    "\\text{Pr}\\{\\tilde{N}(t,t+\\delta\\}\\geq0\\} &= \\mathcal{O}(\\delta^{2})\n",
    "\\end{align}\n",
    "\n",
    "The above equation tells us that if $\\delta \\rightarrow 0$ then there are only two possible observations. Either we there is one spike with probability $delta\\lambda(t)$ or no spike with the complementary probability. The probability of observing two or more spikes is of order $\\delta^{2}$, and therefore approximately zero. \n",
    "Note that the nonhomogeneous Poisson process does not have stationary increment property because obvious if $lambda(t)$ depends on time then expected number of oberservations will depend on start point of the recording. \n",
    "\n",
    "For nonhomogeneous Poisson process, the distribution of $\\tilde{N}(t_1, t_2)$ for the number of events observed in the time window $(t_1, t_2]$ is given by  \n",
    "\n",
    "\\begin{equation}\n",
    "\\text{Pr}\\{\\tilde{N}(t_{1},t_{2}\\}=n\\}=\\frac{\\tilde{\\lambda}(t_{1},t_{2})}{n!}e^{-\\tilde{\\lambda}(t_{1},t_{2})}\n",
    "\\quad \\text{where}\\,\\, \\tilde{\\lambda}(t_{1},t_{2})=\\int_{t_{1}}^{t_{2}}dt'\\,\\lambda(t).\n",
    "\\end{equation}\n",
    "\n",
    "Note that we recover the homogeneous Poisson process with stationary rate $\\lambda$ from the above equation since $\\tilde{\\lambda}=\\lambda(t_2 - t_1)$.\n",
    "\n",
    "## Generate random samples \n",
    "\n",
    "To generate random samples for a nonhomogeneous Poisson process with rate function $\\lambda(t)$ we will use a thinning algorithm which utilizes the following property. Assume that we are given a set of event times $[t_1, t_2, \\ldots, t_n]$ in the time interval $t\\in[t_1, t_2]$ which are generated from an arbitrary nonhomogeneous Poisson process with rate function $\\eta(t)$ which fulfills $\\eta(t) \\geq \\lambda(t)$ for all $t \\in[t_1, t_2]$. If we delete each event time $t_i$ independently with probability $1-\\lambda(t_i)/\\eta(t_i)$ than the surviving spike times will be distributed according to a nonhomogeneous Poisson process with rate \\lambda(t). <br>\n",
    "Since $\\eta(t)$ must only satisfy $\\eta(t) \\geq \\lambda(t)$ and is otherwise arbitrary, we can simply choose a homogeneous Poisson process with rate $\\eta = \\text{max}(\\lambda(t))$ for $t \\in [t_1, t_2]$ which we know how to generate.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.misc import factorial\n",
    "from scipy.optimize import root \n",
    "from scipy.integrate import quad\n",
    "from scipy.stats import poisson\n",
    "\n",
    "def generate_nonhomogeneous_poisson(r, T, r_max):\n",
    "    '''Generate spike train from nonhomogeneous Poisson process with rate function r_t within recording time T\n",
    "    param r: rate function\n",
    "    param T: recording time\n",
    "    param r_max: max(r) for t in [0,T]\n",
    "    return spike_times: array with spike times'''\n",
    "    \n",
    "    # generate spike times for homogeneous Poisson process\n",
    "    N = np.random.poisson(r_max*T) # draw number of spikes drawn from Poisson distribution\n",
    "    hom_spike_times = np.sort(np.random.uniform(0, T, N)) # draw N uniformly distributed random numbers in [0, T]   \n",
    "\n",
    "    #thinning\n",
    "    p = r(hom_spike_times)/r_max # probability to accept spike\n",
    "    \n",
    "    # randomly accept spikes according to p\n",
    "    u = np.random.uniform(size = N)        \n",
    "    spike_times = hom_spike_times[u <= p] \n",
    "    \n",
    "    return spike_times\n",
    "    \n",
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "# parameter\n",
    "    \n",
    "tau = 1. # membrane time constant \n",
    "\n",
    "# define oscillating rate function \n",
    "T = 10.*tau # choose period large compared to the membrane time constannt\n",
    "w = 2.*np.pi/T\n",
    "\n",
    "A  = 5. # amplitude of oscillations \n",
    "r0 = 20. # stationary rate \n",
    "r_max = r0 + A\n",
    "\n",
    "r = lambda t: A*np.sin(w*t) + r0 # rate function\n",
    "\n",
    "Tr = 2*T # recording time\n",
    "\n",
    "#------------------------------------------------------------------------------ \n",
    "# generate ensemble of spike trains and check statistics  \n",
    "\n",
    "N = 100000 # number of trials\n",
    "\n",
    "# select random time window\n",
    "t0 = np.random.uniform(0, Tr)\n",
    "t1 = np.random.uniform(0, Tr)\n",
    "\n",
    "if t0 < t1:\n",
    "    pass\n",
    "else:\n",
    "    t = t0\n",
    "    t0 = t1\n",
    "    t1 = t\n",
    "\n",
    "# generate N spike trains    \n",
    "N_arr = np.zeros(N) \n",
    " \n",
    "for i in xrange(N):\n",
    "\n",
    "    spike_train = generate_nonhomogeneous_poisson(r, Tr, r0 + A)\n",
    "    \n",
    "    hits = np.logical_and(t0 <= spike_train, spike_train <= t1)\n",
    "    count = np.sum(hits)\n",
    "    N_arr[i] = count\n",
    "\n",
    "# estimate count statistics    \n",
    "N_min = min(N_arr)\n",
    "N_max = max(N_arr)\n",
    "\n",
    "n_arr = np.arange(N_min, N_max)\n",
    "\n",
    "p_arr_0 = np.zeros_like(n_arr)\n",
    "\n",
    "# theoretical prediction for spike count statistics \n",
    "lam = quad(r, t0, t1)[0] # rate integral \n",
    "p_arr_1 = np.zeros_like(n_arr)\n",
    "\n",
    "for i,n in enumerate(n_arr):\n",
    "    \n",
    "    count = np.sum(N_arr == n)\n",
    "    p = float(count)/N\n",
    "    p_arr_0[i] = p\n",
    "    # calculated expected prop. from Poisson distribution\n",
    "    p_arr_1[i] = poisson.pmf(n, lam)\n",
    "    \n",
    "#------------------------------------------------------------------------------ \n",
    "# plotting \n",
    "\n",
    "fig = plt.figure(figsize = (12, 6))\n",
    "\n",
    "gs = plt.GridSpec(1,1)\n",
    "\n",
    "ax0 = plt.subplot(gs[0])\n",
    "ax0.bar(n_arr, p_arr_1, align = 'center', color = 'blue', label = 'theory')\n",
    "ax0.plot(n_arr, p_arr_0, 'x', color = 'red', label = 'trial statistics')\n",
    "\n",
    "plt.xlabel('number of spikes', fontsize = 18)\n",
    "plt.ylabel('probability', fontsize = 18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
